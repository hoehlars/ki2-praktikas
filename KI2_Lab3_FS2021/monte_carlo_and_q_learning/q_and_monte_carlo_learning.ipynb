{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d97d4bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym  # If gym isn't installed yet in your environment, then you can install it via pip: pip install gym\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59b715e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('LunarLander-v2')\n",
    "env.reset()\n",
    "for _ in range(200):\n",
    "    env.render()\n",
    "    observation, reward, done, info = env.step(env.action_space.sample())\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cd3460",
   "metadata": {},
   "source": [
    "## Naiven Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb1fc60f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "628\n",
      "629\n",
      "630\n",
      "631\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "637\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "649\n",
      "650\n",
      "651\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "660\n",
      "661\n",
      "662\n",
      "663\n",
      "664\n",
      "665\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n",
      "670\n",
      "671\n",
      "672\n",
      "673\n",
      "674\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n",
      "679\n",
      "680\n",
      "681\n",
      "682\n",
      "683\n",
      "684\n",
      "685\n",
      "686\n",
      "687\n",
      "688\n",
      "689\n",
      "690\n",
      "691\n",
      "692\n",
      "693\n",
      "694\n",
      "695\n",
      "696\n",
      "697\n",
      "698\n",
      "699\n",
      "700\n",
      "701\n",
      "702\n",
      "703\n",
      "704\n",
      "705\n",
      "706\n",
      "707\n",
      "708\n",
      "709\n",
      "710\n",
      "711\n",
      "712\n",
      "713\n",
      "714\n",
      "715\n",
      "716\n",
      "717\n",
      "718\n",
      "719\n",
      "720\n",
      "721\n",
      "722\n",
      "723\n",
      "724\n",
      "725\n",
      "726\n",
      "727\n",
      "728\n",
      "729\n",
      "730\n",
      "731\n",
      "732\n",
      "733\n",
      "734\n",
      "735\n",
      "736\n",
      "737\n",
      "738\n",
      "739\n",
      "740\n",
      "741\n",
      "742\n",
      "743\n",
      "744\n",
      "745\n",
      "746\n",
      "747\n",
      "748\n",
      "749\n",
      "750\n",
      "751\n",
      "752\n",
      "753\n",
      "754\n",
      "755\n",
      "756\n",
      "757\n",
      "758\n",
      "759\n",
      "760\n",
      "761\n",
      "762\n",
      "763\n",
      "764\n",
      "765\n",
      "766\n",
      "767\n",
      "768\n",
      "769\n",
      "770\n",
      "771\n",
      "772\n",
      "773\n",
      "774\n",
      "775\n",
      "776\n",
      "777\n",
      "778\n",
      "779\n",
      "780\n",
      "781\n",
      "782\n",
      "783\n",
      "784\n",
      "785\n",
      "786\n",
      "787\n",
      "788\n",
      "789\n",
      "790\n",
      "791\n",
      "792\n",
      "793\n",
      "794\n",
      "795\n",
      "796\n",
      "797\n",
      "798\n",
      "799\n",
      "800\n",
      "801\n",
      "802\n",
      "803\n",
      "804\n",
      "805\n",
      "806\n",
      "807\n",
      "808\n",
      "809\n",
      "810\n",
      "811\n",
      "812\n",
      "813\n",
      "814\n",
      "815\n",
      "816\n",
      "817\n",
      "818\n",
      "819\n",
      "820\n",
      "821\n",
      "822\n",
      "823\n",
      "824\n",
      "825\n",
      "826\n",
      "827\n",
      "828\n",
      "829\n",
      "830\n",
      "831\n",
      "832\n",
      "833\n",
      "834\n",
      "835\n",
      "836\n",
      "837\n",
      "838\n",
      "839\n",
      "840\n",
      "841\n",
      "842\n",
      "843\n",
      "844\n",
      "845\n",
      "846\n",
      "847\n",
      "848\n",
      "849\n",
      "850\n",
      "851\n",
      "852\n",
      "853\n",
      "854\n",
      "855\n",
      "856\n",
      "857\n",
      "858\n",
      "859\n",
      "860\n",
      "861\n",
      "862\n",
      "863\n",
      "864\n",
      "865\n",
      "866\n",
      "867\n",
      "868\n",
      "869\n",
      "870\n",
      "871\n",
      "872\n",
      "873\n",
      "874\n",
      "875\n",
      "876\n",
      "877\n",
      "878\n",
      "879\n",
      "880\n",
      "881\n",
      "882\n",
      "883\n",
      "884\n",
      "885\n",
      "886\n",
      "887\n",
      "888\n",
      "889\n",
      "890\n",
      "891\n",
      "892\n",
      "893\n",
      "894\n",
      "895\n",
      "896\n",
      "897\n",
      "898\n",
      "899\n",
      "900\n",
      "901\n",
      "902\n",
      "903\n",
      "904\n",
      "905\n",
      "906\n",
      "907\n",
      "908\n",
      "909\n",
      "910\n",
      "911\n",
      "912\n",
      "913\n",
      "914\n",
      "915\n",
      "916\n",
      "917\n",
      "918\n",
      "919\n",
      "920\n",
      "921\n",
      "922\n",
      "923\n",
      "924\n",
      "925\n",
      "926\n",
      "927\n",
      "928\n",
      "929\n",
      "930\n",
      "931\n",
      "932\n",
      "933\n",
      "934\n",
      "935\n",
      "936\n",
      "937\n",
      "938\n",
      "939\n",
      "940\n",
      "941\n",
      "942\n",
      "943\n",
      "944\n",
      "945\n",
      "946\n",
      "947\n",
      "948\n",
      "949\n",
      "950\n",
      "951\n",
      "952\n",
      "953\n",
      "954\n",
      "955\n",
      "956\n",
      "957\n",
      "958\n",
      "959\n",
      "960\n",
      "961\n",
      "962\n",
      "963\n",
      "964\n",
      "965\n",
      "966\n",
      "967\n",
      "968\n",
      "969\n",
      "970\n",
      "971\n",
      "972\n",
      "973\n",
      "974\n",
      "975\n",
      "976\n",
      "977\n",
      "978\n",
      "979\n",
      "980\n",
      "981\n",
      "982\n",
      "983\n",
      "984\n",
      "985\n",
      "986\n",
      "987\n",
      "988\n",
      "989\n",
      "990\n",
      "991\n",
      "992\n",
      "993\n",
      "994\n",
      "995\n",
      "996\n",
      "997\n",
      "998\n",
      "999\n",
      "1000\n",
      "1001\n",
      "1002\n",
      "1003\n",
      "1004\n",
      "1005\n",
      "1006\n",
      "1007\n",
      "1008\n",
      "1009\n",
      "1010\n",
      "1011\n",
      "1012\n",
      "1013\n",
      "1014\n",
      "1015\n",
      "1016\n",
      "1017\n",
      "1018\n",
      "1019\n",
      "1020\n",
      "1021\n",
      "1022\n",
      "1023\n",
      "1024\n",
      "1025\n",
      "1026\n",
      "1027\n",
      "1028\n",
      "1029\n",
      "1030\n",
      "1031\n",
      "1032\n",
      "1033\n",
      "1034\n",
      "1035\n",
      "1036\n",
      "1037\n",
      "1038\n",
      "1039\n",
      "1040\n",
      "1041\n",
      "1042\n",
      "1043\n",
      "1044\n",
      "1045\n",
      "1046\n",
      "1047\n",
      "1048\n",
      "1049\n",
      "1050\n",
      "1051\n",
      "1052\n",
      "1053\n",
      "1054\n",
      "1055\n",
      "1056\n",
      "1057\n",
      "1058\n",
      "1059\n",
      "1060\n",
      "1061\n",
      "1062\n",
      "1063\n",
      "1064\n",
      "1065\n",
      "1066\n",
      "1067\n",
      "1068\n",
      "1069\n",
      "1070\n",
      "1071\n",
      "1072\n",
      "1073\n",
      "1074\n",
      "1075\n",
      "1076\n",
      "1077\n",
      "1078\n",
      "1079\n",
      "1080\n",
      "1081\n",
      "1082\n",
      "1083\n",
      "1084\n",
      "1085\n",
      "1086\n",
      "1087\n",
      "1088\n",
      "1089\n",
      "1090\n",
      "1091\n",
      "1092\n",
      "1093\n",
      "1094\n",
      "1095\n",
      "1096\n",
      "1097\n",
      "1098\n",
      "1099\n",
      "1100\n",
      "1101\n",
      "1102\n",
      "1103\n",
      "1104\n",
      "1105\n",
      "1106\n",
      "1107\n",
      "1108\n",
      "1109\n",
      "1110\n",
      "1111\n",
      "1112\n",
      "1113\n",
      "1114\n",
      "1115\n",
      "1116\n",
      "1117\n",
      "1118\n",
      "1119\n",
      "1120\n",
      "1121\n",
      "1122\n",
      "1123\n",
      "1124\n",
      "1125\n",
      "1126\n",
      "1127\n",
      "1128\n",
      "1129\n",
      "1130\n",
      "1131\n",
      "1132\n",
      "1133\n",
      "1134\n",
      "1135\n",
      "1136\n",
      "1137\n",
      "1138\n",
      "1139\n",
      "1140\n",
      "1141\n",
      "1142\n",
      "1143\n",
      "1144\n",
      "1145\n",
      "1146\n",
      "1147\n",
      "1148\n",
      "1149\n",
      "1150\n",
      "1151\n",
      "1152\n",
      "1153\n",
      "1154\n",
      "1155\n",
      "1156\n",
      "1157\n",
      "1158\n",
      "1159\n",
      "1160\n",
      "1161\n",
      "1162\n",
      "1163\n",
      "1164\n",
      "1165\n",
      "1166\n",
      "1167\n",
      "1168\n",
      "1169\n",
      "1170\n",
      "1171\n",
      "1172\n",
      "1173\n",
      "1174\n",
      "1175\n",
      "1176\n",
      "1177\n",
      "1178\n",
      "1179\n",
      "1180\n",
      "1181\n",
      "1182\n",
      "1183\n",
      "1184\n",
      "1185\n",
      "1186\n",
      "1187\n",
      "1188\n",
      "1189\n",
      "1190\n",
      "1191\n",
      "1192\n",
      "1193\n",
      "1194\n",
      "1195\n",
      "1196\n",
      "1197\n",
      "1198\n",
      "1199\n",
      "1200\n",
      "1201\n",
      "1202\n",
      "1203\n",
      "1204\n",
      "1205\n",
      "1206\n",
      "1207\n",
      "1208\n",
      "1209\n",
      "1210\n",
      "1211\n",
      "1212\n",
      "1213\n",
      "1214\n",
      "1215\n",
      "1216\n",
      "1217\n",
      "1218\n",
      "1219\n",
      "1220\n",
      "1221\n",
      "1222\n",
      "1223\n",
      "1224\n",
      "1225\n",
      "1226\n",
      "1227\n",
      "1228\n",
      "1229\n",
      "1230\n",
      "1231\n",
      "1232\n",
      "1233\n",
      "1234\n",
      "1235\n",
      "1236\n",
      "1237\n",
      "1238\n",
      "1239\n",
      "1240\n",
      "1241\n",
      "1242\n",
      "1243\n",
      "1244\n",
      "1245\n",
      "1246\n",
      "1247\n",
      "1248\n",
      "1249\n",
      "1250\n",
      "1251\n",
      "1252\n",
      "1253\n",
      "1254\n",
      "1255\n",
      "1256\n",
      "1257\n",
      "1258\n",
      "1259\n",
      "1260\n",
      "1261\n",
      "1262\n",
      "1263\n",
      "1264\n",
      "1265\n",
      "1266\n",
      "1267\n",
      "1268\n",
      "1269\n",
      "1270\n",
      "1271\n",
      "1272\n",
      "1273\n",
      "1274\n",
      "1275\n",
      "1276\n",
      "1277\n",
      "1278\n",
      "1279\n",
      "1280\n",
      "1281\n",
      "1282\n",
      "1283\n",
      "1284\n",
      "1285\n",
      "1286\n",
      "1287\n",
      "1288\n",
      "1289\n",
      "1290\n",
      "1291\n",
      "1292\n",
      "1293\n",
      "1294\n",
      "1295\n",
      "1296\n",
      "1297\n",
      "1298\n",
      "1299\n",
      "1300\n",
      "1301\n",
      "1302\n",
      "1303\n",
      "1304\n",
      "1305\n",
      "1306\n",
      "1307\n",
      "1308\n",
      "1309\n",
      "1310\n",
      "1311\n",
      "1312\n",
      "1313\n",
      "1314\n",
      "1315\n",
      "1316\n",
      "1317\n",
      "1318\n",
      "1319\n",
      "1320\n",
      "1321\n",
      "1322\n",
      "1323\n",
      "1324\n",
      "1325\n",
      "1326\n",
      "1327\n",
      "1328\n",
      "1329\n",
      "1330\n",
      "1331\n",
      "1332\n",
      "1333\n",
      "1334\n",
      "1335\n",
      "1336\n",
      "1337\n",
      "1338\n",
      "1339\n",
      "1340\n",
      "1341\n",
      "1342\n",
      "1343\n",
      "1344\n",
      "1345\n",
      "1346\n",
      "1347\n",
      "1348\n",
      "1349\n",
      "1350\n",
      "1351\n",
      "1352\n",
      "1353\n",
      "1354\n",
      "1355\n",
      "1356\n",
      "1357\n",
      "1358\n",
      "1359\n",
      "1360\n",
      "1361\n",
      "1362\n",
      "1363\n",
      "1364\n",
      "1365\n",
      "1366\n",
      "1367\n",
      "1368\n",
      "1369\n",
      "1370\n",
      "1371\n",
      "1372\n",
      "1373\n",
      "1374\n",
      "1375\n",
      "1376\n",
      "1377\n",
      "1378\n",
      "1379\n",
      "1380\n",
      "1381\n",
      "1382\n",
      "1383\n",
      "1384\n",
      "1385\n",
      "1386\n",
      "1387\n",
      "1388\n",
      "1389\n",
      "1390\n",
      "1391\n",
      "1392\n",
      "1393\n",
      "1394\n",
      "1395\n",
      "1396\n",
      "1397\n",
      "1398\n",
      "1399\n",
      "1400\n",
      "1401\n",
      "1402\n",
      "1403\n",
      "1404\n",
      "1405\n",
      "1406\n",
      "1407\n",
      "1408\n",
      "1409\n",
      "1410\n",
      "1411\n",
      "1412\n",
      "1413\n",
      "1414\n",
      "1415\n",
      "1416\n",
      "1417\n",
      "1418\n",
      "1419\n",
      "1420\n",
      "1421\n",
      "1422\n",
      "1423\n",
      "1424\n",
      "1425\n",
      "1426\n",
      "1427\n",
      "1428\n",
      "1429\n",
      "1430\n",
      "1431\n",
      "1432\n",
      "1433\n",
      "1434\n",
      "1435\n",
      "1436\n",
      "1437\n",
      "1438\n",
      "1439\n",
      "1440\n",
      "1441\n",
      "1442\n",
      "1443\n",
      "1444\n",
      "1445\n",
      "1446\n",
      "1447\n",
      "1448\n",
      "1449\n",
      "1450\n",
      "1451\n",
      "1452\n",
      "1453\n",
      "1454\n",
      "1455\n",
      "1456\n",
      "1457\n",
      "1458\n",
      "1459\n",
      "1460\n",
      "1461\n",
      "1462\n",
      "1463\n",
      "1464\n",
      "1465\n",
      "1466\n",
      "1467\n",
      "1468\n",
      "1469\n",
      "1470\n",
      "1471\n",
      "1472\n",
      "1473\n",
      "1474\n",
      "1475\n",
      "1476\n",
      "1477\n",
      "1478\n",
      "1479\n",
      "1480\n",
      "1481\n",
      "1482\n",
      "1483\n",
      "1484\n",
      "1485\n",
      "1486\n",
      "1487\n",
      "1488\n",
      "1489\n",
      "1490\n",
      "1491\n",
      "1492\n",
      "1493\n",
      "1494\n",
      "1495\n",
      "1496\n",
      "1497\n",
      "1498\n",
      "1499\n",
      "1500\n",
      "1501\n",
      "1502\n",
      "1503\n",
      "1504\n",
      "1505\n",
      "1506\n",
      "1507\n",
      "1508\n",
      "1509\n",
      "1510\n",
      "1511\n",
      "1512\n",
      "1513\n",
      "1514\n",
      "1515\n",
      "1516\n",
      "1517\n",
      "1518\n",
      "1519\n",
      "1520\n",
      "1521\n",
      "1522\n",
      "1523\n",
      "1524\n",
      "1525\n",
      "1526\n",
      "1527\n",
      "1528\n",
      "1529\n",
      "1530\n",
      "1531\n",
      "1532\n",
      "1533\n",
      "1534\n",
      "1535\n",
      "1536\n",
      "1537\n",
      "1538\n",
      "1539\n",
      "1540\n",
      "1541\n",
      "1542\n",
      "1543\n",
      "1544\n",
      "1545\n",
      "1546\n",
      "1547\n",
      "1548\n",
      "1549\n",
      "1550\n",
      "1551\n",
      "1552\n",
      "1553\n",
      "1554\n",
      "1555\n",
      "1556\n",
      "1557\n",
      "1558\n",
      "1559\n",
      "1560\n",
      "1561\n",
      "1562\n",
      "1563\n",
      "1564\n",
      "1565\n",
      "1566\n",
      "1567\n",
      "1568\n",
      "1569\n",
      "1570\n",
      "1571\n",
      "1572\n",
      "1573\n",
      "1574\n",
      "1575\n",
      "1576\n",
      "1577\n",
      "1578\n",
      "1579\n",
      "1580\n",
      "1581\n",
      "1582\n",
      "1583\n",
      "1584\n",
      "1585\n",
      "1586\n",
      "1587\n",
      "1588\n",
      "1589\n",
      "1590\n",
      "1591\n",
      "1592\n",
      "1593\n",
      "1594\n",
      "1595\n",
      "1596\n",
      "1597\n",
      "1598\n",
      "1599\n",
      "1600\n",
      "1601\n",
      "1602\n",
      "1603\n",
      "1604\n",
      "1605\n",
      "1606\n",
      "1607\n",
      "1608\n",
      "1609\n",
      "1610\n",
      "1611\n",
      "1612\n",
      "1613\n",
      "1614\n",
      "1615\n",
      "1616\n",
      "1617\n",
      "1618\n",
      "1619\n",
      "1620\n",
      "1621\n",
      "1622\n",
      "1623\n",
      "1624\n",
      "1625\n",
      "1626\n",
      "1627\n",
      "1628\n",
      "1629\n",
      "1630\n",
      "1631\n",
      "1632\n",
      "1633\n",
      "1634\n",
      "1635\n",
      "1636\n",
      "1637\n",
      "1638\n",
      "1639\n",
      "1640\n",
      "1641\n",
      "1642\n",
      "1643\n",
      "1644\n",
      "1645\n",
      "1646\n",
      "1647\n",
      "1648\n",
      "1649\n",
      "1650\n",
      "1651\n",
      "1652\n",
      "1653\n",
      "1654\n",
      "1655\n",
      "1656\n",
      "1657\n",
      "1658\n",
      "1659\n",
      "1660\n",
      "1661\n",
      "1662\n",
      "1663\n",
      "1664\n",
      "1665\n",
      "1666\n",
      "1667\n",
      "1668\n",
      "1669\n",
      "1670\n",
      "1671\n",
      "1672\n",
      "1673\n",
      "1674\n",
      "1675\n",
      "1676\n",
      "1677\n",
      "1678\n",
      "1679\n",
      "1680\n",
      "1681\n",
      "1682\n",
      "1683\n",
      "1684\n",
      "1685\n",
      "1686\n",
      "1687\n",
      "1688\n",
      "1689\n",
      "1690\n",
      "1691\n",
      "1692\n",
      "1693\n",
      "1694\n",
      "1695\n",
      "1696\n",
      "1697\n",
      "1698\n",
      "1699\n",
      "1700\n",
      "1701\n",
      "1702\n",
      "1703\n",
      "1704\n",
      "1705\n",
      "1706\n",
      "1707\n",
      "1708\n",
      "1709\n",
      "1710\n",
      "1711\n",
      "1712\n",
      "1713\n",
      "1714\n",
      "1715\n",
      "1716\n",
      "1717\n",
      "1718\n",
      "1719\n",
      "1720\n",
      "1721\n",
      "1722\n",
      "1723\n",
      "1724\n",
      "1725\n",
      "1726\n",
      "1727\n",
      "1728\n",
      "1729\n",
      "1730\n",
      "1731\n",
      "1732\n",
      "1733\n",
      "1734\n",
      "1735\n",
      "1736\n",
      "1737\n",
      "1738\n",
      "1739\n",
      "1740\n",
      "1741\n",
      "1742\n",
      "1743\n",
      "1744\n",
      "1745\n",
      "1746\n",
      "1747\n",
      "1748\n",
      "1749\n",
      "1750\n",
      "1751\n",
      "1752\n",
      "1753\n",
      "1754\n",
      "1755\n",
      "1756\n",
      "1757\n",
      "1758\n",
      "1759\n",
      "1760\n",
      "1761\n",
      "1762\n",
      "1763\n",
      "1764\n",
      "1765\n",
      "1766\n",
      "1767\n",
      "1768\n",
      "1769\n",
      "1770\n",
      "1771\n",
      "1772\n",
      "1773\n",
      "1774\n",
      "1775\n",
      "1776\n",
      "1777\n",
      "1778\n",
      "1779\n",
      "1780\n",
      "1781\n",
      "1782\n",
      "1783\n",
      "1784\n",
      "1785\n",
      "1786\n",
      "1787\n",
      "1788\n",
      "1789\n",
      "1790\n",
      "1791\n",
      "1792\n",
      "1793\n",
      "1794\n",
      "1795\n",
      "1796\n",
      "1797\n",
      "1798\n",
      "1799\n",
      "1800\n",
      "1801\n",
      "1802\n",
      "1803\n",
      "1804\n",
      "1805\n",
      "1806\n",
      "1807\n",
      "1808\n",
      "1809\n",
      "1810\n",
      "1811\n",
      "1812\n",
      "1813\n",
      "1814\n",
      "1815\n",
      "1816\n",
      "1817\n",
      "1818\n",
      "1819\n",
      "1820\n",
      "1821\n",
      "1822\n",
      "1823\n",
      "1824\n",
      "1825\n",
      "1826\n",
      "1827\n",
      "1828\n",
      "1829\n",
      "1830\n",
      "1831\n",
      "1832\n",
      "1833\n",
      "1834\n",
      "1835\n",
      "1836\n",
      "1837\n",
      "1838\n",
      "1839\n",
      "1840\n",
      "1841\n",
      "1842\n",
      "1843\n",
      "1844\n",
      "1845\n",
      "1846\n",
      "1847\n",
      "1848\n",
      "1849\n",
      "1850\n",
      "1851\n",
      "1852\n",
      "1853\n",
      "1854\n",
      "1855\n",
      "1856\n",
      "1857\n",
      "1858\n",
      "1859\n",
      "1860\n",
      "1861\n",
      "1862\n",
      "1863\n",
      "1864\n",
      "1865\n",
      "1866\n",
      "1867\n",
      "1868\n",
      "1869\n",
      "1870\n",
      "1871\n",
      "1872\n",
      "1873\n",
      "1874\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875\n",
      "1876\n",
      "1877\n",
      "1878\n",
      "1879\n",
      "1880\n",
      "1881\n",
      "1882\n",
      "1883\n",
      "1884\n",
      "1885\n",
      "1886\n",
      "1887\n",
      "1888\n",
      "1889\n",
      "1890\n",
      "1891\n",
      "1892\n",
      "1893\n",
      "1894\n",
      "1895\n",
      "1896\n",
      "1897\n",
      "1898\n",
      "1899\n",
      "1900\n",
      "1901\n",
      "1902\n",
      "1903\n",
      "1904\n",
      "1905\n",
      "1906\n",
      "1907\n",
      "1908\n",
      "1909\n",
      "1910\n",
      "1911\n",
      "1912\n",
      "1913\n",
      "1914\n",
      "1915\n",
      "1916\n",
      "1917\n",
      "1918\n",
      "1919\n",
      "1920\n",
      "1921\n",
      "1922\n",
      "1923\n",
      "1924\n",
      "1925\n",
      "1926\n",
      "1927\n",
      "1928\n",
      "1929\n",
      "1930\n",
      "1931\n",
      "1932\n",
      "1933\n",
      "1934\n",
      "1935\n",
      "1936\n",
      "1937\n",
      "1938\n",
      "1939\n",
      "1940\n",
      "1941\n",
      "1942\n",
      "1943\n",
      "1944\n",
      "1945\n",
      "1946\n",
      "1947\n",
      "1948\n",
      "1949\n",
      "1950\n",
      "1951\n",
      "1952\n",
      "1953\n",
      "1954\n",
      "1955\n",
      "1956\n",
      "1957\n",
      "1958\n",
      "1959\n",
      "1960\n",
      "1961\n",
      "1962\n",
      "1963\n",
      "1964\n",
      "1965\n",
      "1966\n",
      "1967\n",
      "1968\n",
      "1969\n",
      "1970\n",
      "1971\n",
      "1972\n",
      "1973\n",
      "1974\n",
      "1975\n",
      "1976\n",
      "1977\n",
      "1978\n",
      "1979\n",
      "1980\n",
      "1981\n",
      "1982\n",
      "1983\n",
      "1984\n",
      "1985\n",
      "1986\n",
      "1987\n",
      "1988\n",
      "1989\n",
      "1990\n",
      "1991\n",
      "1992\n",
      "1993\n",
      "1994\n",
      "1995\n",
      "1996\n",
      "1997\n",
      "1998\n",
      "1999\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('LunarLander-v2')\n",
    "best_param = np.zeros(8)\n",
    "best_cumulative_reward = 0.0\n",
    "for epoch in range(2000):\n",
    "    observation = env.reset()\n",
    "    param = 2 * np.random.rand(8) - 1 # initialize new random parameter\n",
    "    done = False\n",
    "    cumulative_reward = 0.0\n",
    "    while not done:\n",
    "        # choose action according to our model\n",
    "        action = 0 if np.dot(param, observation) < 0.0 else 1\n",
    "        observation, reward, done, _ = env.step(action)\n",
    "        cumulative_reward += reward\n",
    "    \n",
    "    if cumulative_reward > best_cumulative_reward:\n",
    "        best_param = param\n",
    "        best_cumulative_reward = cumulative_reward\n",
    "    print(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2363fb19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-147.9443757322111\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('LunarLander-v2')\n",
    "done = False\n",
    "observation = env.reset()\n",
    "cum_reward = 0.0\n",
    "while not done:\n",
    "    env.render()\n",
    "    action = 0 if np.dot(best_param, observation) < 0.0 else 1\n",
    "    observation, reward, done, _  = env.step(action)\n",
    "    cum_reward += reward\n",
    "env.close()\n",
    "print(cum_reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb8b033",
   "metadata": {},
   "source": [
    "## Hill Climbing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "be517f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HillClimbRandomPolicy(object):\n",
    "    def __init__(self, dim=4):\n",
    "        self.dim = dim\n",
    "        self.param = self._resample()\n",
    "        self.max_reward = 0.0\n",
    "        self.epsilon = 0.1\n",
    "        self.best_param = self.param\n",
    "        \n",
    "    def _resample(self):\n",
    "        return 2 * np.random.rand(self.dim) - 1\n",
    "    \n",
    "    def action(self, observation):\n",
    "        return 0 if np.dot(observation, self.param) < 0.0 else 1\n",
    "    \n",
    "    def best_action(self, observation):\n",
    "        return 0 if np.dot(observation, self.best_param) < 0.0 else 1\n",
    "    \n",
    "    def update(self, history):\n",
    "        total_reward = np.sum([h['reward'] for h in history])\n",
    "        if total_reward > self.max_reward:\n",
    "            self.max_reward = total_reward\n",
    "            self.best_param = self.param\n",
    "        else:\n",
    "            self.param = self.best_param\n",
    "        self.param += self.epsilon * self._resample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d606a24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "env = gym.make('LunarLander-v2')\n",
    "policy = HillClimbRandomPolicy(dim=8)\n",
    "for epoch in range(30000):\n",
    "    clear_output(wait=True)\n",
    "    done = False\n",
    "    observation = env.reset()\n",
    "    history = []\n",
    "    while not done:\n",
    "        action = policy.action(observation)\n",
    "        history_elem = {}\n",
    "        history_elem['observation'] = observation\n",
    "        history_elem['action'] = action\n",
    "        observation, reward, done, _ = env.step(action)\n",
    "        history_elem['reward'] = reward\n",
    "        \n",
    "        history.append(history_elem)\n",
    "\n",
    "    policy.update(history)\n",
    "    print(epoch)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9255377c",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('LunarLander-v2')\n",
    "done = False\n",
    "observation = env.reset()\n",
    "cum_reward = 0.0\n",
    "while not done:\n",
    "    env.render()\n",
    "    action = policy.best_action(observation)\n",
    "    observation, reward, done, _  = env.step(action)\n",
    "    cum_reward += reward\n",
    "env.close()\n",
    "print(cum_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1fa82655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1EAAAGKCAYAAADt48tvAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAA/bklEQVR4nO3de5ycZX3//9cnm82RzIIkEUyAhQYQxCWEEIMQ5CgIyEHL6SdFwIoKtSLaIloBUawHtK1FtBQVkHwJIAbwAErkjA0YMEYOQmJJSQKEkJDNgZxz/f64Z7Kzk9lkJrub2dm8no/H/biPc9+fmdy1++a67uuOlBKSJEmSpMr0qXUBkiRJklRPDFGSJEmSVAVDlCRJkiRVwRAlSZIkSVUwREmSJElSFQxRkiRJklQFQ5QkbQURcW5EpA6mxVtwvub8Z8/t+mo7vObsiLixi851eMlvsDYiXo6I6yJih664Ri115W9VSxExOiKujIi3ldmXIuLKGpQlSTXXt9YFSNI25jRgbsm2tVtwnleBg4G/drqi2vpH4A/AIOAo4FJgF+CDtSxKG4wGrgBuARaV7DuYje9lSdomGKIkaeuanlKa1dmTpJRWAVO7oJ5aez6lVPgeD0TEcODvI2KnlNJrtSxsUyKiEVibesEb67f0uxT9u0nSNsfufJLUgxR1+zssIu6KiGURsTAivh8RA4uO26g7X0QcFBH3549/KyL+NyKuKzn/uIiYkj/v8oj4XUSMK1PHZ/Jd0lZGxLSImNBBvbtHxMSIWBARqyJiekSc2omf4On8fNeia/SNiMsi4i/5a7wSEd+JiAFFxzwTETcUrTdFxLqIaNdSEhGPR8TtRev/EBH/ExGLImJxREyNiBNKPlP4rS+MiG9FxCvAKmD7/P6KfqtyImLviJicv/aK/PWPK9p/ev7aLWU+e29ETK/yd9rkdyk5/7nAT/KrM4u6Xjbn97frzpfv9pci4p0R8Zv8/fVyRJyX3/93+dqWRcSDEfE3Za758Yj4U/63fCMiflSuK6Ek1ZohSpK2rob8H7vFU7n/Lb4FmAV8CPg34OPADzo6aURsB/wGWAecCxwPXEVRj4P8H+IPAzvkjzkHyAEPR8T+Rcd9DPh34EHgFOBG4Nb854qvuQvwBLA/8FngJLIQdGdEnFTBb1FOc/47zC7adgvwL8D/A04A/hX4GDCx6JgHgCOL1g8nCwcjImKvfL2DgYPy36v4ejeQdbM8A5gG/DIiPlCmti8BewEXAKcCKyv9rcqJiHcAj5H9fv8AnA4sBn5VdP17gFbg7JLPvh04Gvhp0eZKfqcOv0uZY34FfC2/fBpZ972DybqSbsod+c+eAjwF/Dgivg58CvgCcB6wd77O4u/0DeA6YArZvfRPwHHAvRHRsJlrStLWlVJycnJycurmiSy0pA6mX5Y57ocln/8SWbjYK7/enD/u3Pz62Px6yyZq+BnZH+nbF23LkT3r8vP8eh9gDnBfyWfPyJ//xqJtPwIWADuWHHs/WbfFTf0eh+fP936yoDeE7I/uJcA1RcdNyB93TsnnP5LfPjq/fmp+fbf8+r+TBZCZwCfy247LH/PODmrqk6/lt8DdRdsLv/XTQJQcX9Fv1cH1riF7Hm5U0bYG4AXg6aJt/0327FGfom0X5z+7c5W/U9nvUsF9O6rMvgRcWbR+ZWkNZGFyLbAQyBVt/8eSf69msvv78pJrHJI/7pRa/9+wk5OTU/FkS5QkbV2nkrWGFE8Xlznu9pL1SWR/tG/U9S5vJllA+q+IODvfSlTqMLLAtriwIaW0hCxsvC+/aWR+Kr3+nWw8AMZxwK+B1uKWNbIWsf0jItdBrcV+A6whC0+TgUfIWiCKr7GarHWr+Bq/LfpOkLWwraetNepIstapB0q2vZpS+kvh5BFxYET8MiLm57/fGuAYspaSUnellIqfG6rmtyrnMGBqKnpGLqW0jqwla3TR7/dTYATtW9r+DpiSUiq0ClX6O3X0XbrSvYWFlNKbwOtk33NJ0TGFf4PCfXoM2f09saT+J8jujdL6JammDFGStHU9k1KaVjKVG2hifgfrI8qdNKXUChwBvELWJerl/HNCHy467G2U74r1Gm3dz3Yud/2UUqE1odhwsi6Ba0qmb+f371iu1hIXkQXJo4HbyLqhfbnkGv2AZSXXeL34GimlRcCfgCMiYiiwH1kXuwfJWr0g+302dOXLB83fkf0unwbem6/lPmDDc0RFSn+7an6rcjb17xG0/Zs8Sta98e/yde8DjKF9V76KfqdNfJeu9GbJ+uoOtkHb7zw8P5/FxvdTjsruJUnaahydT5J6prcDz5asA8zr6AMppenAh/P/BX8scBlwe0Tsn1J6hqzb3k5lProTbcNXF/64fnvxAflzlv4hu5DsD/xvdlDSKx3VWuTFlNK0/DUeyF/3ixHxk5TSnPw1VpJ1V9vcNR4k60p3RP5zM/LfZ3hEHAIcAPxX0fHHAU3A6SmlDQNQRMSgDq5V2nJTzW9Vzqb+PVJ+PymlFBG3ABdHxKfIwtQyspa7gmp+J9j4u9RaIXS+n40DV/F+SeoRbImSpJ7p9JL1M8m6qz25uQ+mlNambPjpL5P97/w++V0PAydExJDCsfnlD+b3QfbszZwy1/8wG/+Ht/uAFuDZMq1r01I2DHvF8t3LLiZrUflC0TUGAE0dXKM0RI0APgE8lDKvk4XRr5A9b/RA0fGFsLSm6PfYi+w5nEpU81uV8zAwvjDaXf76DWRB8I8ppaVFx/4U2I5soJGPAHemlN4q2l/N71SNwr/hwE0e1Xn3k93fu3ZQ/0vdfH1JqootUZK0dY3OdzcrNS3fDazg+Ij4NtkzLePIXnh6c0rpxXInjYgTyUZauwt4CRhM9vD+UuB/8od9FTgR+F1EfJOsNeJSsjBxFUBKaX1EfAW4ISJ+QvYs1iiyVq3iZ1oALicLdY9ExLVkXc52IOtKt0dK6fxKfpBiKaU/RcSdwMci4uqU0kMRcSvws4j4bv5668kGIjgeuLToN3mEbHCCo8i6CRY8SDb63csppf8t2j6F7NmlmyPiO2Td874CvEwF/5Gxyt+qnH8jG7jh/oi4Iv+ZC8lGzWs3zHpK6cWIeAL4BllQ/GnJ/mp+p2o8l59fFBE3kQXOGSml1Zv4TNVSSn/N35PXRsTeZAFzJdkzU8cAN6SUHtzUOSRpazJESdLWdUcH24cBbxStnw18jmxY6NVkI7R9fhPnnQmsIGt92pksPP0BOKbQVS2lNCMiDgeuBm4ie+5mKvC+lNKfCidKKf0oP2T6JcBZwDNkLWG3FF8wpfRyRIwlG5Xt6/nvsDB//E2bqHVzLidrcbkU+AzZb/Fp4HyyUQpXkQW231D0PFJKaUlEPEUWOotbnB4gC1Ht/ghPKT0bER8hC5D3AH8lawE7jrbnqDap0t+qg8++EhGHknWH/AHQH5gOnJBSuq/MR34KXEvWpbNcoKjod6pGPtReSRbQP04WLnen/RD0XSKl9MWIeJ4sAF9EFvLnkD23NrOrrydJnRHdNziPJKlaRS843bODASckSVKN+UyUJEmSJFXBECVJkiRJVbA7nyRJkiRVwZYoSZIkSaqCIUqSJEmSqrBNDnE+dOjQ1NzcXOsyJEmSJPVQTz311BsppWHl9m2TIaq5uZlp06bVugxJkiRJPVRE/F9H++zOJ0mSJElVMERJkiRJUhUMUZIkSZJUBUOUJEmSJFWhV4SoiDguIl6IiFkR8YVa1yNJkiSp96r7EBURDcD3gQ8A+wJnRcS+ta1KkiRJUm9V9yEKGAfMSin9b0ppNTAJOLnGNUmSJEnqpXpDiBoBzClan5vf1k5EXBAR0yJi2oIFC7ZacZIkSZJ6l94QoqLMtrTRhpSuTymNTSmNHTas7IuHJUmSJGmzekOImgvsUrQ+EnilRrVIkiRJ6uV6Q4j6A7BnROweEf2AM4F7alyTJEmSpF6qb60L6KyU0tqI+AfgN0AD8OOU0rM1Lqsizz8P8+bB0KEwbBjsuCMMGFDrqiRJkiRtSt2HKICU0q+BX9e6jmr96Efwne+037bddlmoKgSrwnLxVAhcfftCStm0fn3lyw0N2XWGDMmmwYOzbZIkSZI2r1eEqHr12c/CySfDG29k04IFbcuF6fnns/myZd1by6BBWaAqhKvikFW8bfDg7NhBg9ovdzQNGAB9ekOnUUmSJCnPEFVDI0ZkUyVWroSFC9sHrXXrsoAS0TYVr3e0vHYtLF8OS5dm07Jl5ecLFsBLL7Xftn599d9z4MBs6t8f+vVrPy+3rXQe0daaBm3Lpeuly337wvbbQ1NT+3nptgEDsmtIkiRJlTBE1YkBA6oLXd0hJVi9Gt56q+Np+fLy21esgFWrss+vWtV+efVqWLx4422F4woKIbB4uXS9eHn1amhtzcLmpvTrVz5YFYJcuXC3ueXiqdy20vPZWidJklQ/DFGqWERbANhhh1pXU5mUshC3eHE2tba2n3e0beHCtjBXHOwKy2vXdm2djY2Qy22+5azc/kGDqm+lK8wbGrIWu8K8dDLcSZIkbcwQpV4tInt2a/Dgrm3FW78e1qzZOFyVtqJtalvx9pUrs+6SxcHuxRfbgl13PxPXkYiOQ1ah5a2xccuWq/3coEHwtrdl0447ZmFekiSpFgxR0hbo06etVW5rWLsWliwp33L21lvVd3UsWL8+O3dhWreu/XpH+9asyaZCgCxdXrKk/PZVq9p/ds2aLf9NCqFqxx3bz0uX3/a2bFCUgQPbBjwpPKfnqJSSJGlLGKKkOtC3b1sg6E1SykJZR2GseHnZMli0qG1auLD9/Nln25Yr7W7Zv//G4ap4ubExC5rr1lU3Tynr8jp8eDa9/e1ty8XbhgxxUBNJkuqRIUpSzURkQaWxMety2RVSygJXIVAtWpQNeLJiRfuBTorn5Zbnz8/CW0ND1vJYbl7o6li6PSV4802YMSM7z+LF5Wvt33/jYJXLtR9Rs9wom+XmDQ3ZM3Kl75XzJd6SJHU9Q5SkXiWi7R1nzc21riazenX2yoDXX28/zZ/ffv2ZZ7KukJW+OLvSVw4UXuK9447lX+BdGKCk3FRondvSVwEUnh8stCoWJrBrpSSpfhmiJKmb9evXva8oKHSLXLx44xd2l5tmzszmS5ZUfo2I9t0dC8Fq3bqNA1LxtLlXDBT069d2/s3NCy/7rmYaNMjRJiVJXccQJUl1rtAtctiwbKrU6tVZt8fFi9t3Z6x0WrGi/UiN1UwpbdytsqP5woUwZ07b+vLl2VTty78bG9t3u9xUV83iYxoa2oLbdtu1BbNyy6XbBgzIrtu3b/t5uW0+HydJ9cMQJUnbqH79YOeds6nepJSN9lh4wXchWG1qWrWqukFCCstr17Zd49VX2863bFk2ddV74/r0aQtV/fplA8kUgnHxNHToxtu66plCSVJlDFGSpLoTkbXyDBiQPetVS6tXtw9WxfOVK7NnwgqvBuhoXrpt1aqsBW7BAnj5ZXjqqWy5o9cCDBzYFq7e9rbsZdy53MZTR9tzOZ9Lk6RqGKIkSeqEQhfFHXbo3uuklD3HtmBB9kzbggVtU/H6m29mLWZLlmTvk1u6NPvs5gwa1PFLscvNi5cbGtoPftLRVHpMnz7ZqJTveEfbc4OF5aFDfY5NUs9liJIkqQ5EZC1JTU0walTln1u/PmsVW7KkLVgVlou3LV268XvaSl+OXdi/bFn77evWtR+Ov9xUbv+6dfCHP2QjVZYGvcbGLFCVC1gjRmQjcFbycvBy+woBsJKp+NimJl8ZICljiJIkqRfr06dt2P/uGiGys9asgddeg3nz4JVXsnnx8p//DPfdl4W3Whs6FEaOzKYRI9qWi7cNGVLrKiV1N0OUJEmqqcZG2GWXbNqUpUvbAtby5W0DcZROhZdhl5si2p4/29Tw/KXTqlVZV8m5c7NpzhyYOjXrSlkql2sfqkaMyFqxCmE2lyu/PHCgozRK9cIQJUmS6sKQIfDOd2ZTT7FiRdZiNnduFu4KIauw/swz2TNqlTyX1tDQFqgK0+DBWRfC/v2rnxeG6C8Ey9Kp3Pa+fbPh+YcNy7owSirPECVJkrSFBg6Ev/mbbOpI4bm0pUuzZ9CWLt14uaN9b72VLa9cmbWGFc9XrsxaybpLLtc2jP7w4RsPrV+6zefFtC0xREmSJHWj4ufS3vGOrj33+vVt3Q1Lg1bhfWeFATVKp3Lb167Nwlvx6I+vvw6zZ2eDgCxY0PG70Ypbzfr3z1qyCsvFU7ntAwe2vai69MXVHW3v61+xqiFvP0mSpDrVp0/bO9Oamrr/eillozmWhqwFC7J3m61a1fG0YgUsXtwW+kr3rVxZXS39+mWhavvts1cMlJs62tfU5LvR1DmGKEmSJFUkIgsm228Pe+7Ztedet67txdWlL7DuaPuyZVkwe/PNbJozp225o5dTF75HU1P2cuodd2ybStdLtw0Z4uAfyhiiJEmSVHMNDdlzWLlc58+VUvY8WXHAKjctXJhNb7wBL7wAixZlLW0d6ds3C1PDh8NOO2Uviy6eircNG2ZrV29miJIkSVKvEtH27FS170dbs6Z9wFq0qG25ELhefz17SfSLL2bzcl0RI7L3ipULV8OHt5+GDctqVf0wREmSJEl5jY1t4aYSKWWDccyf3za99lr79fnzYdasLHy99Vb58wwatHGwKl4vbvEaOtRWrlozREmSJElbKKKtG2Ilz4ktX942IEdhKl2fOxf++MdsudyzXX36tLVybW7aaafseHUtQ5QkSZK0lRS6GTY3b/7YwmiI8+e3dSHsqJVr/vxslMNSgwbBfvtBS0vb9O53ZwNmaMsZoiRJkqQeqHg0xL333vSxKWWjFZZ2K5w5E2bMgMmT4YYb2o4fOTILU8Xhau+9s+6M2jxDlCRJklTnItpe6jxq1Mb7U8pC1YwZ7acpU9q6DDY2wr77ZoFq//3hkENgzJjsnVxqzxAlSZIk9XIRsPPO2XTssW3bV6/Ohnf/85/bgtUDD8BPf5rtHzgQxo+Hww6DCROyZUcShEgp1bqGrW7s2LFp2rRptS5DkiRJ6pFeew0eewwefTSbpk/PWrP69oUDD8wC1YQJcOihvff5qoh4KqU0tuw+Q5QkSZKkTWlthd//vi1UPflk1ooF2cAVhVA1YUL2vFVvYIgqYYiSJEmSttzKlVmQevRReOSRLGAtW5btu/JKuOKKmpbXJTYVohw1XpIkSVJVBgzInpP60pfgN7+BN9+EadNgt92yd1z1doYoSZIkSZ1SeFZql11gyZJaV9P9DFGSJEmSukRTkyFKkiRJkiqWyxmiJEmSJKlihihJkiRJqoIhSpIkSZKqkMvBihWwZk2tK+lehihJkiRJXSKXy+ZLl9a2ju5miJIkSZLUJQohqrd36TNESZIkSeoShihJkiRJqoIhSpIkSZKqUAhRra21raO7GaIkSZIkdYmmpmxuS5QkSZIkVcDufJIkSZJUBUOUJEmSJFVh0CDo08cQJUmSJEkVichaowxRkiRJklQhQ1QPERHfjoi/RMSMiJgcEdsX7bssImZFxAsRcWwNy5QkSZK2eYaonuN+YL+UUgvwInAZQETsC5wJvAs4DrguIhpqVqUkSZK0jTNE9RAppd+mlNbmV6cCI/PLJwOTUkqrUkovAbOAcbWoUZIkSZIhqqc6H7g3vzwCmFO0b25+20Yi4oKImBYR0xYsWNDNJUqSJEnbplwOWltrXUX36lvrAgoiYgqwU5ldX0op3Z0/5kvAWmBi4WNljk/lzp9Suh64HmDs2LFlj5EkSZLUOdtCS1SPCVEppaM3tT8iPgqcCByVUiqEoLnALkWHjQRe6Z4KJUmSJG1OU1PvD1F10Z0vIo4DLgVOSim9VbTrHuDMiOgfEbsDewJP1qJGSZIkSVlL1PLlsG5drSvpPj2mJWozrgX6A/dHBMDUlNInU0rPRsTtwHNk3fwuSin14n8uSZIkqWfL5bL50qWw/fY1LaXb1EWISimN2sS+q4Grt2I5kiRJkjpQCFFLlvTeEFUX3fkkSZIk1YfiENVbGaIkSZIkdRlDlCRJkiRVwRAlSZIkSVUwREmSJElSFQohqrW1tnV0J0OUJEmSpC5jS5QkSZIkVWG77SDCECVJkiRJFenTB4YMMURJkiRJUsVyOUOUJEmSJFXMECVJkiRJVTBESZIkSVIVDFGSJEmSVAVDlCRJkiRVwRAlSZIkSVUwREmSJElSFXI5WLoU1q+vdSXdwxAlSZIkqUs1NUFKsGxZrSvpHoYoSZIkSV0ql8vmvbVLnyFKkiRJUpcyREmSJElSFQxRkiRJklQFQ5QkSZIkVcEQJUmSJElVMERJkiRJUhUMUZIkSZJUhSFDsrkhSpIkSZIq0NAAgwdDa2utK+kehihJkiRJXS6XsyVKkiRJkirW1GSIkiRJkqSK2RIlSZIkSVUwREmSJElSFQxRkiRJklQFQ5QkSZIkVcEQJUmSJElVKISolGpdSdczREmSJEnqcrkcrF8Pb71V60q6niFKkiRJUpfL5bJ5a2tt6+gOhihJkiRJXa4Qonrjc1GGKEmSJEldrqkpmxuiJEmSJKkCtkRJkiRJUhUMUZIkSZJUBUOUJEmSJFXBECVJkiRJVRgyJJsboiRJkiSpAo2NMHCgIUqSJEmSKpbLGaIkSZIkqWKGKEmSJEmqQi4Hra21rqLrGaIkSZIkdYumJluiJEmSJKlidueTJEmSpCoYoiRJkiSpCoaoHiAiPh8RKSKGFm27LCJmRcQLEXFsLeuTJEmS1KYQolKqdSVdq2+tC6hUROwCHAO8XLRtX+BM4F3AO4ApEbFXSmldbaqUJEmSVJDLwdq1sHJl9uLd3qKeWqL+DfhnoDjHngxMSimtSim9BMwCxtWiOEmSJEnt5XLZvLd16auLEBURJwHzUkp/Ktk1AphTtD43v02SJElSjfXWENVjuvNFxBRgpzK7vgR8EXh/uY+V2Va2x2VEXABcALDrrrtuYZWSJEmSKmWI6mYppaPLbY+IdwO7A3+KCICRwNMRMY6s5WmXosNHAq90cP7rgesBxo4d28sebZMkSZJ6nkKIam2tbR1drcd350sp/TmlNDyl1JxSaiYLTmNSSq8B9wBnRkT/iNgd2BN4soblSpIkScqzJaoHSik9GxG3A88Ba4GLHJlPkiRJ6hmamrK5IarG8q1RxetXA1fXphpJkiRJHemtLVE9vjufJEmSpPo0ZEg2N0RJkiRJUgX698+m3haiNtudLyIur+J8KaX01U7UI0mSJKkXyeW2wRAFXFmyntj0+5kMUZIkSZKA3hmiNtudL6XUpzAB+wEvAV8AmoGB+fll+e3v6rZKJUmSJNWd3hiiqh2d71rghpTSt4q2vQx8MyL6AN8Hjuqq4iRJkiTVt94YoqodWOI9wLQO9v0BGN+5ciRJkiT1JrkctLbWuoquVW2IagWO6WDf+/P7JUmSJAnonS1R1Xbn+zFwWURsB9wBzAfeDpwOXAB8vWvLkyRJklTPmpoMUZeTjcJ3MfDJ/LYAlpMFqCu7qjBJkiRJ9W+bb4lKKa0HvhwR3wHeDewMvArMSCnZlU+SJElSO7kcrF4Nq1ZlL97tDSoOURHRD3gNODeldA/waLdVJUmSJKlXyOWy+ZIlMGxYbWvpKhUPLJFSWg2sBVZ2XzmSJEmSepPiENVbVDs6313A33ZDHZIkSZJ6od4YoqodWOJe4HsR8TOyQPUq2UATG6SUHuia0iRJkiTVO0MU3Jmffyg/FSSyUfoS0NAFdUmSJEnqBQxRcES3VCFJkiSpV9rmQ1RK6eHuKkSSJElS71MIUa296IVI1Q4sIUmSJEkV2+ZbogAiYj/gY8DewICS3SmldFRXFCZJkiSp/g0YAI2N23CIioj3AA8Ds4E9gRnADsCuwFxgVhfXJ0mSJKmORWStUb0pRFXbne/rwM+Bd5GNxvexlFIzcDTZqHxf69LqJEmSJNW9bT1EtQC30PZuqAbY8G6orwH/2nWlSZIkSeoNtvUQ1QgsTymtBxYBOxftewHYr6sKkyRJktQ7bOsh6q/AiPzyDOD8iOgTEX2A84DXurI4SZIkSfVvWw9RvwAOzy9/HfgAsAR4E/j/gO92WWWSJEmSeoXeFqKqfdnulUXLUyJiPPBhYBBwX0rpt11bniRJkqR6t02HqFIppT8Cf+yiWiRJkiT1QrkctLbWuoquU1V3voj4RkS8PyIGdVdBkiRJknqXXA5WroTVq2tdSdeo9pmos4H7gDcj4rGI+GpEHBkR/buhNkmSJEm9QFNTNl+6tLZ1dJWqQlRKaSTwTuAzwDzgAmAKsDgiHoyIL3d9iZIkSZLqWS6XzXvLc1HVtkSRUnoxpfTDlNIZKaW3AxOAx4D3AVd2cX2SJEmS6lxvC1FVDywREQOBQ4EjgSOAMcBbwC+BB7q0OkmSJEl1b5sOURHxCDAOWA38HpgMfBp4KqW0vuvLkyRJklTvtukQRdYCtQL4KfAb4OGUUi8arFCSJElSV9vWQ1QLbd34bgSGRMR0sm58DwKPppSWd2WBkiRJkurbNh2iUkrPAM8A34uIAA4gC1UnAp8H1gADurpISZIkSfVrmw5RBRHRCLyXrEXqSOA9QABvdl1pkiRJknqDQYOgTx9o7SUPAlU7sMQXyULTwcBAYCHwMHAJ8EBK6fkur1CSJElSXYvIWqO21ZaofwIeAb4EPJhS+lPXlyRJkiSpt2lq2nZD1I4OZS5JkiSpWttsS1QhQEXEUGA8sCPwi5TSoogYAKw2ZEmSJEkq1ZtCVJ9qDo7Mt4G5wD3Aj4Hm/O67ybr5SZIkSVI722yIAi4D/gG4irYR+Qp+QTbUuSRJkiS105tCVLXPRP09cFVK6V8joqFk3yzgb7qmLEmSJEm9SW8KUdW2RI0ApnawbzUwuHPlSJIkSeqNtuUQNQ/Yr4N9+wMvda4cSZIkSb1RLgfLl8O6dbWupPOqDVF3AJdHxCFF21JE7AV8DpjUZZVJkiRJ6jVyuWy+dGlt6+gK1YaoK4G/kL1wd2Z+2x3An8meifpGl1UmSZIkqdcohKjW1trW0RWqClEppRXA4cC5wO+BKcAfgAvIRub7VNeWJ0mSJKk3KISo3vBcVFWj8+VfsrswpfRT4Kf5bYPIwtNMYDjwH11dpCRJkqT61tSUzXtDiNpsS1RE9I+I/4iIZcB8YGFEfCq/72zgr8C3gZeB47qzWEmSJEn1qTe1RFXSne9y4NNk3fe+DdwP/EdE/CdwM9AKnJxSek9K6f7uKjQiPh0RL0TEsxHxraLtl0XErPy+Y7vr+pIkSZK2XG8KUZV05zsDuC6l9A+FDRFxPnADWaD6YEppdTfVV7jeEcDJQEtKaVVEDM9v3xc4E3gX8A5gSkTslVLqBQMnSpIkSb1HbwpRlbRE7QJMLtn28/z8u90doPI+BXwjpbQKIKX0en77ycCklNKqlNJLZCMEjtsK9UiSJEmqwrYWohqB0tHcC+sLuracDu0FTIiIJyLi4Yg4KL99BDCn6Li5+W0biYgLImJaRExbsGBrlS1JkiQJYPBgiOgdIarS0flGRMQeResNRdsXFx+YUvrfLSkkIqYAO5XZ9SWyOncAxgMHAbfn64kyx6dy508pXQ9cDzB27Niyx0iSJEnqHn36wJAh21aI+lkH2+8qs62hzLbNSikd3dG+/GiAP08pJeDJiFgPDCVredql6NCRwCtbcn1JkiRJ3SuX23ZC1HndXsXm3QUcCTwUEXsB/YA3gHuA/xcR3yUbWGJP4MlaFSlJkiSpY7kctLbWuorO22yISindtDUK2YwfAz+OiGeA1cBH861Sz0bE7cBzwFrgIkfmkyRJknqmbaklqubyIwCe3cG+q4Grt25FkiRJkqrV1ASLF9e6is6rZHQ+SZIkSeq03tISZYiSJEmStFUYoiRJkiSpCoYoSZIkSapCLgdLl8L69bWupHMMUZIkSZK2ilwumy9bVts6OssQJUmSJGmrKISoeu/SZ4iSJEmStFUYoiRJkiSpCoUQ1dpa2zo6yxAlSZIkaauwJUqSJEmSqmCIkiRJkqQqNDVlc0OUJEmSJFXAlihJkiRJqsJ222VzQ5QkSZIkVaChIQtShihJkiRJqlAuZ4iSJEmSpIoZoiRJkiSpCoYoSZIkSaqCIUqSJEmSqpDLQWtrravoHEOUJEmSpK3GlihJkiRJqkJTkyFKkiRJkipWaIlKqdaVbDlDlCRJkqStJpfLAtTy5bWuZMsZoiRJkiRtNblcNq/nLn2GKEmSJElbjSFKkiRJkqpgiJIkSZKkKhiiJEmSJKkKhihJkiRJqkIhRLW21raOzjBESZIkSdpqbImSJEmSpCoYoiRJkiSpCn37wqBBhihJkiRJqlguZ4iSJEmSpIoZoiRJkiSpCoYoSZIkSaqCIUqSJEmSqmCIkiRJkqQqGKIkSZIkqQq5HLS21rqKLWeIkiRJkrRVFVqiUqp1JVvGECVJkiRpq8rlYN06WLGi1pVsGUOUJEmSpK2qqSmb1+tzUYYoSZIkSVtVLpfNDVGSJEmSVAFDlCRJkiRVwRAlSZIkSVUwREmSJElSFQxRkiRJklQFQ5QkSZIkVWHIkGxuiJIkSZKkCvTvn02trbWuZMsYoiRJkiRtdbmcLVHdKiJGR8TUiJgeEdMiYlzRvssiYlZEvBARx9ayTkmSJEmVaWqq3xDVt9YFVOhbwFdSSvdGxPH59cMjYl/gTOBdwDuAKRGxV0ppXQ1rlSRJkrQZtkR1vwTkx/CgCXglv3wyMCmltCql9BIwCxhX5vOSJEmSepB6DlH10hJ1MfCbiLiGLPi9N799BDC16Li5+W2SJEmSerBcDl5+udZVbJkeE6IiYgqwU5ldXwKOAj6bUrozIk4HfgQcDUSZ41MH578AuABg11137ZKaJUmSJG0ZW6K6QErp6I72RcTNwGfyq3cAN+SX5wK7FB06kraufqXnvx64HmDs2LFlg5YkSZKkraOeQ1S9PBP1CvC+/PKRwMz88j3AmRHRPyJ2B/YEnqxBfZIkSZKqUM8hqse0RG3Gx4H/iIi+wEry3fJSSs9GxO3Ac8Ba4CJH5pMkSZJ6vlwOVq+GVauyF+/Wk7oIUSmlx4ADO9h3NXD11q1IkiRJUmfk8mNvt7bC8OG1raVa9dKdT5IkSVIvUghR9dilzxAlSZIkaatrasrmhihJkiRJqoAtUZIkSZJUBUOUJEmSJFXBECVJkiRJVTBESZIkSVIVDFGSJEmSVIX+/aGx0RAlSZIkSRWJyFqjDFGSJEmSVKFcDlpba11F9QxRkiRJkmrClihJkiRJqoIhSpIkSZKq0NRkiJIkSZKkitkSJUmSJElVMERJkiRJUhUMUZIkSZJUhVwOVq6E1atrXUl1DFGSJEmSaiKXy+ZLl9a2jmoZoiRJkiTVRCFE1VuXPkOUJEmSpJowREmSJElSFQohqrW1tnVUyxAlSZIkqSZsiZIkSZKkKjQ1ZXNDlCRJkiRVwJYoSZIkSaqCIUqSJEmSqjBwIDQ0GKIkSZIkqSIRWWuUIUqSJEmSKmSIkiRJkqQqGKIkSZIkqQqGKEmSJEmqQi4Hra21rqI6hihJkiRJNVOPLVF9a11AT7FmzRrmzp3LypUra12K6tSAAQMYOXIkjY2NtS5FkiSpbhii6tjcuXMZMmQIzc3NRESty1GdSSmxcOFC5s6dy+67717rciRJkupGU1P9hSi78+WtXLmSHXfc0QClLRIR7LjjjrZkSpIkVSmXg7fegrVra11J5QxRRQxQ6gzvH0mSpOrlctl86dLa1lENQ1QP0tDQwOjRozdM3/jGNzZ5/A9/+ENuvvnmTl+3ubmZN954o+LjDz/8cPbee2/2339/DjroIKZPn97pGrbElVdeyTXXXFOTa0uSJKlrFEJUPXXp85moHmTgwIFVBZJPfvKT3VfMZkycOJGxY8fyk5/8hH/6p3/i/vvv79brpZRIKdGnj7lfkiSpN6nHEOVfpHWgubmZSy+9lHHjxjFu3DhmzZoFtG+J+d73vse+++5LS0sLZ555JgCLFi3ilFNOoaWlhfHjxzNjxgwAFi5cyPvf/34OOOAAPvGJT5BS2nCtW265hXHjxjF69Gg+8YlPsG7duk3WdvDBBzNv3jwAli9fzvnnn89BBx3EAQccwN133w3A8ccfv+HaBxxwAFdddRUAX/7yl7nhhhtYtmwZRx11FGPGjOHd7373hs/Nnj2bffbZhwsvvJAxY8YwZ84crr76avbee2+OPvpoXnjhhS75fSVJklQ79RiibIkq4+KLoat7qI0eDf/+75s+ZsWKFYwePXrD+mWXXcYZZ5wBQC6X48knn+Tmm2/m4osv5pe//GW7z37jG9/gpZdeon///ixevBiAK664ggMOOIC77rqLBx54gHPOOYfp06fzla98hUMPPZTLL7+cX/3qV1x//fUAPP/889x22208/vjjNDY2cuGFFzJx4kTOOeecDmu+7777OOWUUwC4+uqrOfLII/nxj3/M4sWLGTduHEcffTSHHXYYjz76KM3NzfTt25fHH38cgMcee4yzzz6bAQMGMHnyZHK5HG+88Qbjx4/npJNOAuCFF17gJz/5Cddddx1PPfUUkyZN4o9//CNr165lzJgxHHjggZX9A0iSJKlHMkSpUzbVne+ss87aMP/sZz+70f6WlhY+8pGPcMopp2wINY899hh33nknAEceeSQLFy6ktbWVRx55hJ///OcAnHDCCeywww4A/O53v+Opp57ioIMOArJQN3z48LL1fOQjH2H58uWsW7eOp59+GoDf/va33HPPPRtax1auXMnLL7/MhAkT+N73vsfuu+/OCSecwP33389bb73F7Nmz2XvvvVmzZg1f/OIXeeSRR+jTpw/z5s1j/vz5AOy2226MHz8egEcffZRTTz2VQYMGAWwIWpIkSapfhRDV2lrbOqphiCpjcy1GtVA88lu5UeB+9atf8cgjj3DPPffw1a9+lWeffbZdN73Sz5Y7R0qJj370o/zrv/7rZuuZOHEi+++/P1/4whe46KKL+PnPf05KiTvvvJO999673bGrV69m2rRp7LHHHhxzzDG88cYb/Pd///eGVqSJEyeyYMECnnrqKRobG2lubt4wVPjgwYM7/B0kSZJU/+qxJcpnourEbbfdtmF+8MEHt9u3fv165syZwxFHHMG3vvUtFi9ezLJlyzjssMOYOHEiAA899BBDhw4ll8u1237vvffy5ptvAnDUUUfxs5/9jNdffx3Inqn6v//7vw5ramxs5Gtf+xpTp07l+eef59hjj+U///M/N4S3P/7xjwD069ePXXbZhdtvv53x48czYcIErrnmGiZMmABAa2srw4cPp7GxkQcffLDDax522GFMnjyZFStWsHTpUn7xi19s0W8pSZKknqMeQ5QtUT1I6TNRxx133IZhzletWsV73vMe1q9fz6233truc+vWrePss8+mtbWVlBKf/exn2X777bnyyis577zzaGlpYdCgQdx0001A9qzUWWedxZgxY3jf+97HrrvuCsC+++7L1772Nd7//vezfv16Ghsb+f73v89uu+3WYc0DBw7kc5/7HNdccw3XXnstF198MS0tLaSUaG5u3vDs1oQJE/jd737HoEGDmDBhAnPnzt0Qoj7ykY/wwQ9+kLFjxzJ69Gje+c53lr3WmDFjOOOMMxg9ejS77bbbhs9LkiSpfm23HUTUV4iKcl2+eruxY8emadOmtdv2/PPPs88++9Sook1rbm5m2rRpDB06tNalaDN68n0kSZLUU22/PZx7bs96rCYinkopjS23z+58kiRJkmoql6uvlii789WB2bNn17oESZIkqdvUW4iyJUqSJElSTRmiJEmSJKkKhihJkiRJqoIhSpIkSZKqYIjSFosI/u7v/m7D+tq1axk2bBgnnnjiFp3vhz/8ITfffHNXlceCBQtobGzkv/7rv7rsnN3p4osv5pFHHgHg2muvZdSoUUQEb7zxxoZjUkr84z/+I6NGjaKlpYWnn356w7777ruPvffem1GjRm14XxfA5z//eR544IGt90UkSZJ6uVwOWltrXUXlekyIiojTIuLZiFgfEWNL9l0WEbMi4oWIOLZo+4ER8ef8vu9FRGz9yrvO4MGDeeaZZ1ixYgUA999/PyNGjNji833yk5/knHPO6aryuOOOOxg/fvxGL/vdUmvXru2S85SzaNEipk6dymGHHQbAIYccwpQpUzZ6cfC9997LzJkzmTlzJtdffz2f+tSngOwFxhdddBH33nsvzz33HLfeeivPPfccAJ/+9KfbhSpJkiR1Ti4Hy5bBunW1rqQyPSZEAc8AHwIeKd4YEfsCZwLvAo4DrouIhvzuHwAXAHvmp+O2WrXd5AMf+AC/+tWvALj11ls566yzNuxbtGgRp5xyCi0tLYwfP54ZM2awfv16mpubWbx48YbjRo0axfz587nyyiu55pprADj88MO59NJLGTduHHvttRePPvooAG+99Rann346LS0tnHHGGbznPe+h9EXEBbfeeivf+c53mDt3LvPmzaO1tZXm5mbWr1+/4Vy77LILa9as4a9//SvHHXccBx54IBMmTOAvf/kLAOeeey6XXHIJRxxxBJdeeilPPvkk733veznggAN473vfywsvvLDZun77299y8MEHM2bMGE477TSWLVu2Ua0/+9nPOO64ttvhgAMOoLm5eaPj7r77bs455xwigvHjx7N48WJeffVVnnzySUaNGsUee+xBv379OPPMM7n77rsB2G233Vi4cCGvvfba5v9BJUmStFlNTdm8zJ91PVKPeU9USul5yLq0lTgZmJRSWgW8FBGzgHERMRvIpZT+J/+5m4FTgHs7XczFF8P06Z0+TTujR1f0CuYzzzyTq666ihNPPJEZM2Zw/vnnbwg8V1xxBQcccAB33XUXDzzwAOeccw7Tp0/n5JNPZvLkyZx33nk88cQTNDc38/a3v32jc69du5Ynn3ySX//613zlK19hypQpXHfddeywww7MmDGDZ555htGjR5eta86cObz22muMGzeO008/ndtuu41LLrmE/fffn4cffpgjjjiCX/ziFxx77LE0NjZywQUX8MMf/pA999yTJ554ggsvvHBDF7gXX3yRKVOm0NDQwJIlS3jkkUfo27cvU6ZM4Ytf/CJ33nlnh3W98cYbfO1rX2PKlCkMHjyYb37zm3z3u9/l8ssvb1fv448/zt/+7d9u9veeN28eu+yyy4b1kSNHMm/evLLbn3jiiQ3rY8aM4fHHH+fDH/7wZq8hSZKkTcvlsvmSJW2BqifrMSFqE0YAU4vW5+a3rckvl24vKyIuIGu1Ytddd+36KrtIS0sLs2fP5tZbb+X4449vt++xxx7jzjvvBODII49k4cKFtLa2csYZZ3DVVVdx3nnnMWnSJM4444yy5/7Qhz4EwIEHHrjhBb6PPfYYn/nMZwDYb7/9aGlpKfvZSZMmcfrppwNZ0PvYxz7GJZdcwhlnnMFtt93GEUccwaRJk7jwwgtZtmwZv//97znttNM2fH7VqlUblk877TQaGrLGxNbWVj760Y8yc+ZMIoI1a9Zssq6pU6fy3HPPccghhwCwevVqDj744I3qffXVVxk2bFjZ71IspbTRtojocHvB8OHDeeWVVzZ7fkmSJG3e7rvDscdu/rieYquGqIiYAuxUZteXUkp3d/SxMtvSJraXlVK6HrgeYOzYsR0eB1TUYtSdTjrpJD7/+c/z0EMPsXDhwg3bO/rD/uCDD2bWrFksWLCAu+66i3/5l38pe97+/fsD0NDQsOF5pHLnLOfWW29l/vz5TJw4EYBXXnmFmTNnctJJJ3HZZZexaNEinnrqKY488kiWL1/O9ttvz/QOWvMGDx68YfnLX/4yRxxxBJMnT2b27Nkcfvjhm6wrpcQxxxyz2eeyBg4cyMqVKzf7vUaOHMmcOXM2rM+dO5d3vOMdrF69uuz2gpUrVzJw4MDNnl+SJEmbd+SR2VQvtuozUSmlo1NK+5WZOgpQkLUw7VK0PhJ4Jb99ZJntde/888/n8ssv593vfne77YcddtiGEPPQQw8xdOhQcrkcEcGpp57KJZdcwj777MOOO+5Y8bUOPfRQbr/9dgCee+45/vznP290zAsvvMDy5cuZN28es2fPZvbs2Vx22WVMmjSJ7bbbjnHjxvGZz3yGE088kYaGBnK5HLvvvjt33HEHkAWfP/3pT2Wv39raumHwjBtvvHGzdY0fP57HH3+cWbNmAdmzUy+++OJG591nn302HLMpJ510EjfffDMpJaZOnUpTUxM777wzBx10EDNnzuSll15i9erVTJo0iZNOOmnD51588UX222+/zZ5fkiRJvU9PGliiI/cAZ0ZE/4jYnWwAiSdTSq8CSyNifH5UvnOATYWxujFy5MgNXdmKXXnllUybNo2Wlha+8IUvcNNNN23Yd8YZZ3DLLbd02JWvIxdeeCELFiygpaWFb37zm7S0tNBU0hH11ltv5dRTT2237cMf/vCG1qBy1544cSI/+tGP2H///XnXu961YVCGUv/8z//MZZddxiGHHMK6ouFYOqpr2LBh3HjjjZx11lkbBtgoDFpR7IQTTuChhx7asP69732PkSNHMnfuXFpaWvj7v/97AI4//nj22GMPRo0axcc//nGuu+46APr27cu1117Lscceyz777MPpp5/Ou971LgDWrFnDrFmzGDt27EbXlSRJUu8XlXbn6m4RcSrwn8AwYDEwPaV0bH7fl4DzgbXAxSmle/PbxwI3AgPJBpT4dKrgC40dOzaVjkD3/PPPs88++3TV16kb69atY82aNQwYMIC//vWvHHXUUbz44ov069ev7us69NBD+eUvf8n222/fpbVNnjyZp59+mq9+9asb7dtW7yNJkqTeJiKeSimV/a/mPWZgiZTSZGByB/uuBq4us30aYJ+qTnjrrbc44ogjWLNmDSklfvCDH9Q8QHVVXd/5znd4+eWXuzxErV27ls997nNdek5JkiTVjx4TolQbQ4YM6fC9ULXUFXW95z3v6aJq2isedVCSJEnbnnp4JkqSJEmSegxDVJGe8nyY6pP3jyRJ0rbBEJU3YMAAFi5c6B/C2iIpJRYuXMiAAQNqXYokSZK6mc9E5RWGv16wYEGtS1GdGjBgACNHjtz8gZIkSaprhqi8xsZGdt9991qXIUmSJKmHszufJEmSJFXBECVJkiRJVTBESZIkSVIVYlscjS4iFgD/18WnHQq80cXn1LbFe0id5T2kzvIeUmd4/6izeto9tFtKaVi5HdtkiOoOETEtpTS21nWofnkPqbO8h9RZ3kPqDO8fdVY93UN255MkSZKkKhiiJEmSJKkKhqiuc32tC1Dd8x5SZ3kPqbO8h9QZ3j/qrLq5h3wmSpIkSZKqYEuUJEmSJFXBENVJEXFcRLwQEbMi4gu1rkc9X0T8OCJej4hnira9LSLuj4iZ+fkOtaxRPVtE7BIRD0bE8xHxbER8Jr/d+0gViYgBEfFkRPwpfw99Jb/de0hViYiGiPhjRPwyv+49pIpFxOyI+HNETI+IafltdXEPGaI6ISIagO8DHwD2Bc6KiH1rW5XqwI3AcSXbvgD8LqW0J/C7/LrUkbXA51JK+wDjgYvy/9vjfaRKrQKOTCntD4wGjouI8XgPqXqfAZ4vWvceUrWOSCmNLhravC7uIUNU54wDZqWU/jeltBqYBJxc45rUw6WUHgEWlWw+Gbgpv3wTcMrWrEn1JaX0akrp6fzyUrI/YEbgfaQKpcyy/Gpjfkp4D6kKETESOAG4oWiz95A6qy7uIUNU54wA5hStz81vk6r19pTSq5D9gQwMr3E9qhMR0QwcADyB95GqkO+GNR14Hbg/peQ9pGr9O/DPwPqibd5DqkYCfhsRT0XEBfltdXEP9a11AXUuymxzuENJW0VEbAfcCVycUloSUe5/kqTyUkrrgNERsT0wOSL2q3FJqiMRcSLwekrpqYg4vMblqH4dklJ6JSKGA/dHxF9qXVClbInqnLnALkXrI4FXalSL6tv8iNgZID9/vcb1qIeLiEayADUxpfTz/GbvI1UtpbQYeIjsWU3vIVXqEOCkiJhN9jjDkRFxC95DqkJK6ZX8/HVgMtmjMnVxDxmiOucPwJ4RsXtE9APOBO6pcU2qT/cAH80vfxS4u4a1qIeLrMnpR8DzKaXvFu3yPlJFImJYvgWKiBgIHA38Be8hVSildFlKaWRKqZns758HUkpn4z2kCkXE4IgYUlgG3g88Q53cQ75st5Mi4niyPsENwI9TSlfXtiL1dBFxK3A4MBSYD1wB3AXcDuwKvAycllIqHXxCAiAiDgUeBf5M27MIXyR7Lsr7SJsVES1kD2w3kP0H1dtTSldFxI54D6lK+e58n08pneg9pEpFxB5krU+QPWL0/1JKV9fLPWSIkiRJkqQq2J1PkiRJkqpgiJIkSZKkKhiiJEmSJKkKhihJkiRJqoIhSpIkSZKqYIiSJPUYEXFuRKQOpsVVnqs5/7lzu6fastecHRE3bq3rSZJqo2+tC5AkqYzTgLkl29ZWeY5XgYOBv3ZJRZIk5RmiJEk90fSU0qzOnCCltAqY2kX1SJK0gd35JEl1pajL32ERcVdELIuIhRHx/YgYWHTcRt35IuKgiLg/f/xbEfG/EXFdyfnHRcSU/HmXR8TvImJcmTo+k+++tzIipkXEhA7q3T0iJkbEgohYFRHTI+LULvxJJElbmSFKktQTNURE35Kp9P9n3QLMAj4E/BvwceAHHZ0wIrYDfgOsA84FjgeuoqhXRkS0AA8DO+SPOQfIAQ9HxP5Fx30M+HfgQeAU4Ebg1vzniq+5C/AEsD/wWeAk4Gngzog4qcLfQpLUw9idT5LUE/2lzLZfAScWrf86pfT5/PJvIyIBV0XE11NKL5b5/DvJQs4/p5RmFG2/sWj5cmAVcFRKaTFARNwPzAauAD6UD3NXAr9JKZ1X+GBELAAmlVzzSiCA96WUFua3/SYfrq4C7ilTpySph7MlSpLUE50KHFQyXVxyzO0l65PI/v/aRl3v8mYCi4H/ioiz80Gm1GHALwsBCiCltIQs7Lwvv2lkfiq9/p1sPPjFccCvgdbiVjWyFrH9IyLXQa2SpB7MlihJUk/0TAUDS8zvYH1EuYNTSq0RcQTwZeA6YEhEPAtckVK6M3/Y28hG9Sv1Gm1d9XYud/2U0tqIWEh7w8m6BJ7TwXfYEVjSwT5JUg9liJIk1au3A8+WrAPM6+gDKaXpwIfzrUFjgcuA2yNi/5TSM8AiYKcyH90pvw/aQtbbiw/In3PHks8tBB4FvtlBSa90VKskqeeyO58kqV6dXrJ+JrAeeHJzH0wprU0pTSVrleoD7JPf9TBwQkQMKRybX/5gfh9k76+aU+b6H2bj/zh5H9ACPJtSmlZmWrW5WiVJPY8tUZKknmh0RAwts31a0fLxEfFt4Ldkz0FdAdzcwaASRMSJwAXAXcBLwGDgH4GlwP/kD/sq2eAVv4uIbwIJuBQYRDYQBCml9RHxFeCGiPgJ2bNYo8hatUq75l1OFuoeiYhryQao2AHYD9gjpXR+JT+GJKlnMURJknqiOzrYPqxo+Wzgc8CngNXAfwOfL/ehvJnACrLWp53JwtMfgGNSSnMBUkozIuJw4GrgJrKR9aaSja73p8KJUko/yg+ZfglwFvAMWUvYLcUXTCm9HBFjyUbp+3q+/oX542/aRK2SpB4sUkq1rkGSpIrlX577E2DPCgafkCSpy/lMlCRJkiRVwRAlSZIkSVWwO58kSZIkVcGWKEmSJEmqgiFKkiRJkqpgiJIkSZKkKhiiJEmSJKkKhihJkiRJqoIhSpIkSZKq8P8DsdRY/KaYbxsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1008x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(len(history))\n",
    "reward_per_episode = [history[count][\"reward\"] for count,h in enumerate(history)]\n",
    "fig, ax = plt.subplots(1, 1, figsize=(14, 6))\n",
    "ax.plot(range(1, len(reward_per_episode) + 1), reward_per_episode, 'b', label='Episode Reward')\n",
    "ax.plot(range(1, len(reward_per_episode) - 99 + 1), moving_average(reward_per_episode, 100), 'r', label='Moving Average (100)')\n",
    "# ax[0].plot(epochs, val_accuracy, 'b', label='Validation accuracy')\n",
    "ax.set_title('Episode Reward over time', fontsize=16)\n",
    "ax.set_xlabel('Episode', fontsize=16)\n",
    "ax.set_ylabel('Reward', fontsize=16)\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2697c970",
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(a, n=3) :\n",
    "    ret = np.cumsum(a, dtype=float)\n",
    "    ret[n:] = ret[n:] - ret[:-n]\n",
    "    return ret[n - 1:] / n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0270f0a",
   "metadata": {},
   "source": [
    "## DQN\n",
    "https://github.com/fakemonk1/Reinforcement-Learning-Lunar_Lander/blob/master/Lunar_Lander.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09737bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import random\n",
    "from collections import deque\n",
    "\n",
    "class DQN:\n",
    "    def __init__(self, env, lr, gamma, epsilon, epsilon_decay):\n",
    "\n",
    "        self.env = env\n",
    "        self.action_space = env.action_space\n",
    "        self.observation_space = env.observation_space\n",
    "        self.counter = 0\n",
    "\n",
    "        self.lr = lr\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.rewards_list = []\n",
    "\n",
    "        self.replay_memory_buffer = deque(maxlen=500000)\n",
    "        self.batch_size = 64\n",
    "        self.epsilon_min = 0.01\n",
    "        self.num_action_space = self.action_space.n\n",
    "        self.num_observation_space = env.observation_space.shape[0]\n",
    "        self.model = self.initialize_model()\n",
    "\n",
    "    def initialize_model(self):\n",
    "        model = keras.Sequential()\n",
    "        model.add(keras.layers.Dense(512, input_dim=self.num_observation_space, activation=keras.layers.Activation('relu')))\n",
    "        model.add(keras.layers.Dense(256, activation=keras.layers.Activation('relu')))\n",
    "        model.add(keras.layers.Dense(self.num_action_space, activation=keras.layers.Activation('linear')))\n",
    "\n",
    "        # Compile the model\n",
    "        model.compile(loss=keras.losses.MeanSquaredError(),optimizer=keras.optimizers.Adam(lr=self.lr))\n",
    "        print(model.summary())\n",
    "        return model\n",
    "\n",
    "    def get_action(self, state):\n",
    "        if np.random.rand() < self.epsilon:\n",
    "            return random.randrange(self.num_action_space)\n",
    "\n",
    "        predicted_actions = self.model.predict(state)\n",
    "        return np.argmax(predicted_actions[0])\n",
    "\n",
    "    def add_to_replay_memory(self, state, action, reward, next_state, done):\n",
    "        self.replay_memory_buffer.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def learn_and_update_weights_by_reply(self):\n",
    "\n",
    "        # replay_memory_buffer size check\n",
    "        if len(self.replay_memory_buffer) < self.batch_size or self.counter != 0:\n",
    "            return\n",
    "\n",
    "        # Early Stopping\n",
    "        if np.mean(self.rewards_list[-10:]) > 180:\n",
    "            return\n",
    "\n",
    "        random_sample = self.get_random_sample_from_replay_mem()\n",
    "        states, actions, rewards, next_states, done_list = self.get_attribues_from_sample(random_sample)\n",
    "        targets = rewards + self.gamma * (np.amax(self.model.predict_on_batch(next_states), axis=1)) * (1 - done_list)\n",
    "        target_vec = self.model.predict_on_batch(states)\n",
    "        indexes = np.array([i for i in range(self.batch_size)])\n",
    "        target_vec[[indexes], [actions]] = targets\n",
    "\n",
    "        self.model.fit(states, target_vec, epochs=1, verbose=0)\n",
    "\n",
    "    def get_attribues_from_sample(self, random_sample):\n",
    "        states = np.array([i[0] for i in random_sample])\n",
    "        actions = np.array([i[1] for i in random_sample])\n",
    "        rewards = np.array([i[2] for i in random_sample])\n",
    "        next_states = np.array([i[3] for i in random_sample])\n",
    "        done_list = np.array([i[4] for i in random_sample])\n",
    "        states = np.squeeze(states)\n",
    "        next_states = np.squeeze(next_states)\n",
    "        return np.squeeze(states), actions, rewards, next_states, done_list\n",
    "\n",
    "    def get_random_sample_from_replay_mem(self):\n",
    "        random_sample = random.sample(self.replay_memory_buffer, self.batch_size)\n",
    "        return random_sample\n",
    "\n",
    "    def train(self, num_episodes=2000, can_stop=True):\n",
    "        for episode in range(num_episodes):\n",
    "            state = env.reset()\n",
    "            reward_for_episode = 0\n",
    "            num_steps = 1000\n",
    "            state = np.reshape(state, [1, self.num_observation_space])\n",
    "            for step in range(num_steps):\n",
    "                env.render()\n",
    "                received_action = self.get_action(state)\n",
    "                #print(\"received_action:\", received_action)\n",
    "                next_state, reward, done, info = env.step(received_action)\n",
    "                next_state = np.reshape(next_state, [1, self.num_observation_space])\n",
    "                # Store the experience in replay memory\n",
    "                self.add_to_replay_memory(state, received_action, reward, next_state, done)\n",
    "                # add up rewards\n",
    "                reward_for_episode += reward\n",
    "                state = next_state\n",
    "                self.update_counter()\n",
    "                self.learn_and_update_weights_by_reply()\n",
    "\n",
    "                if done:\n",
    "                    break\n",
    "            self.rewards_list.append(reward_for_episode)\n",
    "\n",
    "            # Decay the epsilon after each experience completion\n",
    "            if self.epsilon > self.epsilon_min:\n",
    "                self.epsilon *= self.epsilon_decay\n",
    "\n",
    "            # Check for breaking condition\n",
    "            last_rewards_mean = np.mean(self.rewards_list[-100:])\n",
    "            if last_rewards_mean > 200 and can_stop:\n",
    "                print(\"DQN Training Complete...\")\n",
    "                break\n",
    "            print(episode, \"\\t: Episode || Reward: \",reward_for_episode, \"\\t|| Average Reward: \",last_rewards_mean, \"\\t epsilon: \", self.epsilon )\n",
    "\n",
    "    def update_counter(self):\n",
    "        self.counter += 1\n",
    "        step_size = 5\n",
    "        self.counter = self.counter % step_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fe620e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_already_trained_model(trained_model):\n",
    "    rewards_list = []\n",
    "    num_test_episode = 100\n",
    "    env = gym.make(\"LunarLander-v2\")\n",
    "    print(\"Starting Testing of the trained model...\")\n",
    "\n",
    "    step_count = 1000\n",
    "\n",
    "    for test_episode in range(num_test_episode):\n",
    "        current_state = env.reset()\n",
    "        num_observation_space = env.observation_space.shape[0]\n",
    "        current_state = np.reshape(current_state, [1, num_observation_space])\n",
    "        reward_for_episode = 0\n",
    "        for step in range(step_count):\n",
    "            env.render()\n",
    "            selected_action = np.argmax(trained_model.predict(current_state)[0])\n",
    "            new_state, reward, done, info = env.step(selected_action)\n",
    "            new_state = np.reshape(new_state, [1, num_observation_space])\n",
    "            current_state = new_state\n",
    "            reward_for_episode += reward\n",
    "            if done:\n",
    "                break\n",
    "        rewards_list.append(reward_for_episode)\n",
    "        print(test_episode, \"\\t: Episode || Reward: \", reward_for_episode)\n",
    "\n",
    "    return rewards_list\n",
    "\n",
    "\n",
    "def plot_df(df, chart_name, title, x_axis_label, y_axis_label):\n",
    "    plt.rcParams.update({'font.size': 17})\n",
    "    df['rolling_mean'] = df[df.columns[0]].rolling(100).mean()\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    plt.close()\n",
    "    plt.figure()\n",
    "    # plot = df.plot(linewidth=1.5, figsize=(15, 8), title=title)\n",
    "    plot = df.plot(linewidth=1.5, figsize=(15, 8))\n",
    "    plot.set_xlabel(x_axis_label)\n",
    "    plot.set_ylabel(y_axis_label)\n",
    "    # plt.ylim((-400, 300))\n",
    "    fig = plot.get_figure()\n",
    "    plt.legend().set_visible(False)\n",
    "    fig.savefig(chart_name)\n",
    "\n",
    "\n",
    "def plot_df2(df, chart_name, title, x_axis_label, y_axis_label):\n",
    "    df['mean'] = df[df.columns[0]].mean()\n",
    "    plt.rcParams.update({'font.size': 17})\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    plt.close()\n",
    "    plt.figure()\n",
    "    # plot = df.plot(linewidth=1.5, figsize=(15, 8), title=title)\n",
    "    plot = df.plot(linewidth=1.5, figsize=(15, 8))\n",
    "    plot.set_xlabel(x_axis_label)\n",
    "    plot.set_ylabel(y_axis_label)\n",
    "    plt.ylim((0, 300))\n",
    "    plt.xlim((0, 100))\n",
    "    plt.legend().set_visible(False)\n",
    "    fig = plot.get_figure()\n",
    "    fig.savefig(chart_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7671ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 512)               4608      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 1028      \n",
      "=================================================================\n",
      "Total params: 136,964\n",
      "Trainable params: 136,964\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\larsh\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3419: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\larsh\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:188: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \t: Episode || Reward:  -444.4426211924587 \t|| Average Reward:  -444.4426211924587 \t epsilon:  0.995\n",
      "1 \t: Episode || Reward:  -111.20663665344993 \t|| Average Reward:  -277.82462892295433 \t epsilon:  0.990025\n",
      "2 \t: Episode || Reward:  -98.59437587064873 \t|| Average Reward:  -218.08121123885246 \t epsilon:  0.985074875\n",
      "3 \t: Episode || Reward:  -361.4966790443282 \t|| Average Reward:  -253.9350781902214 \t epsilon:  0.9801495006250001\n",
      "4 \t: Episode || Reward:  -57.54297790829867 \t|| Average Reward:  -214.65665813383686 \t epsilon:  0.9752487531218751\n",
      "5 \t: Episode || Reward:  -163.22106582619364 \t|| Average Reward:  -206.0840594158963 \t epsilon:  0.9703725093562657\n",
      "6 \t: Episode || Reward:  -147.00768031277073 \t|| Average Reward:  -197.64457668687834 \t epsilon:  0.9655206468094844\n",
      "7 \t: Episode || Reward:  -130.01220513543603 \t|| Average Reward:  -189.19053024294809 \t epsilon:  0.960693043575437\n",
      "8 \t: Episode || Reward:  -107.10414043835323 \t|| Average Reward:  -180.06982026465977 \t epsilon:  0.9558895783575597\n",
      "9 \t: Episode || Reward:  -56.565957710007396 \t|| Average Reward:  -167.71943400919452 \t epsilon:  0.9511101304657719\n",
      "10 \t: Episode || Reward:  -112.90049101538524 \t|| Average Reward:  -162.73589373703004 \t epsilon:  0.946354579813443\n",
      "11 \t: Episode || Reward:  -133.03822921883125 \t|| Average Reward:  -160.26108836051347 \t epsilon:  0.9416228069143757\n",
      "12 \t: Episode || Reward:  -112.42036161974944 \t|| Average Reward:  -156.58103245737777 \t epsilon:  0.9369146928798039\n",
      "13 \t: Episode || Reward:  -247.06528529962117 \t|| Average Reward:  -163.04419337468087 \t epsilon:  0.9322301194154049\n",
      "14 \t: Episode || Reward:  -95.64453768446626 \t|| Average Reward:  -158.55088299533324 \t epsilon:  0.9275689688183278\n",
      "15 \t: Episode || Reward:  -119.48587501964803 \t|| Average Reward:  -156.10931999685292 \t epsilon:  0.9229311239742362\n",
      "16 \t: Episode || Reward:  -147.33345011611982 \t|| Average Reward:  -155.5930923568098 \t epsilon:  0.918316468354365\n",
      "17 \t: Episode || Reward:  -131.06451939537274 \t|| Average Reward:  -154.2303938589522 \t epsilon:  0.9137248860125932\n",
      "18 \t: Episode || Reward:  -87.60186136567927 \t|| Average Reward:  -150.7236289908852 \t epsilon:  0.9091562615825302\n",
      "19 \t: Episode || Reward:  -332.62407049850515 \t|| Average Reward:  -159.8186510662662 \t epsilon:  0.9046104802746175\n",
      "20 \t: Episode || Reward:  -101.27543525313482 \t|| Average Reward:  -157.0308788846885 \t epsilon:  0.9000874278732445\n",
      "21 \t: Episode || Reward:  -95.80213664224021 \t|| Average Reward:  -154.2477542373045 \t epsilon:  0.8955869907338783\n",
      "22 \t: Episode || Reward:  -139.2048080336815 \t|| Average Reward:  -153.59371309801654 \t epsilon:  0.8911090557802088\n",
      "23 \t: Episode || Reward:  -67.6770087775169 \t|| Average Reward:  -150.0138504179957 \t epsilon:  0.8866535105013078\n",
      "24 \t: Episode || Reward:  -83.13019976664212 \t|| Average Reward:  -147.33850439194154 \t epsilon:  0.8822202429488013\n",
      "25 \t: Episode || Reward:  -195.71164472502784 \t|| Average Reward:  -149.19900978936795 \t epsilon:  0.8778091417340573\n",
      "26 \t: Episode || Reward:  -158.96556461754807 \t|| Average Reward:  -149.5607340422635 \t epsilon:  0.8734200960253871\n",
      "27 \t: Episode || Reward:  -95.81557507906507 \t|| Average Reward:  -147.6412640792921 \t epsilon:  0.8690529955452602\n",
      "28 \t: Episode || Reward:  -117.92934421759558 \t|| Average Reward:  -146.61671511854396 \t epsilon:  0.8647077305675338\n",
      "29 \t: Episode || Reward:  -235.8311960176847 \t|| Average Reward:  -149.5905311485153 \t epsilon:  0.8603841919146962\n",
      "30 \t: Episode || Reward:  -68.41897039912789 \t|| Average Reward:  -146.9720937049867 \t epsilon:  0.8560822709551227\n",
      "31 \t: Episode || Reward:  -114.50551186671525 \t|| Average Reward:  -145.95751302254075 \t epsilon:  0.851801859600347\n",
      "32 \t: Episode || Reward:  -64.54040674836318 \t|| Average Reward:  -143.49032798392932 \t epsilon:  0.8475428503023453\n",
      "33 \t: Episode || Reward:  -71.7802210757261 \t|| Average Reward:  -141.38120719251157 \t epsilon:  0.8433051360508336\n",
      "34 \t: Episode || Reward:  -91.0045749757781 \t|| Average Reward:  -139.94187484346205 \t epsilon:  0.8390886103705794\n",
      "35 \t: Episode || Reward:  -152.26956720256214 \t|| Average Reward:  -140.28431074232594 \t epsilon:  0.8348931673187264\n",
      "36 \t: Episode || Reward:  -246.38809266112835 \t|| Average Reward:  -143.1519805239152 \t epsilon:  0.8307187014821328\n",
      "37 \t: Episode || Reward:  -100.03307581883064 \t|| Average Reward:  -142.01727250536035 \t epsilon:  0.8265651079747222\n",
      "38 \t: Episode || Reward:  -92.56893919027996 \t|| Average Reward:  -140.74936652292237 \t epsilon:  0.8224322824348486\n",
      "39 \t: Episode || Reward:  -153.3935476918806 \t|| Average Reward:  -141.0654710521463 \t epsilon:  0.8183201210226743\n",
      "40 \t: Episode || Reward:  -65.09262992411429 \t|| Average Reward:  -139.21247492707238 \t epsilon:  0.8142285204175609\n",
      "41 \t: Episode || Reward:  -130.5605465814948 \t|| Average Reward:  -139.00647663313006 \t epsilon:  0.810157377815473\n",
      "42 \t: Episode || Reward:  -130.02010582009393 \t|| Average Reward:  -138.79749126538502 \t epsilon:  0.8061065909263957\n",
      "43 \t: Episode || Reward:  -139.85888975539353 \t|| Average Reward:  -138.82161395833975 \t epsilon:  0.8020760579717637\n",
      "44 \t: Episode || Reward:  -84.26479298041424 \t|| Average Reward:  -137.60924015883032 \t epsilon:  0.798065677681905\n",
      "45 \t: Episode || Reward:  -141.02583290665996 \t|| Average Reward:  -137.6835139142179 \t epsilon:  0.7940753492934954\n",
      "46 \t: Episode || Reward:  -59.1285564001202 \t|| Average Reward:  -136.01213183944986 \t epsilon:  0.7901049725470279\n",
      "47 \t: Episode || Reward:  -40.92522071519984 \t|| Average Reward:  -134.0311545243613 \t epsilon:  0.7861544476842928\n",
      "48 \t: Episode || Reward:  -230.38972899032817 \t|| Average Reward:  -135.99765604407492 \t epsilon:  0.7822236754458713\n",
      "49 \t: Episode || Reward:  -38.39878500675344 \t|| Average Reward:  -134.04567862332848 \t epsilon:  0.778312557068642\n",
      "50 \t: Episode || Reward:  -81.03532052736293 \t|| Average Reward:  -133.0062598371331 \t epsilon:  0.7744209942832988\n",
      "51 \t: Episode || Reward:  -58.425169081727915 \t|| Average Reward:  -131.57200809183684 \t epsilon:  0.7705488893118823\n",
      "52 \t: Episode || Reward:  -144.565875152483 \t|| Average Reward:  -131.81717539486792 \t epsilon:  0.7666961448653229\n",
      "53 \t: Episode || Reward:  -100.08561929769037 \t|| Average Reward:  -131.22955398566094 \t epsilon:  0.7628626641409962\n",
      "54 \t: Episode || Reward:  -75.26533161954039 \t|| Average Reward:  -130.21202266991327 \t epsilon:  0.7590483508202912\n",
      "55 \t: Episode || Reward:  -80.94812140154139 \t|| Average Reward:  -129.33231014726377 \t epsilon:  0.7552531090661897\n",
      "56 \t: Episode || Reward:  -72.26849056185196 \t|| Average Reward:  -128.33119050541444 \t epsilon:  0.7514768435208588\n",
      "57 \t: Episode || Reward:  -118.3659774614959 \t|| Average Reward:  -128.15937648741584 \t epsilon:  0.7477194593032545\n",
      "58 \t: Episode || Reward:  -89.0771725609487 \t|| Average Reward:  -127.49696625137402 \t epsilon:  0.7439808620067382\n",
      "59 \t: Episode || Reward:  -96.66173384583075 \t|| Average Reward:  -126.98304571128163 \t epsilon:  0.7402609576967045\n",
      "60 \t: Episode || Reward:  -75.76954109529817 \t|| Average Reward:  -126.14348006183928 \t epsilon:  0.736559652908221\n",
      "61 \t: Episode || Reward:  -89.57180867469697 \t|| Average Reward:  -125.55361439430473 \t epsilon:  0.7328768546436799\n",
      "62 \t: Episode || Reward:  -111.09247436405938 \t|| Average Reward:  -125.32407248906274 \t epsilon:  0.7292124703704616\n",
      "63 \t: Episode || Reward:  -172.00176913787507 \t|| Average Reward:  -126.05341149920044 \t epsilon:  0.7255664080186093\n",
      "64 \t: Episode || Reward:  -48.97687966523008 \t|| Average Reward:  -124.86761870175474 \t epsilon:  0.7219385759785162\n",
      "65 \t: Episode || Reward:  -96.05170825358229 \t|| Average Reward:  -124.43101399799454 \t epsilon:  0.7183288830986236\n",
      "66 \t: Episode || Reward:  -114.62885720527694 \t|| Average Reward:  -124.28471315034203 \t epsilon:  0.7147372386831305\n",
      "67 \t: Episode || Reward:  -132.54004222757408 \t|| Average Reward:  -124.40611504853662 \t epsilon:  0.7111635524897149\n",
      "68 \t: Episode || Reward:  -20.256047761249306 \t|| Average Reward:  -122.89669378350347 \t epsilon:  0.7076077347272662\n",
      "69 \t: Episode || Reward:  -20.52321616997496 \t|| Average Reward:  -121.43421553188163 \t epsilon:  0.7040696960536299\n",
      "70 \t: Episode || Reward:  -38.69412466941924 \t|| Average Reward:  -120.26886213945258 \t epsilon:  0.7005493475733617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71 \t: Episode || Reward:  -122.73044973685376 \t|| Average Reward:  -120.30305085608317 \t epsilon:  0.697046600835495\n",
      "72 \t: Episode || Reward:  -103.35613063608058 \t|| Average Reward:  -120.07090126402834 \t epsilon:  0.6935613678313175\n",
      "73 \t: Episode || Reward:  -106.17069519827348 \t|| Average Reward:  -119.88306064151816 \t epsilon:  0.6900935609921609\n",
      "74 \t: Episode || Reward:  -146.8144036166243 \t|| Average Reward:  -120.24214521451958 \t epsilon:  0.6866430931872001\n",
      "75 \t: Episode || Reward:  -62.41133565896242 \t|| Average Reward:  -119.4812135098412 \t epsilon:  0.6832098777212641\n",
      "76 \t: Episode || Reward:  -88.53919355865962 \t|| Average Reward:  -119.07936909489078 \t epsilon:  0.6797938283326578\n",
      "77 \t: Episode || Reward:  -109.68423775279597 \t|| Average Reward:  -118.95891869306904 \t epsilon:  0.6763948591909945\n",
      "78 \t: Episode || Reward:  -136.7226189721745 \t|| Average Reward:  -119.18377565862735 \t epsilon:  0.6730128848950395\n",
      "79 \t: Episode || Reward:  -195.00051535167765 \t|| Average Reward:  -120.13148490479048 \t epsilon:  0.6696478204705644\n",
      "80 \t: Episode || Reward:  -107.4262939213715 \t|| Average Reward:  -119.97463069511863 \t epsilon:  0.6662995813682115\n",
      "81 \t: Episode || Reward:  -104.68098064043885 \t|| Average Reward:  -119.78812276762253 \t epsilon:  0.6629680834613705\n",
      "82 \t: Episode || Reward:  -80.91386049194945 \t|| Average Reward:  -119.31975816189154 \t epsilon:  0.6596532430440636\n",
      "83 \t: Episode || Reward:  -47.40689273437083 \t|| Average Reward:  -118.46365262108772 \t epsilon:  0.6563549768288433\n",
      "84 \t: Episode || Reward:  -68.04630797655975 \t|| Average Reward:  -117.87050738997561 \t epsilon:  0.653073201944699\n",
      "85 \t: Episode || Reward:  -176.45938013579257 \t|| Average Reward:  -118.5517733521363 \t epsilon:  0.6498078359349755\n",
      "86 \t: Episode || Reward:  -93.53461414342362 \t|| Average Reward:  -118.26421979801316 \t epsilon:  0.6465587967553006\n",
      "87 \t: Episode || Reward:  -89.77253909605146 \t|| Average Reward:  -117.94045069912721 \t epsilon:  0.6433260027715241\n",
      "88 \t: Episode || Reward:  -41.01990806823558 \t|| Average Reward:  -117.07617493922955 \t epsilon:  0.6401093727576664\n",
      "89 \t: Episode || Reward:  -30.76909435287112 \t|| Average Reward:  -116.11720737715889 \t epsilon:  0.6369088258938781\n",
      "90 \t: Episode || Reward:  -98.44728761225572 \t|| Average Reward:  -115.92303243468744 \t epsilon:  0.6337242817644086\n",
      "91 \t: Episode || Reward:  -67.91760733966186 \t|| Average Reward:  -115.40123433582846 \t epsilon:  0.6305556603555866\n",
      "92 \t: Episode || Reward:  -109.94206383092958 \t|| Average Reward:  -115.34253357771127 \t epsilon:  0.6274028820538087\n",
      "93 \t: Episode || Reward:  18.7624647350866 \t|| Average Reward:  -113.91588465949002 \t epsilon:  0.6242658676435396\n",
      "94 \t: Episode || Reward:  -86.66538134048949 \t|| Average Reward:  -113.62903725613212 \t epsilon:  0.6211445383053219\n",
      "95 \t: Episode || Reward:  -71.91304575946461 \t|| Average Reward:  -113.19449567804183 \t epsilon:  0.6180388156137953\n",
      "96 \t: Episode || Reward:  -122.15351114748678 \t|| Average Reward:  -113.2868566622629 \t epsilon:  0.6149486215357263\n",
      "97 \t: Episode || Reward:  -36.67390944522967 \t|| Average Reward:  -112.50509189474215 \t epsilon:  0.6118738784280476\n",
      "98 \t: Episode || Reward:  -119.87285950314265 \t|| Average Reward:  -112.5795137897765 \t epsilon:  0.6088145090359074\n",
      "99 \t: Episode || Reward:  -22.885728270632583 \t|| Average Reward:  -111.68257593458506 \t epsilon:  0.6057704364907278\n",
      "100 \t: Episode || Reward:  -46.75816363464453 \t|| Average Reward:  -107.70573135900693 \t epsilon:  0.6027415843082742\n",
      "101 \t: Episode || Reward:  -76.82096511712308 \t|| Average Reward:  -107.36187464364366 \t epsilon:  0.5997278763867329\n",
      "102 \t: Episode || Reward:  -36.80393576768371 \t|| Average Reward:  -106.74397024261401 \t epsilon:  0.5967292370047992\n",
      "103 \t: Episode || Reward:  -208.20396775208542 \t|| Average Reward:  -105.2110431296916 \t epsilon:  0.5937455908197752\n",
      "104 \t: Episode || Reward:  -42.57573216874068 \t|| Average Reward:  -105.06137067229604 \t epsilon:  0.5907768628656763\n",
      "105 \t: Episode || Reward:  -71.81189582554246 \t|| Average Reward:  -104.14727897228951 \t epsilon:  0.5878229785513479\n",
      "106 \t: Episode || Reward:  -93.74889727169533 \t|| Average Reward:  -103.61469114187875 \t epsilon:  0.5848838636585911\n",
      "107 \t: Episode || Reward:  -90.60172373345596 \t|| Average Reward:  -103.22058632785894 \t epsilon:  0.5819594443402982\n",
      "108 \t: Episode || Reward:  -76.1612750786883 \t|| Average Reward:  -102.91115767426228 \t epsilon:  0.5790496471185967\n",
      "109 \t: Episode || Reward:  -55.004579939108424 \t|| Average Reward:  -102.8955438965533 \t epsilon:  0.5761543988830038\n",
      "110 \t: Episode || Reward:  -57.23158737734004 \t|| Average Reward:  -102.33885486017287 \t epsilon:  0.5732736268885887\n",
      "111 \t: Episode || Reward:  -14.983702880981213 \t|| Average Reward:  -101.15830959679437 \t epsilon:  0.5704072587541458\n",
      "112 \t: Episode || Reward:  -112.54655630163876 \t|| Average Reward:  -101.15957154361325 \t epsilon:  0.567555222460375\n",
      "113 \t: Episode || Reward:  -70.88180975239067 \t|| Average Reward:  -99.39773678814096 \t epsilon:  0.5647174463480732\n",
      "114 \t: Episode || Reward:  -37.554826916907054 \t|| Average Reward:  -98.81683968046536 \t epsilon:  0.5618938591163328\n",
      "115 \t: Episode || Reward:  -25.714344613418447 \t|| Average Reward:  -97.87912437640306 \t epsilon:  0.5590843898207511\n",
      "116 \t: Episode || Reward:  -67.30568131281643 \t|| Average Reward:  -97.07884668837004 \t epsilon:  0.5562889678716474\n",
      "117 \t: Episode || Reward:  -53.63729356092583 \t|| Average Reward:  -96.30457443002555 \t epsilon:  0.5535075230322891\n",
      "118 \t: Episode || Reward:  -53.61620106250868 \t|| Average Reward:  -95.96471782699386 \t epsilon:  0.5507399854171277\n",
      "119 \t: Episode || Reward:  -156.19675979214617 \t|| Average Reward:  -94.20044471993026 \t epsilon:  0.547986285490042\n",
      "120 \t: Episode || Reward:  -51.414144878610415 \t|| Average Reward:  -93.70183181618502 \t epsilon:  0.5452463540625918\n",
      "121 \t: Episode || Reward:  -37.735882970391685 \t|| Average Reward:  -93.12116927946653 \t epsilon:  0.5425201222922789\n",
      "122 \t: Episode || Reward:  -53.721706221520506 \t|| Average Reward:  -92.26633826134494 \t epsilon:  0.5398075216808175\n",
      "123 \t: Episode || Reward:  -113.39051228053356 \t|| Average Reward:  -92.72347329637509 \t epsilon:  0.5371084840724134\n",
      "124 \t: Episode || Reward:  -21.54837180075873 \t|| Average Reward:  -92.10765501671625 \t epsilon:  0.5344229416520513\n",
      "125 \t: Episode || Reward:  -127.34552463242902 \t|| Average Reward:  -91.42399381579025 \t epsilon:  0.531750826943791\n",
      "126 \t: Episode || Reward:  -106.52903829003671 \t|| Average Reward:  -90.89962855251514 \t epsilon:  0.5290920728090721\n",
      "127 \t: Episode || Reward:  -51.169543934116476 \t|| Average Reward:  -90.45316824106565 \t epsilon:  0.5264466124450268\n",
      "128 \t: Episode || Reward:  -20.27796579318992 \t|| Average Reward:  -89.47665445682159 \t epsilon:  0.5238143793828016\n",
      "129 \t: Episode || Reward:  -26.39817847119224 \t|| Average Reward:  -87.38232428135669 \t epsilon:  0.5211953074858876\n",
      "130 \t: Episode || Reward:  -30.21615408458294 \t|| Average Reward:  -87.00029611821122 \t epsilon:  0.5185893309484582\n",
      "131 \t: Episode || Reward:  35.76579014756993 \t|| Average Reward:  -85.49758309806838 \t epsilon:  0.5159963842937159\n",
      "132 \t: Episode || Reward:  -68.43814498922528 \t|| Average Reward:  -85.53656048047698 \t epsilon:  0.5134164023722473\n",
      "133 \t: Episode || Reward:  -51.1619980823702 \t|| Average Reward:  -85.33037825054343 \t epsilon:  0.510849320360386\n",
      "134 \t: Episode || Reward:  -88.86353266185199 \t|| Average Reward:  -85.30896782740416 \t epsilon:  0.5082950737585841\n",
      "135 \t: Episode || Reward:  -132.1709537890676 \t|| Average Reward:  -85.10798169326922 \t epsilon:  0.5057535983897912\n",
      "136 \t: Episode || Reward:  -189.44768698037902 \t|| Average Reward:  -84.53857763646174 \t epsilon:  0.5032248303978422\n",
      "137 \t: Episode || Reward:  -31.64064738097872 \t|| Average Reward:  -83.85465335208322 \t epsilon:  0.500708706245853\n",
      "138 \t: Episode || Reward:  -210.93803516382107 \t|| Average Reward:  -85.03834431181862 \t epsilon:  0.4982051627146237\n",
      "139 \t: Episode || Reward:  -34.090068959462855 \t|| Average Reward:  -83.84530952449448 \t epsilon:  0.49571413690105054\n",
      "140 \t: Episode || Reward:  1.0282303590117152 \t|| Average Reward:  -83.18410092166322 \t epsilon:  0.4932355662165453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141 \t: Episode || Reward:  -35.37161047426882 \t|| Average Reward:  -82.23221156059093 \t epsilon:  0.4907693883854626\n",
      "142 \t: Episode || Reward:  -50.785647439930074 \t|| Average Reward:  -81.4398669767893 \t epsilon:  0.4883155414435353\n",
      "143 \t: Episode || Reward:  -5.520543790149503 \t|| Average Reward:  -80.09648351713686 \t epsilon:  0.4858739637363176\n",
      "144 \t: Episode || Reward:  -64.0617602266042 \t|| Average Reward:  -79.89445318959876 \t epsilon:  0.483444593917636\n",
      "145 \t: Episode || Reward:  -78.56466007487606 \t|| Average Reward:  -79.26984146128093 \t epsilon:  0.4810273709480478\n",
      "146 \t: Episode || Reward:  -68.03173829770674 \t|| Average Reward:  -79.35887328025677 \t epsilon:  0.47862223409330756\n",
      "147 \t: Episode || Reward:  -0.30251448203003406 \t|| Average Reward:  -78.95264621792508 \t epsilon:  0.47622912292284103\n",
      "148 \t: Episode || Reward:  -20.522783850448334 \t|| Average Reward:  -76.85397676652629 \t epsilon:  0.4738479773082268\n",
      "149 \t: Episode || Reward:  -248.0710468877671 \t|| Average Reward:  -78.95069938533642 \t epsilon:  0.47147873742168567\n",
      "150 \t: Episode || Reward:  -28.2217701494572 \t|| Average Reward:  -78.42256388155737 \t epsilon:  0.46912134373457726\n",
      "151 \t: Episode || Reward:  -41.40237520848534 \t|| Average Reward:  -78.25233594282494 \t epsilon:  0.46677573701590436\n",
      "152 \t: Episode || Reward:  -7.504996556216867 \t|| Average Reward:  -76.88172715686227 \t epsilon:  0.46444185833082485\n",
      "153 \t: Episode || Reward:  -27.657669246172503 \t|| Average Reward:  -76.15744765634709 \t epsilon:  0.46211964903917074\n",
      "154 \t: Episode || Reward:  1.369129349800275 \t|| Average Reward:  -75.39110304665368 \t epsilon:  0.4598090507939749\n",
      "155 \t: Episode || Reward:  -68.85252392164621 \t|| Average Reward:  -75.27014707185474 \t epsilon:  0.457510005540005\n",
      "156 \t: Episode || Reward:  -50.208823072835955 \t|| Average Reward:  -75.04955039696456 \t epsilon:  0.45522245551230495\n",
      "157 \t: Episode || Reward:  -53.52553846148215 \t|| Average Reward:  -74.40114600696444 \t epsilon:  0.4529463432347434\n",
      "158 \t: Episode || Reward:  -43.53854048837452 \t|| Average Reward:  -73.9457596862387 \t epsilon:  0.4506816115185697\n",
      "159 \t: Episode || Reward:  -8.578543306002175 \t|| Average Reward:  -73.06492778084042 \t epsilon:  0.4484282034609769\n",
      "160 \t: Episode || Reward:  -301.5542016198732 \t|| Average Reward:  -75.32277438608618 \t epsilon:  0.446186062443672\n",
      "161 \t: Episode || Reward:  -12.864924496196545 \t|| Average Reward:  -74.55570554430116 \t epsilon:  0.4439551321314536\n",
      "162 \t: Episode || Reward:  -34.59182128476266 \t|| Average Reward:  -73.7906990135082 \t epsilon:  0.4417353564707963\n",
      "163 \t: Episode || Reward:  -5.602766373912374 \t|| Average Reward:  -72.12670898586858 \t epsilon:  0.43952667968844233\n",
      "164 \t: Episode || Reward:  -1.9784560240584312 \t|| Average Reward:  -71.65672474945686 \t epsilon:  0.43732904629000013\n",
      "165 \t: Episode || Reward:  -136.33000388324942 \t|| Average Reward:  -72.05950770575353 \t epsilon:  0.4351424010585501\n",
      "166 \t: Episode || Reward:  -385.21956480190835 \t|| Average Reward:  -74.76541478171984 \t epsilon:  0.43296668905325736\n",
      "167 \t: Episode || Reward:  -16.742268255775798 \t|| Average Reward:  -73.60743704200186 \t epsilon:  0.43080185560799106\n",
      "168 \t: Episode || Reward:  -188.5299795344159 \t|| Average Reward:  -75.29017635973352 \t epsilon:  0.4286478463299511\n",
      "169 \t: Episode || Reward:  22.405527980994005 \t|| Average Reward:  -74.86088891822384 \t epsilon:  0.42650460709830135\n",
      "170 \t: Episode || Reward:  -60.27843085036349 \t|| Average Reward:  -75.07673198003326 \t epsilon:  0.42437208406280985\n",
      "171 \t: Episode || Reward:  89.98816661065591 \t|| Average Reward:  -72.94954581655819 \t epsilon:  0.4222502236424958\n",
      "172 \t: Episode || Reward:  -13.454770881648457 \t|| Average Reward:  -72.05053221901386 \t epsilon:  0.42013897252428334\n",
      "173 \t: Episode || Reward:  -51.3118343017776 \t|| Average Reward:  -71.5019436100489 \t epsilon:  0.4180382776616619\n",
      "174 \t: Episode || Reward:  -10.781209082357634 \t|| Average Reward:  -70.14161166470622 \t epsilon:  0.4159480862733536\n",
      "175 \t: Episode || Reward:  9.895360164826528 \t|| Average Reward:  -69.41854470646834 \t epsilon:  0.41386834584198684\n",
      "176 \t: Episode || Reward:  -31.589530724791743 \t|| Average Reward:  -68.84904807812967 \t epsilon:  0.4117990041127769\n",
      "177 \t: Episode || Reward:  -249.59807612378353 \t|| Average Reward:  -70.24818646183954 \t epsilon:  0.40974000909221303\n",
      "178 \t: Episode || Reward:  -16.681974978637527 \t|| Average Reward:  -69.04778002190417 \t epsilon:  0.40769130904675194\n",
      "179 \t: Episode || Reward:  14.190445878388083 \t|| Average Reward:  -66.9558704096035 \t epsilon:  0.40565285250151817\n",
      "180 \t: Episode || Reward:  -139.5867576312786 \t|| Average Reward:  -67.27747504670258 \t epsilon:  0.4036245882390106\n",
      "181 \t: Episode || Reward:  -26.56817994690651 \t|| Average Reward:  -66.49634703976726 \t epsilon:  0.4016064652978155\n",
      "182 \t: Episode || Reward:  -42.48707875744851 \t|| Average Reward:  -66.11207922242224 \t epsilon:  0.3995984329713264\n",
      "183 \t: Episode || Reward:  -56.960830737163846 \t|| Average Reward:  -66.20761860245017 \t epsilon:  0.3976004408064698\n",
      "184 \t: Episode || Reward:  121.67408836375147 \t|| Average Reward:  -64.31041463904707 \t epsilon:  0.39561243860243744\n",
      "185 \t: Episode || Reward:  12.327785162406053 \t|| Average Reward:  -62.422542986065075 \t epsilon:  0.3936343764094253\n",
      "186 \t: Episode || Reward:  84.73418632494875 \t|| Average Reward:  -60.63985498138136 \t epsilon:  0.39166620452737816\n",
      "187 \t: Episode || Reward:  67.78325079068527 \t|| Average Reward:  -59.064297082513995 \t epsilon:  0.3897078735047413\n",
      "188 \t: Episode || Reward:  -56.79751864767931 \t|| Average Reward:  -59.22207318830844 \t epsilon:  0.3877593341372176\n",
      "189 \t: Episode || Reward:  96.21799899804002 \t|| Average Reward:  -57.952202254799325 \t epsilon:  0.3858205374665315\n",
      "190 \t: Episode || Reward:  -44.69733930500941 \t|| Average Reward:  -57.41470277172685 \t epsilon:  0.38389143477919885\n",
      "191 \t: Episode || Reward:  92.88894745210857 \t|| Average Reward:  -55.80663722380915 \t epsilon:  0.3819719776053028\n",
      "192 \t: Episode || Reward:  51.131049658019684 \t|| Average Reward:  -54.195906088919656 \t epsilon:  0.3800621177172763\n",
      "193 \t: Episode || Reward:  -106.13013692844899 \t|| Average Reward:  -55.444832105555015 \t epsilon:  0.37816180712868996\n",
      "194 \t: Episode || Reward:  74.21256028799857 \t|| Average Reward:  -53.83605268927013 \t epsilon:  0.37627099809304654\n",
      "195 \t: Episode || Reward:  -22.293543161529954 \t|| Average Reward:  -53.339857663290786 \t epsilon:  0.3743896431025813\n",
      "196 \t: Episode || Reward:  -430.5249966786638 \t|| Average Reward:  -56.42357251860256 \t epsilon:  0.37251769488706843\n",
      "197 \t: Episode || Reward:  -22.678297917157835 \t|| Average Reward:  -56.28361640332183 \t epsilon:  0.3706551064126331\n",
      "198 \t: Episode || Reward:  58.200283337136625 \t|| Average Reward:  -54.502884974919034 \t epsilon:  0.36880183088056995\n",
      "199 \t: Episode || Reward:  57.09053896942473 \t|| Average Reward:  -53.70312230251849 \t epsilon:  0.3669578217261671\n",
      "200 \t: Episode || Reward:  -162.95401171274523 \t|| Average Reward:  -54.86508078329948 \t epsilon:  0.36512303261753626\n",
      "201 \t: Episode || Reward:  67.68030373898819 \t|| Average Reward:  -53.42006809473836 \t epsilon:  0.3632974174544486\n",
      "202 \t: Episode || Reward:  57.809362074730224 \t|| Average Reward:  -52.47393511631422 \t epsilon:  0.3614809303671764\n",
      "203 \t: Episode || Reward:  -115.54249308710274 \t|| Average Reward:  -51.547320369664405 \t epsilon:  0.3596735257153405\n",
      "204 \t: Episode || Reward:  -232.8198398331452 \t|| Average Reward:  -53.449761446308436 \t epsilon:  0.3578751580867638\n",
      "205 \t: Episode || Reward:  71.09087821982763 \t|| Average Reward:  -52.020733705854745 \t epsilon:  0.35608578229633\n",
      "206 \t: Episode || Reward:  -271.825819244224 \t|| Average Reward:  -53.801502925580024 \t epsilon:  0.3543053533848483\n",
      "207 \t: Episode || Reward:  69.36468938158703 \t|| Average Reward:  -52.2018387944296 \t epsilon:  0.35253382661792404\n",
      "208 \t: Episode || Reward:  -33.54079091193098 \t|| Average Reward:  -51.77563395276203 \t epsilon:  0.3507711574848344\n",
      "209 \t: Episode || Reward:  -21.055731326458883 \t|| Average Reward:  -51.43614546663554 \t epsilon:  0.34901730169741024\n",
      "210 \t: Episode || Reward:  -130.3093765656281 \t|| Average Reward:  -52.16692335851842 \t epsilon:  0.3472722151889232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211 \t: Episode || Reward:  5.298543107319631 \t|| Average Reward:  -51.96410089863541 \t epsilon:  0.3455358541129786\n",
      "212 \t: Episode || Reward:  -62.161234830653484 \t|| Average Reward:  -51.46024768392555 \t epsilon:  0.3438081748424137\n",
      "213 \t: Episode || Reward:  -125.7062015908989 \t|| Average Reward:  -52.008491602310635 \t epsilon:  0.3420891339682016\n",
      "214 \t: Episode || Reward:  82.0576011172958 \t|| Average Reward:  -50.8123673219686 \t epsilon:  0.3403786882983606\n",
      "215 \t: Episode || Reward:  87.50365534149856 \t|| Average Reward:  -49.680187322419435 \t epsilon:  0.3386767948568688\n",
      "216 \t: Episode || Reward:  68.00565460756737 \t|| Average Reward:  -48.3270739632156 \t epsilon:  0.33698341088258443\n",
      "217 \t: Episode || Reward:  138.8156313777981 \t|| Average Reward:  -46.402544713828355 \t epsilon:  0.3352984938281715\n",
      "218 \t: Episode || Reward:  -33.147318403963965 \t|| Average Reward:  -46.197855887242916 \t epsilon:  0.33362200135903064\n",
      "219 \t: Episode || Reward:  109.16853430161423 \t|| Average Reward:  -43.54420294630531 \t epsilon:  0.33195389135223546\n",
      "220 \t: Episode || Reward:  62.712377967992374 \t|| Average Reward:  -42.40293771783928 \t epsilon:  0.3302941218954743\n",
      "221 \t: Episode || Reward:  3.3794112233750013 \t|| Average Reward:  -41.991784775901614 \t epsilon:  0.32864265128599696\n",
      "222 \t: Episode || Reward:  81.4846049244745 \t|| Average Reward:  -40.63972166444166 \t epsilon:  0.326999438029567\n",
      "223 \t: Episode || Reward:  63.58244286611216 \t|| Average Reward:  -38.869992112975204 \t epsilon:  0.3253644408394192\n",
      "224 \t: Episode || Reward:  89.37722987175773 \t|| Average Reward:  -37.76073609625005 \t epsilon:  0.3237376186352221\n",
      "225 \t: Episode || Reward:  90.24966259766074 \t|| Average Reward:  -35.58478422394916 \t epsilon:  0.322118930542046\n",
      "226 \t: Episode || Reward:  26.50516838061364 \t|| Average Reward:  -34.25444215724264 \t epsilon:  0.32050833588933575\n",
      "227 \t: Episode || Reward:  -24.84820104118728 \t|| Average Reward:  -33.99122872831335 \t epsilon:  0.31890579420988907\n",
      "228 \t: Episode || Reward:  -53.25481248132547 \t|| Average Reward:  -34.32099719519471 \t epsilon:  0.3173112652388396\n",
      "229 \t: Episode || Reward:  93.95470253242372 \t|| Average Reward:  -33.11746838515855 \t epsilon:  0.3157247089126454\n",
      "230 \t: Episode || Reward:  -395.78596433865187 \t|| Average Reward:  -36.773166487699235 \t epsilon:  0.3141460853680822\n",
      "231 \t: Episode || Reward:  87.38758882112673 \t|| Average Reward:  -36.25694850096367 \t epsilon:  0.3125753549412418\n",
      "232 \t: Episode || Reward:  -509.7372463816946 \t|| Average Reward:  -40.669939514888355 \t epsilon:  0.31101247816653554\n",
      "233 \t: Episode || Reward:  -8.002140214463921 \t|| Average Reward:  -40.2383409362093 \t epsilon:  0.30945741577570285\n",
      "234 \t: Episode || Reward:  15.54796339092519 \t|| Average Reward:  -39.194225975681526 \t epsilon:  0.3079101286968243\n",
      "235 \t: Episode || Reward:  72.66061059190561 \t|| Average Reward:  -37.14591033187179 \t epsilon:  0.3063705780533402\n",
      "236 \t: Episode || Reward:  64.73936257666838 \t|| Average Reward:  -34.60403983630132 \t epsilon:  0.30483872516307353\n",
      "237 \t: Episode || Reward:  132.99448889114444 \t|| Average Reward:  -32.957688473580085 \t epsilon:  0.3033145315372582\n",
      "238 \t: Episode || Reward:  106.93703628125144 \t|| Average Reward:  -29.778937759129363 \t epsilon:  0.3017979588795719\n",
      "239 \t: Episode || Reward:  56.729238410879496 \t|| Average Reward:  -28.870744685425933 \t epsilon:  0.30028896908517405\n",
      "240 \t: Episode || Reward:  11.975007844994522 \t|| Average Reward:  -28.76127691056611 \t epsilon:  0.2987875242397482\n",
      "241 \t: Episode || Reward:  78.92010974671408 \t|| Average Reward:  -27.61835970835628 \t epsilon:  0.29729358661854943\n",
      "242 \t: Episode || Reward:  116.31831737881225 \t|| Average Reward:  -25.94732006016886 \t epsilon:  0.29580711868545667\n",
      "243 \t: Episode || Reward:  90.82261871123787 \t|| Average Reward:  -24.983888435154984 \t epsilon:  0.2943280830920294\n",
      "244 \t: Episode || Reward:  -59.34604928688829 \t|| Average Reward:  -24.936731325757833 \t epsilon:  0.29285644267656924\n",
      "245 \t: Episode || Reward:  63.160507219219184 \t|| Average Reward:  -23.51947965281688 \t epsilon:  0.2913921604631864\n",
      "246 \t: Episode || Reward:  85.58353163184886 \t|| Average Reward:  -21.983326953521324 \t epsilon:  0.28993519966087045\n",
      "247 \t: Episode || Reward:  -15.249701918675427 \t|| Average Reward:  -22.132798827887772 \t epsilon:  0.2884855236625661\n",
      "248 \t: Episode || Reward:  -213.76901720643127 \t|| Average Reward:  -24.065261161447598 \t epsilon:  0.28704309604425327\n",
      "249 \t: Episode || Reward:  96.55176770913602 \t|| Average Reward:  -20.619033015478568 \t epsilon:  0.285607880564032\n",
      "250 \t: Episode || Reward:  73.99506521319921 \t|| Average Reward:  -19.596864661852006 \t epsilon:  0.28417984116121187\n",
      "251 \t: Episode || Reward:  118.97505127656092 \t|| Average Reward:  -17.99309039700154 \t epsilon:  0.2827589419554058\n",
      "252 \t: Episode || Reward:  95.94201683292764 \t|| Average Reward:  -16.9586202631101 \t epsilon:  0.28134514724562876\n",
      "253 \t: Episode || Reward:  178.21769914046874 \t|| Average Reward:  -14.899866579243685 \t epsilon:  0.2799384215094006\n",
      "254 \t: Episode || Reward:  -45.548352736462405 \t|| Average Reward:  -15.369041400106314 \t epsilon:  0.27853872940185365\n",
      "255 \t: Episode || Reward:  -136.45960042693014 \t|| Average Reward:  -16.045112165159154 \t epsilon:  0.27714603575484437\n",
      "256 \t: Episode || Reward:  35.648773653546435 \t|| Average Reward:  -15.186536197895329 \t epsilon:  0.2757603055760701\n",
      "257 \t: Episode || Reward:  -20.645787257212774 \t|| Average Reward:  -14.857738685852635 \t epsilon:  0.2743815040481898\n",
      "258 \t: Episode || Reward:  81.54042636881819 \t|| Average Reward:  -13.60694901728071 \t epsilon:  0.2730095965279488\n",
      "259 \t: Episode || Reward:  122.18574200602615 \t|| Average Reward:  -12.299306164160425 \t epsilon:  0.27164454854530906\n",
      "260 \t: Episode || Reward:  170.84330224264335 \t|| Average Reward:  -7.575331125535258 \t epsilon:  0.2702863258025825\n",
      "261 \t: Episode || Reward:  132.267982600351 \t|| Average Reward:  -6.124002054569782 \t epsilon:  0.2689348941735696\n",
      "262 \t: Episode || Reward:  132.81057298581095 \t|| Average Reward:  -4.449978111864048 \t epsilon:  0.26759021970270175\n",
      "263 \t: Episode || Reward:  132.1000527374983 \t|| Average Reward:  -3.072949920749941 \t epsilon:  0.2662522686041882\n",
      "264 \t: Episode || Reward:  57.038148390003315 \t|| Average Reward:  -2.4827838766093238 \t epsilon:  0.2649210072611673\n",
      "265 \t: Episode || Reward:  127.34149895865619 \t|| Average Reward:  0.1539311518097317 \t epsilon:  0.26359640222486147\n",
      "266 \t: Episode || Reward:  111.64307525334726 \t|| Average Reward:  5.122557552362288 \t epsilon:  0.26227842021373715\n",
      "267 \t: Episode || Reward:  -3.2767847821215383 \t|| Average Reward:  5.257212387098829 \t epsilon:  0.2609670281126685\n",
      "268 \t: Episode || Reward:  104.87989588097527 \t|| Average Reward:  8.191311141252742 \t epsilon:  0.25966219297210513\n",
      "269 \t: Episode || Reward:  155.1296281543429 \t|| Average Reward:  9.51855214298623 \t epsilon:  0.2583638820072446\n",
      "270 \t: Episode || Reward:  253.09488632969186 \t|| Average Reward:  12.652285314786784 \t epsilon:  0.2570720625972084\n",
      "271 \t: Episode || Reward:  12.12697527566391 \t|| Average Reward:  11.873673401436866 \t epsilon:  0.25578670228422234\n",
      "272 \t: Episode || Reward:  -96.73020979099226 \t|| Average Reward:  11.04091901234343 \t epsilon:  0.25450776877280124\n",
      "273 \t: Episode || Reward:  103.30648036517758 \t|| Average Reward:  12.587102159012977 \t epsilon:  0.2532352299289372\n",
      "274 \t: Episode || Reward:  152.45779877594745 \t|| Average Reward:  14.219492237596032 \t epsilon:  0.2519690537792925\n",
      "275 \t: Episode || Reward:  102.04598495393755 \t|| Average Reward:  15.140998485487138 \t epsilon:  0.2507092085103961\n",
      "276 \t: Episode || Reward:  13.18193869191599 \t|| Average Reward:  15.588713179654219 \t epsilon:  0.2494556624678441\n",
      "277 \t: Episode || Reward:  138.26850521954097 \t|| Average Reward:  19.467378993087458 \t epsilon:  0.24820838415550486\n",
      "278 \t: Episode || Reward:  123.917838701164 \t|| Average Reward:  20.873377129885476 \t epsilon:  0.24696734223472733\n",
      "279 \t: Episode || Reward:  129.27579662486485 \t|| Average Reward:  22.024230637350247 \t epsilon:  0.2457325055235537\n",
      "280 \t: Episode || Reward:  235.11946890794067 \t|| Average Reward:  25.771292902742445 \t epsilon:  0.24450384299593592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281 \t: Episode || Reward:  72.13897854785651 \t|| Average Reward:  26.75836448769007 \t epsilon:  0.24328132378095624\n",
      "282 \t: Episode || Reward:  100.86471793817758 \t|| Average Reward:  28.19188245464633 \t epsilon:  0.24206491716205145\n",
      "283 \t: Episode || Reward:  85.12820016418202 \t|| Average Reward:  29.61277276365978 \t epsilon:  0.2408545925762412\n",
      "284 \t: Episode || Reward:  115.445141591511 \t|| Average Reward:  29.550483295937383 \t epsilon:  0.23965031961336\n",
      "285 \t: Episode || Reward:  -4.766349812213946 \t|| Average Reward:  29.379541946191186 \t epsilon:  0.2384520680152932\n",
      "286 \t: Episode || Reward:  118.91803654333083 \t|| Average Reward:  29.721380448375008 \t epsilon:  0.23725980767521673\n",
      "287 \t: Episode || Reward:  210.5141222176199 \t|| Average Reward:  31.148689162644356 \t epsilon:  0.23607350863684065\n",
      "288 \t: Episode || Reward:  -24.710127080825643 \t|| Average Reward:  31.46956307831289 \t epsilon:  0.23489314109365644\n",
      "289 \t: Episode || Reward:  85.70577127189301 \t|| Average Reward:  31.364440801051416 \t epsilon:  0.23371867538818816\n",
      "290 \t: Episode || Reward:  146.69664990237055 \t|| Average Reward:  33.278380693125214 \t epsilon:  0.23255008201124722\n",
      "291 \t: Episode || Reward:  107.93778799131643 \t|| Average Reward:  33.428869098517296 \t epsilon:  0.231387331601191\n",
      "292 \t: Episode || Reward:  -169.18900985068737 \t|| Average Reward:  31.225668503430224 \t epsilon:  0.23023039494318503\n",
      "293 \t: Episode || Reward:  115.8723390998508 \t|| Average Reward:  33.44569326371322 \t epsilon:  0.2290792429684691\n",
      "294 \t: Episode || Reward:  90.2333745042663 \t|| Average Reward:  33.605901405875905 \t epsilon:  0.22793384675362674\n",
      "295 \t: Episode || Reward:  131.96878134103343 \t|| Average Reward:  35.14852465090153 \t epsilon:  0.22679417751985861\n",
      "296 \t: Episode || Reward:  130.6505915855641 \t|| Average Reward:  40.76028053354381 \t epsilon:  0.22566020663225933\n",
      "297 \t: Episode || Reward:  168.79973978379994 \t|| Average Reward:  42.675060910553384 \t epsilon:  0.22453190559909803\n",
      "298 \t: Episode || Reward:  138.76930474500534 \t|| Average Reward:  43.480751124632086 \t epsilon:  0.22340924607110255\n",
      "299 \t: Episode || Reward:  97.13109165526708 \t|| Average Reward:  43.88115665149051 \t epsilon:  0.22229219984074702\n",
      "300 \t: Episode || Reward:  138.99391165079774 \t|| Average Reward:  46.900635885125936 \t epsilon:  0.2211807388415433\n",
      "301 \t: Episode || Reward:  271.08216899357313 \t|| Average Reward:  48.93465453767178 \t epsilon:  0.22007483514733558\n",
      "302 \t: Episode || Reward:  -182.09632720514543 \t|| Average Reward:  46.535597644873036 \t epsilon:  0.2189744609715989\n",
      "303 \t: Episode || Reward:  33.50926956350995 \t|| Average Reward:  48.02611527137915 \t epsilon:  0.2178795886667409\n",
      "304 \t: Episode || Reward:  -6.473386417911194 \t|| Average Reward:  50.28957980553148 \t epsilon:  0.2167901907234072\n",
      "305 \t: Episode || Reward:  211.55554052777072 \t|| Average Reward:  51.694226428610925 \t epsilon:  0.21570623976979014\n",
      "306 \t: Episode || Reward:  142.48088981582904 \t|| Average Reward:  55.837293519211464 \t epsilon:  0.21462770857094118\n",
      "307 \t: Episode || Reward:  73.71345952997973 \t|| Average Reward:  55.88078122069538 \t epsilon:  0.21355457002808648\n",
      "308 \t: Episode || Reward:  10.398794285150487 \t|| Average Reward:  56.320177072666205 \t epsilon:  0.21248679717794605\n",
      "309 \t: Episode || Reward:  77.52352578835665 \t|| Average Reward:  57.30596964381436 \t epsilon:  0.21142436319205632\n",
      "310 \t: Episode || Reward:  224.66323906805405 \t|| Average Reward:  60.85569580015118 \t epsilon:  0.21036724137609603\n",
      "311 \t: Episode || Reward:  130.22165073205196 \t|| Average Reward:  62.104926876398515 \t epsilon:  0.20931540516921554\n",
      "312 \t: Episode || Reward:  90.56389507787586 \t|| Average Reward:  63.63217817548379 \t epsilon:  0.20826882814336947\n",
      "313 \t: Episode || Reward:  227.24485572461873 \t|| Average Reward:  67.16168874863897 \t epsilon:  0.20722748400265262\n",
      "314 \t: Episode || Reward:  249.49234309710823 \t|| Average Reward:  68.83603616843709 \t epsilon:  0.20619134658263935\n",
      "315 \t: Episode || Reward:  -22.705513740134236 \t|| Average Reward:  67.73394447762078 \t epsilon:  0.20516038984972615\n",
      "316 \t: Episode || Reward:  130.25628194023173 \t|| Average Reward:  68.35645075094742 \t epsilon:  0.2041345879004775\n",
      "317 \t: Episode || Reward:  199.0127504419109 \t|| Average Reward:  68.95842194158854 \t epsilon:  0.2031139149609751\n",
      "318 \t: Episode || Reward:  -349.9483495476651 \t|| Average Reward:  65.79041163015152 \t epsilon:  0.20209834538617025\n",
      "319 \t: Episode || Reward:  47.71028176982239 \t|| Average Reward:  65.1758291048336 \t epsilon:  0.2010878536592394\n",
      "320 \t: Episode || Reward:  247.10252507592378 \t|| Average Reward:  67.01973057591292 \t epsilon:  0.2000824143909432\n",
      "321 \t: Episode || Reward:  98.78207844450766 \t|| Average Reward:  67.97375724812424 \t epsilon:  0.19908200231898848\n",
      "322 \t: Episode || Reward:  229.65571336270685 \t|| Average Reward:  69.45546833250657 \t epsilon:  0.19808659230739353\n",
      "323 \t: Episode || Reward:  69.40782173262718 \t|| Average Reward:  69.51372212117171 \t epsilon:  0.19709615934585656\n",
      "324 \t: Episode || Reward:  212.68160432951538 \t|| Average Reward:  70.7467658657493 \t epsilon:  0.19611067854912728\n",
      "325 \t: Episode || Reward:  -463.4190047593161 \t|| Average Reward:  65.21007919217952 \t epsilon:  0.19513012515638165\n",
      "326 \t: Episode || Reward:  88.46508106053129 \t|| Average Reward:  65.82967831897871 \t epsilon:  0.19415447453059972\n",
      "327 \t: Episode || Reward:  202.8521747795167 \t|| Average Reward:  68.10668207718574 \t epsilon:  0.19318370215794672\n",
      "328 \t: Episode || Reward:  130.32597698453057 \t|| Average Reward:  69.94248997184431 \t epsilon:  0.192217783647157\n",
      "329 \t: Episode || Reward:  253.0081661396271 \t|| Average Reward:  71.53302460791635 \t epsilon:  0.1912566947289212\n",
      "330 \t: Episode || Reward:  47.03726849929831 \t|| Average Reward:  75.96125693629585 \t epsilon:  0.1903004112552766\n",
      "331 \t: Episode || Reward:  33.210317816461654 \t|| Average Reward:  75.41948422624918 \t epsilon:  0.18934890919900021\n",
      "332 \t: Episode || Reward:  236.69375920201793 \t|| Average Reward:  82.88379428208633 \t epsilon:  0.18840216465300522\n",
      "333 \t: Episode || Reward:  1.13522904564104 \t|| Average Reward:  82.97516797468738 \t epsilon:  0.18746015382974018\n",
      "334 \t: Episode || Reward:  243.0068321886487 \t|| Average Reward:  85.24975666266461 \t epsilon:  0.1865228530605915\n",
      "335 \t: Episode || Reward:  116.09854514440322 \t|| Average Reward:  85.68413600818958 \t epsilon:  0.18559023879528855\n",
      "336 \t: Episode || Reward:  82.41116376401894 \t|| Average Reward:  85.86085402006307 \t epsilon:  0.1846622876013121\n",
      "337 \t: Episode || Reward:  132.79583803416315 \t|| Average Reward:  85.85886751149324 \t epsilon:  0.18373897616330553\n",
      "338 \t: Episode || Reward:  -18.26129112597357 \t|| Average Reward:  84.606884237421 \t epsilon:  0.182820281282489\n",
      "339 \t: Episode || Reward:  137.33106152044087 \t|| Average Reward:  85.41290246851662 \t epsilon:  0.18190617987607657\n",
      "340 \t: Episode || Reward:  223.81218887902202 \t|| Average Reward:  87.53127427885691 \t epsilon:  0.18099664897669618\n",
      "341 \t: Episode || Reward:  246.37673613548154 \t|| Average Reward:  89.20584054274461 \t epsilon:  0.1800916657318127\n",
      "342 \t: Episode || Reward:  165.83744543505964 \t|| Average Reward:  89.70103182330708 \t epsilon:  0.17919120740315364\n",
      "343 \t: Episode || Reward:  249.0541337379748 \t|| Average Reward:  91.28334697357442 \t epsilon:  0.17829525136613786\n",
      "344 \t: Episode || Reward:  246.40581922749524 \t|| Average Reward:  94.34086565871827 \t epsilon:  0.17740377510930716\n",
      "345 \t: Episode || Reward:  -266.2419670439458 \t|| Average Reward:  91.04684091608662 \t epsilon:  0.17651675623376062\n",
      "346 \t: Episode || Reward:  231.99961018410386 \t|| Average Reward:  92.51100170160915 \t epsilon:  0.1756341724525918\n",
      "347 \t: Episode || Reward:  251.6876416591575 \t|| Average Reward:  95.18037513738749 \t epsilon:  0.17475600159032884\n",
      "348 \t: Episode || Reward:  197.12763740782455 \t|| Average Reward:  99.28934168353005 \t epsilon:  0.17388222158237718\n",
      "349 \t: Episode || Reward:  -92.67280392435623 \t|| Average Reward:  97.39709596719513 \t epsilon:  0.1730128104744653\n",
      "350 \t: Episode || Reward:  -4.7852186922462465 \t|| Average Reward:  96.60929312814064 \t epsilon:  0.17214774642209296\n",
      "351 \t: Episode || Reward:  233.51765033511197 \t|| Average Reward:  97.75471911872619 \t epsilon:  0.1712870076899825\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "352 \t: Episode || Reward:  117.61691020530037 \t|| Average Reward:  97.9714680524499 \t epsilon:  0.17043057265153258\n",
      "353 \t: Episode || Reward:  133.18300887277348 \t|| Average Reward:  97.52112114977295 \t epsilon:  0.16957841978827493\n",
      "354 \t: Episode || Reward:  74.59133591343176 \t|| Average Reward:  98.72251803627191 \t epsilon:  0.16873052768933355\n",
      "355 \t: Episode || Reward:  168.55812541523653 \t|| Average Reward:  101.77269529469355 \t epsilon:  0.1678868750508869\n",
      "356 \t: Episode || Reward:  276.38909063689744 \t|| Average Reward:  104.18009846452708 \t epsilon:  0.16704744067563246\n",
      "357 \t: Episode || Reward:  88.80014387903954 \t|| Average Reward:  105.27455777588959 \t epsilon:  0.1662122034722543\n",
      "358 \t: Episode || Reward:  253.42789077944434 \t|| Average Reward:  106.99343241999586 \t epsilon:  0.16538114245489302\n",
      "359 \t: Episode || Reward:  264.5106676149972 \t|| Average Reward:  108.41668167608559 \t epsilon:  0.16455423674261854\n",
      "360 \t: Episode || Reward:  275.7606543411071 \t|| Average Reward:  109.46585519707023 \t epsilon:  0.16373146555890544\n",
      "361 \t: Episode || Reward:  249.87595404147572 \t|| Average Reward:  110.64193491148146 \t epsilon:  0.16291280823111093\n",
      "362 \t: Episode || Reward:  104.54088906533278 \t|| Average Reward:  110.35923807227668 \t epsilon:  0.16209824418995536\n",
      "363 \t: Episode || Reward:  232.10747682346167 \t|| Average Reward:  111.35931231313629 \t epsilon:  0.16128775296900558\n",
      "364 \t: Episode || Reward:  263.18384047449797 \t|| Average Reward:  113.42076923398125 \t epsilon:  0.16048131420416054\n",
      "365 \t: Episode || Reward:  226.69171694645308 \t|| Average Reward:  114.41427141385923 \t epsilon:  0.15967890763313974\n",
      "366 \t: Episode || Reward:  264.1052029386722 \t|| Average Reward:  115.93889269071245 \t epsilon:  0.15888051309497406\n",
      "367 \t: Episode || Reward:  254.93951970808763 \t|| Average Reward:  118.52105573561455 \t epsilon:  0.1580861105294992\n",
      "368 \t: Episode || Reward:  237.38978600419975 \t|| Average Reward:  119.8461546368468 \t epsilon:  0.1572956799768517\n",
      "369 \t: Episode || Reward:  246.05537773800856 \t|| Average Reward:  120.75541213268347 \t epsilon:  0.15650920157696743\n",
      "370 \t: Episode || Reward:  214.05571139632383 \t|| Average Reward:  120.3650203833498 \t epsilon:  0.1557266555690826\n",
      "371 \t: Episode || Reward:  194.73551524156898 \t|| Average Reward:  122.19110578300884 \t epsilon:  0.1549480222912372\n",
      "372 \t: Episode || Reward:  242.9897080039588 \t|| Average Reward:  125.58830496095835 \t epsilon:  0.15417328217978102\n",
      "373 \t: Episode || Reward:  229.9266385254257 \t|| Average Reward:  126.85450654256083 \t epsilon:  0.1534024157688821\n",
      "374 \t: Episode || Reward:  264.5333567348403 \t|| Average Reward:  127.97526212214976 \t epsilon:  0.1526354036900377\n",
      "375 \t: Episode || Reward:  259.69459737316754 \t|| Average Reward:  129.55174824634204 \t epsilon:  0.1518722266715875\n",
      "376 \t: Episode || Reward:  275.1939197353347 \t|| Average Reward:  132.17186805677622 \t epsilon:  0.15111286553822956\n",
      "377 \t: Episode || Reward:  250.35877531401277 \t|| Average Reward:  133.29277075772094 \t epsilon:  0.15035730121053842\n",
      "378 \t: Episode || Reward:  260.9148557089528 \t|| Average Reward:  134.66274092779884 \t epsilon:  0.14960551470448571\n",
      "379 \t: Episode || Reward:  258.51409941928364 \t|| Average Reward:  135.95512395574303 \t epsilon:  0.14885748713096328\n",
      "380 \t: Episode || Reward:  243.71570903344139 \t|| Average Reward:  136.04108635699805 \t epsilon:  0.14811319969530845\n",
      "381 \t: Episode || Reward:  247.7627773430263 \t|| Average Reward:  137.79732434494974 \t epsilon:  0.1473726336968319\n",
      "382 \t: Episode || Reward:  247.3546940448383 \t|| Average Reward:  139.26222410601633 \t epsilon:  0.14663577052834775\n",
      "383 \t: Episode || Reward:  243.94000481254182 \t|| Average Reward:  140.85034215249996 \t epsilon:  0.14590259167570602\n",
      "384 \t: Episode || Reward:  250.24586187167486 \t|| Average Reward:  142.1983493553016 \t epsilon:  0.1451730787173275\n",
      "385 \t: Episode || Reward:  239.2653248577475 \t|| Average Reward:  144.63866610200122 \t epsilon:  0.14444721332374086\n",
      "386 \t: Episode || Reward:  262.24611616901416 \t|| Average Reward:  146.07194689825803 \t epsilon:  0.14372497725712216\n",
      "387 \t: Episode || Reward:  242.053026793549 \t|| Average Reward:  146.3873359440173 \t epsilon:  0.14300635237083656\n",
      "388 \t: Episode || Reward:  215.50586666718345 \t|| Average Reward:  148.7894958814974 \t epsilon:  0.14229132060898236\n",
      "389 \t: Episode || Reward:  270.67361005409987 \t|| Average Reward:  150.63917426931945 \t epsilon:  0.14157986400593744\n",
      "390 \t: Episode || Reward:  253.71124604613368 \t|| Average Reward:  151.7093202307571 \t epsilon:  0.14087196468590776\n",
      "391 \t: Episode || Reward:  265.07056999695453 \t|| Average Reward:  153.2806480508135 \t epsilon:  0.14016760486247823\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "env = gym.make('LunarLander-v2')\n",
    "# set seeds\n",
    "\n",
    "env.seed(21)\n",
    "np.random.seed(21)\n",
    "\n",
    "# setting up params\n",
    "lr = 0.001\n",
    "epsilon = 1.0\n",
    "epsilon_decay = 0.995\n",
    "gamma = 0.99\n",
    "training_episodes = 1000\n",
    "model = DQN(env, lr, gamma, epsilon, epsilon_decay)\n",
    "model.train(training_episodes, True)\n",
    "\n",
    "reward_df = pd.DataFrame(model.rewards_list)\n",
    "test_rewards = test_already_trained_model(trained_model)\n",
    "\n",
    "plot_df(reward_df, \"Figure 1: Reward for each training episode\", \"Reward for each training episode\", \"Episode\",\"Reward\")\n",
    "plot_df2(pd.DataFrame(test_rewards), \"Figure 2: Reward for each testing episode\",\"Reward for each testing episode\", \"Episode\", \"Reward\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e135ac6",
   "metadata": {},
   "source": [
    "## Monte Carlo\n",
    "https://github.com/omargup/Lunar-Lander/blob/master/Monte_Carlo_LunarLander.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6dc07d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "025359e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_buckets_and_actions():\n",
    "    number_of_buckets = (5,5,5,5,5,5,2,2) #buckets in each dimension\n",
    "    number_of_actions = env.action_space.n\n",
    "    \n",
    "    #Creating a 2-tuple with the original bounds of each dimension\n",
    "    state_value_bounds = list(zip(env.observation_space.low,env.observation_space.high))\n",
    "    \n",
    "    #New bound values for each dimension\n",
    "    state_value_bounds[0] = [-1,1]      #Position x\n",
    "    state_value_bounds[1] = [-1,1]    #Position y\n",
    "    state_value_bounds[2] = [-1,1]        #vel x\n",
    "    state_value_bounds[3] = [-1,1]    #vel y\n",
    "    state_value_bounds[4] = [-1,1]        #angle\n",
    "    state_value_bounds[5] = [-1,1]        #angular vel\n",
    "    state_value_bounds[6] = [0,1]\n",
    "    state_value_bounds[7] = [0,1]\n",
    "    \n",
    "    return number_of_buckets, number_of_actions, state_value_bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "952e249c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def bucketize(state):\n",
    "    bucket_indexes = []\n",
    "    for i in range(len(state)):\n",
    "        if state[i] <= state_value_bounds[i][0]:\n",
    "            bucket_index = 0\n",
    "        elif state[i] >= state_value_bounds[i][1]:\n",
    "            bucket_index = number_of_buckets[i] - 1\n",
    "        else:\n",
    "            bound_width = state_value_bounds[i][1] - state_value_bounds[i][0]\n",
    "            offset = (number_of_buckets[i]-1) * state_value_bounds[i][0]/bound_width\n",
    "            scaling = (number_of_buckets[i]-1) / bound_width\n",
    "            bucket_index = int(round(scaling*state[i] - offset))\n",
    "        bucket_indexes.append(bucket_index)\n",
    "    return tuple(bucket_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f97cb3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def initialize_q_table():\n",
    "    return np.zeros(number_of_buckets + (number_of_actions,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd500987",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_visits_table():\n",
    "    return np.zeros(number_of_buckets + (number_of_actions,))\n",
    "\n",
    "def decay_function(episode):\n",
    "    return max(min_epsilon, min(max_epsilon, 1.0 - \n",
    "                              math.log10((episode + 1) / (total_train_episodes*0.1))))\n",
    "\n",
    "\n",
    "def choose_action(q_table, bucket_state, epsilon):\n",
    "    if (np.random.random() <= epsilon):\n",
    "        #print(\"random\")\n",
    "        return env.action_space.sample() #Exploration\n",
    "    else:\n",
    "        #print(\"greedy\")\n",
    "        return np.argmax(q_table[bucket_state]) #Eplotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f79e368c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ******* Generate an episode following pi: S0, A0, R1, ...S_T-1,A_T-1,R_T\n",
    "def Generate_episode(epsilon, q_table, max_env_steps):\n",
    "    # Control variables\n",
    "    total_reward = 0\n",
    "    done = False\n",
    "        \n",
    "    trayectory = []\n",
    "        \n",
    "    # Initialize S\n",
    "    # Reset the environment getting the initial state\n",
    "    bucket_state = bucketize(env.reset())\n",
    "\n",
    "    # Loop for each step of episode:\n",
    "    for step in range(max_env_steps):\n",
    "            #print(\"step \", step)\n",
    "\n",
    "        # Choose A from S using a soft policy derived from Q (e.g., epsilon-greedy)\n",
    "        action = choose_action(q_table, bucket_state, epsilon)\n",
    "            #print(q_table[bucket_state])\n",
    "            #print(\"action \", action)\n",
    "\n",
    "        # Take the action A, observe R, S'\n",
    "        new_state, reward, done, info = env.step(action)\n",
    "        bucket_new_state = bucketize(new_state)\n",
    "            #print(\"reward \", reward)\n",
    "            \n",
    "        trayectory.append([bucket_state, action, reward])\n",
    "            \n",
    "        # new_state is now the current state\n",
    "        bucket_state = bucket_new_state\n",
    "\n",
    "        total_reward += reward\n",
    "\n",
    "        # if done, finish the episode\n",
    "        if done:\n",
    "            break\n",
    "    \n",
    "    return trayectory, total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03baf4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Monte_Carlo():\n",
    "    # ******* Initialize (s,a) arbitrarily.\n",
    "    q_table = initialize_q_table()\n",
    "    #print(\"Q_Table shape: \", q_table.shape)\n",
    "    \n",
    "    # ******* Initialize Returns(s,a) empty list\n",
    "    # initialize visits_counter instead (for incremental implementation of the average)\n",
    "    visits_counter = initialize_visits_table()\n",
    "    \n",
    "    rewards = []\n",
    "    \n",
    "    max_env_steps = env._max_episode_steps   #1000 in LunarLander\n",
    "    #print(\"Max env steps: \", max_env_steps)\n",
    "    \n",
    "\n",
    "    \n",
    "    # ******* Loop for each episode:\n",
    "    for episode in range(total_train_episodes):\n",
    "        #print(\"\\n\\n ***Episode*** \", episode)\n",
    "        \n",
    "        # ******* Generate an episode following pi: S0, A0, R1, ...S_T-1,A_T-1,R_T\n",
    "        #Update epsilon\n",
    "        epsilon = decay_function(episode)\n",
    "        #print(\"Epsilon \", epsilon)\n",
    "        trayectory ,total_reward = Generate_episode(epsilon, q_table, max_env_steps)\n",
    "        \n",
    "        # ******* G <-- 0\n",
    "        G = 0\n",
    "        \n",
    "        \n",
    "        # ******* Loop for each step of episode: t = T-1, T-2, ..., 0\n",
    "        for t in reversed(range(len(trayectory))):\n",
    "            #print(\"\\n step\", t)\n",
    "            s_t, a_t, r_t = trayectory[t]\n",
    "            # ******* G <-- gamma*G + R_{t+1}\n",
    "            G = gamma*G + r_t\n",
    "            #print(\"G \", G)\n",
    "            \n",
    "            # ******* Unless the pair S_t,A_t appears in S_0,A_0,R_1, ...,S_{t-1},A_{t-1}: \n",
    "            if not [s_t, a_t] in [[x[0], x[1]] for x in trayectory[0:t]]:\n",
    "                #print(\"YES First visit \", s_t, a_t)\n",
    "                \n",
    "                # ******* Append G to Returns(S_t,A_t)\n",
    "                # ******* Q(S_t,A_t) <-- average(Returns(S_t,A_t))\n",
    "                # Using incremental implementation: Q(S_t,A_t)= Q_n <-- Q_n + (1/n)*(G_n - Q_n)\n",
    "                visits_counter[s_t][a_t] += 1\n",
    "                #print(\"visits_counter \", visits_counter[s_t][a_t])\n",
    "                #print(\"old Q value \", q_table[s_t][a_t])\n",
    "                q_table[s_t][a_t] += (G - q_table[s_t][a_t]) / visits_counter[s_t][a_t]\n",
    "                #print(\"new Q value \", q_table[s_t][a_t])\n",
    "            #else: print(\"NO first visit \", s_t, a_t)\n",
    "        \n",
    "                  \n",
    "        #print(\"total_reward \", total_reward)\n",
    "        \n",
    "        if episode % 50 == 0:\n",
    "            rewards.append(total_reward)\n",
    "            print(\"Episode {}, epsilon {:5.4f}, reward {:6.2f}\".format(episode,epsilon,total_reward))  \n",
    "    \n",
    "    rewards.append(total_reward)\n",
    "    print(\"Episode {}, epsilon {:5.4f}, reward {:6.2f}\".format(episode,epsilon,total_reward))\n",
    "    return q_table, rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "405bcfd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ********** Training number  0\n",
      "Episode 0, epsilon 1.0000, reward -122.01\n",
      "Episode 50, epsilon 1.0000, reward  14.67\n",
      "Episode 100, epsilon 1.0000, reward -204.37\n",
      "Episode 150, epsilon 1.0000, reward  42.49\n",
      "Episode 200, epsilon 1.0000, reward -216.81\n",
      "Episode 250, epsilon 1.0000, reward -99.47\n",
      "Episode 300, epsilon 1.0000, reward -253.94\n",
      "Episode 350, epsilon 1.0000, reward -247.39\n",
      "Episode 400, epsilon 1.0000, reward -358.04\n",
      "Episode 450, epsilon 1.0000, reward -319.43\n",
      "Episode 500, epsilon 1.0000, reward  24.94\n",
      "Episode 550, epsilon 1.0000, reward -389.87\n",
      "Episode 600, epsilon 1.0000, reward -130.25\n",
      "Episode 650, epsilon 1.0000, reward -87.05\n",
      "Episode 700, epsilon 1.0000, reward -336.94\n",
      "Episode 750, epsilon 1.0000, reward -126.65\n",
      "Episode 800, epsilon 1.0000, reward -235.24\n",
      "Episode 850, epsilon 1.0000, reward -346.80\n",
      "Episode 900, epsilon 1.0000, reward -320.60\n",
      "Episode 950, epsilon 1.0000, reward -137.08\n",
      "Episode 1000, epsilon 0.9996, reward -68.33\n",
      "Episode 1050, epsilon 0.9784, reward -212.40\n",
      "Episode 1100, epsilon 0.9582, reward -353.83\n",
      "Episode 1150, epsilon 0.9389, reward -179.20\n",
      "Episode 1200, epsilon 0.9205, reward -301.39\n",
      "Episode 1250, epsilon 0.9027, reward -145.90\n",
      "Episode 1300, epsilon 0.8857, reward -125.25\n",
      "Episode 1350, epsilon 0.8693, reward -69.05\n",
      "Episode 1400, epsilon 0.8536, reward -312.17\n",
      "Episode 1450, epsilon 0.8383, reward -144.18\n",
      "Episode 1500, epsilon 0.8236, reward -205.17\n",
      "Episode 1550, epsilon 0.8094, reward -102.37\n",
      "Episode 1600, epsilon 0.7956, reward -285.78\n",
      "Episode 1650, epsilon 0.7823, reward -98.86\n",
      "Episode 1700, epsilon 0.7693, reward -110.96\n",
      "Episode 1750, epsilon 0.7567, reward -82.74\n",
      "Episode 1800, epsilon 0.7445, reward -76.11\n",
      "Episode 1850, epsilon 0.7326, reward -73.62\n",
      "Episode 1900, epsilon 0.7210, reward -97.77\n",
      "Episode 1950, epsilon 0.7097, reward -96.26\n",
      "Episode 2000, epsilon 0.6988, reward -54.67\n",
      "Episode 2050, epsilon 0.6880, reward -90.54\n",
      "Episode 2100, epsilon 0.6776, reward -166.90\n",
      "Episode 2150, epsilon 0.6674, reward -56.62\n",
      "Episode 2200, epsilon 0.6574, reward -83.30\n",
      "Episode 2250, epsilon 0.6476, reward -122.24\n",
      "Episode 2300, epsilon 0.6381, reward  19.53\n",
      "Episode 2350, epsilon 0.6287, reward -196.88\n",
      "Episode 2400, epsilon 0.6196, reward -41.18\n",
      "Episode 2450, epsilon 0.6107, reward -106.17\n",
      "Episode 2500, epsilon 0.6019, reward -154.94\n",
      "Episode 2550, epsilon 0.5933, reward -42.05\n",
      "Episode 2600, epsilon 0.5849, reward -81.86\n",
      "Episode 2650, epsilon 0.5766, reward -108.18\n",
      "Episode 2700, epsilon 0.5685, reward -69.73\n",
      "Episode 2750, epsilon 0.5605, reward -62.60\n",
      "Episode 2800, epsilon 0.5527, reward -201.26\n",
      "Episode 2850, epsilon 0.5450, reward -91.61\n",
      "Episode 2900, epsilon 0.5375, reward -108.62\n",
      "Episode 2950, epsilon 0.5300, reward -252.45\n",
      "Episode 3000, epsilon 0.5227, reward  -9.52\n",
      "Episode 3050, epsilon 0.5156, reward -77.63\n",
      "Episode 3100, epsilon 0.5085, reward  11.15\n",
      "Episode 3150, epsilon 0.5016, reward -91.45\n",
      "Episode 3200, epsilon 0.4947, reward -44.18\n",
      "Episode 3250, epsilon 0.4880, reward -42.69\n",
      "Episode 3300, epsilon 0.4814, reward -37.26\n",
      "Episode 3350, epsilon 0.4748, reward -56.16\n",
      "Episode 3400, epsilon 0.4684, reward -200.49\n",
      "Episode 3450, epsilon 0.4621, reward -58.49\n",
      "Episode 3500, epsilon 0.4558, reward  -4.90\n",
      "Episode 3550, epsilon 0.4496, reward -77.74\n",
      "Episode 3600, epsilon 0.4436, reward -244.21\n",
      "Episode 3650, epsilon 0.4376, reward -20.23\n",
      "Episode 3700, epsilon 0.4317, reward -31.31\n",
      "Episode 3750, epsilon 0.4259, reward -98.64\n",
      "Episode 3800, epsilon 0.4201, reward -80.32\n",
      "Episode 3850, epsilon 0.4144, reward -67.20\n",
      "Episode 3900, epsilon 0.4088, reward -231.38\n",
      "Episode 3950, epsilon 0.4033, reward -33.55\n",
      "Episode 4000, epsilon 0.3978, reward -93.69\n",
      "Episode 4050, epsilon 0.3924, reward  58.13\n",
      "Episode 4100, epsilon 0.3871, reward  -3.75\n",
      "Episode 4150, epsilon 0.3818, reward  -2.45\n",
      "Episode 4200, epsilon 0.3766, reward -112.47\n",
      "Episode 4250, epsilon 0.3715, reward  -2.08\n",
      "Episode 4300, epsilon 0.3664, reward -25.07\n",
      "Episode 4350, epsilon 0.3614, reward  14.59\n",
      "Episode 4400, epsilon 0.3564, reward  17.09\n",
      "Episode 4450, epsilon 0.3515, reward   5.50\n",
      "Episode 4500, epsilon 0.3467, reward -49.98\n",
      "Episode 4550, epsilon 0.3419, reward -107.63\n",
      "Episode 4600, epsilon 0.3371, reward -50.70\n",
      "Episode 4650, epsilon 0.3325, reward -28.78\n",
      "Episode 4700, epsilon 0.3278, reward -13.53\n",
      "Episode 4750, epsilon 0.3232, reward -47.10\n",
      "Episode 4800, epsilon 0.3187, reward -19.62\n",
      "Episode 4850, epsilon 0.3142, reward -85.66\n",
      "Episode 4900, epsilon 0.3097, reward -39.50\n",
      "Episode 4950, epsilon 0.3053, reward -56.99\n",
      "Episode 5000, epsilon 0.3009, reward -16.69\n",
      "Episode 5050, epsilon 0.2966, reward -22.95\n",
      "Episode 5100, epsilon 0.2923, reward -152.14\n",
      "Episode 5150, epsilon 0.2881, reward  -8.14\n",
      "Episode 5200, epsilon 0.2839, reward -79.34\n",
      "Episode 5250, epsilon 0.2798, reward   7.49\n",
      "Episode 5300, epsilon 0.2756, reward -17.70\n",
      "Episode 5350, epsilon 0.2716, reward  57.68\n",
      "Episode 5400, epsilon 0.2675, reward  95.75\n",
      "Episode 5450, epsilon 0.2635, reward -16.09\n",
      "Episode 5500, epsilon 0.2596, reward -29.70\n",
      "Episode 5550, epsilon 0.2556, reward  31.08\n",
      "Episode 5600, epsilon 0.2517, reward  33.13\n",
      "Episode 5650, epsilon 0.2479, reward -66.50\n",
      "Episode 5700, epsilon 0.2440, reward  15.02\n",
      "Episode 5750, epsilon 0.2403, reward   4.24\n",
      "Episode 5800, epsilon 0.2365, reward -61.00\n",
      "Episode 5850, epsilon 0.2328, reward   3.69\n",
      "Episode 5900, epsilon 0.2291, reward -76.94\n",
      "Episode 5950, epsilon 0.2254, reward -44.77\n",
      "Episode 6000, epsilon 0.2218, reward 228.02\n",
      "Episode 6050, epsilon 0.2182, reward -66.06\n",
      "Episode 6100, epsilon 0.2146, reward -67.42\n",
      "Episode 6150, epsilon 0.2111, reward  -4.17\n",
      "Episode 6200, epsilon 0.2075, reward   4.18\n",
      "Episode 6250, epsilon 0.2041, reward -18.44\n",
      "Episode 6300, epsilon 0.2006, reward -91.20\n",
      "Episode 6350, epsilon 0.1972, reward  -9.56\n",
      "Episode 6400, epsilon 0.1938, reward  27.38\n",
      "Episode 6450, epsilon 0.1904, reward   5.59\n",
      "Episode 6500, epsilon 0.1870, reward -16.55\n",
      "Episode 6550, epsilon 0.1837, reward  -4.43\n",
      "Episode 6600, epsilon 0.1804, reward  14.88\n",
      "Episode 6650, epsilon 0.1771, reward -37.91\n",
      "Episode 6700, epsilon 0.1739, reward -82.43\n",
      "Episode 6750, epsilon 0.1706, reward -218.65\n",
      "Episode 6800, epsilon 0.1674, reward  20.66\n",
      "Episode 6850, epsilon 0.1642, reward  35.60\n",
      "Episode 6900, epsilon 0.1611, reward -10.75\n",
      "Episode 6950, epsilon 0.1580, reward  -9.91\n",
      "Episode 7000, epsilon 0.1548, reward -21.33\n",
      "Episode 7050, epsilon 0.1517, reward  67.90\n",
      "Episode 7100, epsilon 0.1487, reward -139.21\n",
      "Episode 7150, epsilon 0.1456, reward -29.47\n",
      "Episode 7200, epsilon 0.1426, reward 300.45\n",
      "Episode 7250, epsilon 0.1396, reward -45.71\n",
      "Episode 7300, epsilon 0.1366, reward 223.73\n",
      "Episode 7350, epsilon 0.1337, reward -89.17\n",
      "Episode 7400, epsilon 0.1307, reward  18.02\n",
      "Episode 7450, epsilon 0.1278, reward  26.49\n",
      "Episode 7500, epsilon 0.1249, reward 238.09\n",
      "Episode 7550, epsilon 0.1220, reward -13.46\n",
      "Episode 7600, epsilon 0.1191, reward  77.03\n",
      "Episode 7650, epsilon 0.1163, reward  41.31\n",
      "Episode 7700, epsilon 0.1135, reward -250.89\n",
      "Episode 7750, epsilon 0.1106, reward  -6.89\n",
      "Episode 7800, epsilon 0.1078, reward -23.43\n",
      "Episode 7850, epsilon 0.1051, reward -13.75\n",
      "Episode 7900, epsilon 0.1023, reward  97.88\n",
      "Episode 7950, epsilon 0.0996, reward 216.78\n",
      "Episode 8000, epsilon 0.0969, reward 291.26\n",
      "Episode 8050, epsilon 0.0942, reward -187.97\n",
      "Episode 8100, epsilon 0.0915, reward  35.46\n",
      "Episode 8150, epsilon 0.0888, reward  29.32\n",
      "Episode 8200, epsilon 0.0861, reward  21.00\n",
      "Episode 8250, epsilon 0.0835, reward 234.44\n",
      "Episode 8300, epsilon 0.0809, reward 291.01\n",
      "Episode 8350, epsilon 0.0783, reward  20.64\n",
      "Episode 8400, epsilon 0.0757, reward  -7.32\n",
      "Episode 8450, epsilon 0.0731, reward -29.03\n",
      "Episode 8500, epsilon 0.0705, reward  -7.21\n",
      "Episode 8550, epsilon 0.0680, reward   5.05\n",
      "Episode 8600, epsilon 0.0655, reward -17.71\n",
      "Episode 8650, epsilon 0.0629, reward 231.24\n",
      "Episode 8700, epsilon 0.0604, reward  52.25\n",
      "Episode 8750, epsilon 0.0579, reward 160.61\n",
      "Episode 8800, epsilon 0.0555, reward 134.90\n",
      "Episode 8850, epsilon 0.0530, reward -27.54\n",
      "Episode 8900, epsilon 0.0506, reward 183.40\n",
      "Episode 8950, epsilon 0.0481, reward  90.45\n",
      "Episode 9000, epsilon 0.0457, reward -26.72\n",
      "Episode 9050, epsilon 0.0433, reward 168.79\n",
      "Episode 9100, epsilon 0.0409, reward -18.78\n",
      "Episode 9150, epsilon 0.0385, reward 217.99\n",
      "Episode 9200, epsilon 0.0362, reward 241.89\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 9250, epsilon 0.0338, reward -59.08\n",
      "Episode 9300, epsilon 0.0315, reward -87.42\n",
      "Episode 9350, epsilon 0.0291, reward -18.64\n",
      "Episode 9400, epsilon 0.0268, reward -49.18\n",
      "Episode 9450, epsilon 0.0245, reward 239.12\n",
      "Episode 9500, epsilon 0.0222, reward -10.74\n",
      "Episode 9550, epsilon 0.0200, reward 227.33\n",
      "Episode 9600, epsilon 0.0177, reward 218.41\n",
      "Episode 9650, epsilon 0.0154, reward  71.38\n",
      "Episode 9700, epsilon 0.0132, reward -30.43\n",
      "Episode 9750, epsilon 0.0110, reward -63.06\n",
      "Episode 9800, epsilon 0.0100, reward  40.92\n",
      "Episode 9850, epsilon 0.0100, reward  12.91\n",
      "Episode 9900, epsilon 0.0100, reward 226.69\n",
      "Episode 9950, epsilon 0.0100, reward  49.02\n",
      "Episode 9999, epsilon 0.0100, reward -56.56\n",
      "\n",
      " ********** Training number  1\n",
      "Episode 0, epsilon 1.0000, reward -72.16\n",
      "Episode 50, epsilon 1.0000, reward -154.04\n",
      "Episode 100, epsilon 1.0000, reward -157.72\n",
      "Episode 150, epsilon 1.0000, reward -279.46\n",
      "Episode 200, epsilon 1.0000, reward -310.27\n",
      "Episode 250, epsilon 1.0000, reward -109.21\n",
      "Episode 300, epsilon 1.0000, reward -397.17\n",
      "Episode 350, epsilon 1.0000, reward -219.41\n",
      "Episode 400, epsilon 1.0000, reward -73.24\n",
      "Episode 450, epsilon 1.0000, reward -278.65\n",
      "Episode 500, epsilon 1.0000, reward -376.90\n",
      "Episode 550, epsilon 1.0000, reward -259.02\n",
      "Episode 600, epsilon 1.0000, reward -154.17\n",
      "Episode 650, epsilon 1.0000, reward -147.46\n",
      "Episode 700, epsilon 1.0000, reward -136.25\n",
      "Episode 750, epsilon 1.0000, reward -92.06\n",
      "Episode 800, epsilon 1.0000, reward -58.75\n",
      "Episode 850, epsilon 1.0000, reward -96.77\n",
      "Episode 900, epsilon 1.0000, reward -232.30\n",
      "Episode 950, epsilon 1.0000, reward -478.79\n",
      "Episode 1000, epsilon 0.9996, reward -174.10\n",
      "Episode 1050, epsilon 0.9784, reward -103.01\n",
      "Episode 1100, epsilon 0.9582, reward -177.77\n",
      "Episode 1150, epsilon 0.9389, reward -66.64\n",
      "Episode 1200, epsilon 0.9205, reward -67.95\n",
      "Episode 1250, epsilon 0.9027, reward -402.17\n",
      "Episode 1300, epsilon 0.8857, reward -83.47\n",
      "Episode 1350, epsilon 0.8693, reward -173.41\n",
      "Episode 1400, epsilon 0.8536, reward -10.73\n",
      "Episode 1450, epsilon 0.8383, reward -363.60\n",
      "Episode 1500, epsilon 0.8236, reward -81.39\n",
      "Episode 1550, epsilon 0.8094, reward -122.47\n",
      "Episode 1600, epsilon 0.7956, reward -111.27\n",
      "Episode 1650, epsilon 0.7823, reward -92.02\n",
      "Episode 1700, epsilon 0.7693, reward  -2.79\n",
      "Episode 1750, epsilon 0.7567, reward -186.55\n",
      "Episode 1800, epsilon 0.7445, reward  15.10\n",
      "Episode 1850, epsilon 0.7326, reward -83.05\n",
      "Episode 1900, epsilon 0.7210, reward -109.96\n",
      "Episode 1950, epsilon 0.7097, reward -60.65\n",
      "Episode 2000, epsilon 0.6988, reward -346.25\n",
      "Episode 2050, epsilon 0.6880, reward -30.12\n",
      "Episode 2100, epsilon 0.6776, reward -82.42\n",
      "Episode 2150, epsilon 0.6674, reward -85.75\n",
      "Episode 2200, epsilon 0.6574, reward -83.17\n",
      "Episode 2250, epsilon 0.6476, reward -61.31\n",
      "Episode 2300, epsilon 0.6381, reward -25.82\n",
      "Episode 2350, epsilon 0.6287, reward -95.58\n",
      "Episode 2400, epsilon 0.6196, reward -91.62\n",
      "Episode 2450, epsilon 0.6107, reward -64.94\n",
      "Episode 2500, epsilon 0.6019, reward -195.80\n",
      "Episode 2550, epsilon 0.5933, reward -87.33\n",
      "Episode 2600, epsilon 0.5849, reward -77.70\n",
      "Episode 2650, epsilon 0.5766, reward -184.72\n",
      "Episode 2700, epsilon 0.5685, reward -130.85\n",
      "Episode 2750, epsilon 0.5605, reward -96.72\n",
      "Episode 2800, epsilon 0.5527, reward -279.05\n",
      "Episode 2850, epsilon 0.5450, reward -107.88\n",
      "Episode 2900, epsilon 0.5375, reward -10.61\n",
      "Episode 2950, epsilon 0.5300, reward  50.28\n",
      "Episode 3000, epsilon 0.5227, reward -35.94\n",
      "Episode 3050, epsilon 0.5156, reward  -2.83\n",
      "Episode 3100, epsilon 0.5085, reward  -0.87\n",
      "Episode 3150, epsilon 0.5016, reward -22.84\n",
      "Episode 3200, epsilon 0.4947, reward -98.02\n",
      "Episode 3250, epsilon 0.4880, reward -37.88\n",
      "Episode 3300, epsilon 0.4814, reward -48.40\n",
      "Episode 3350, epsilon 0.4748, reward -56.83\n",
      "Episode 3400, epsilon 0.4684, reward  65.22\n",
      "Episode 3450, epsilon 0.4621, reward -103.86\n",
      "Episode 3500, epsilon 0.4558, reward -82.29\n",
      "Episode 3550, epsilon 0.4496, reward   8.93\n",
      "Episode 3600, epsilon 0.4436, reward -95.55\n",
      "Episode 3650, epsilon 0.4376, reward -117.61\n",
      "Episode 3700, epsilon 0.4317, reward -27.23\n",
      "Episode 3750, epsilon 0.4259, reward -81.42\n",
      "Episode 3800, epsilon 0.4201, reward -37.99\n",
      "Episode 3850, epsilon 0.4144, reward -43.70\n",
      "Episode 3900, epsilon 0.4088, reward -14.17\n",
      "Episode 3950, epsilon 0.4033, reward  18.73\n",
      "Episode 4000, epsilon 0.3978, reward -98.35\n",
      "Episode 4050, epsilon 0.3924, reward -119.23\n",
      "Episode 4100, epsilon 0.3871, reward -66.32\n",
      "Episode 4150, epsilon 0.3818, reward   8.02\n",
      "Episode 4200, epsilon 0.3766, reward   6.88\n",
      "Episode 4250, epsilon 0.3715, reward -66.09\n",
      "Episode 4300, epsilon 0.3664, reward -86.85\n",
      "Episode 4350, epsilon 0.3614, reward -57.99\n",
      "Episode 4400, epsilon 0.3564, reward   4.34\n",
      "Episode 4450, epsilon 0.3515, reward -64.54\n",
      "Episode 4500, epsilon 0.3467, reward -56.79\n",
      "Episode 4550, epsilon 0.3419, reward   1.16\n",
      "Episode 4600, epsilon 0.3371, reward -29.28\n",
      "Episode 4650, epsilon 0.3325, reward -90.26\n",
      "Episode 4700, epsilon 0.3278, reward -41.80\n",
      "Episode 4750, epsilon 0.3232, reward -70.54\n",
      "Episode 4800, epsilon 0.3187, reward -47.69\n",
      "Episode 4850, epsilon 0.3142, reward -111.28\n",
      "Episode 4900, epsilon 0.3097, reward -16.21\n",
      "Episode 4950, epsilon 0.3053, reward  35.13\n",
      "Episode 5000, epsilon 0.3009, reward -23.24\n",
      "Episode 5050, epsilon 0.2966, reward -64.78\n",
      "Episode 5100, epsilon 0.2923, reward -16.25\n",
      "Episode 5150, epsilon 0.2881, reward -40.91\n",
      "Episode 5200, epsilon 0.2839, reward -22.91\n",
      "Episode 5250, epsilon 0.2798, reward -210.43\n",
      "Episode 5300, epsilon 0.2756, reward  -2.29\n",
      "Episode 5350, epsilon 0.2716, reward -27.81\n",
      "Episode 5400, epsilon 0.2675, reward  58.69\n",
      "Episode 5450, epsilon 0.2635, reward  75.46\n",
      "Episode 5500, epsilon 0.2596, reward -53.79\n",
      "Episode 5550, epsilon 0.2556, reward -12.21\n",
      "Episode 5600, epsilon 0.2517, reward -50.51\n",
      "Episode 5650, epsilon 0.2479, reward -172.80\n",
      "Episode 5700, epsilon 0.2440, reward   2.58\n",
      "Episode 5750, epsilon 0.2403, reward  16.29\n",
      "Episode 5800, epsilon 0.2365, reward -59.12\n",
      "Episode 5850, epsilon 0.2328, reward 254.80\n",
      "Episode 5900, epsilon 0.2291, reward -39.16\n",
      "Episode 5950, epsilon 0.2254, reward  35.97\n",
      "Episode 6000, epsilon 0.2218, reward  -0.62\n",
      "Episode 6050, epsilon 0.2182, reward -11.84\n",
      "Episode 6100, epsilon 0.2146, reward -41.17\n",
      "Episode 6150, epsilon 0.2111, reward -39.84\n",
      "Episode 6200, epsilon 0.2075, reward -18.34\n",
      "Episode 6250, epsilon 0.2041, reward -208.56\n",
      "Episode 6300, epsilon 0.2006, reward -16.05\n",
      "Episode 6350, epsilon 0.1972, reward -18.98\n",
      "Episode 6400, epsilon 0.1938, reward -27.73\n",
      "Episode 6450, epsilon 0.1904, reward -14.05\n",
      "Episode 6500, epsilon 0.1870, reward  77.22\n",
      "Episode 6550, epsilon 0.1837, reward -68.91\n",
      "Episode 6600, epsilon 0.1804, reward -61.66\n",
      "Episode 6650, epsilon 0.1771, reward -142.99\n",
      "Episode 6700, epsilon 0.1739, reward -50.55\n",
      "Episode 6750, epsilon 0.1706, reward  22.42\n",
      "Episode 6800, epsilon 0.1674, reward   2.84\n",
      "Episode 6850, epsilon 0.1642, reward 244.11\n",
      "Episode 6900, epsilon 0.1611, reward 271.50\n",
      "Episode 6950, epsilon 0.1580, reward  49.52\n",
      "Episode 7000, epsilon 0.1548, reward -133.14\n",
      "Episode 7050, epsilon 0.1517, reward 160.80\n",
      "Episode 7100, epsilon 0.1487, reward  96.89\n",
      "Episode 7150, epsilon 0.1456, reward  25.58\n",
      "Episode 7200, epsilon 0.1426, reward -247.48\n",
      "Episode 7250, epsilon 0.1396, reward  76.11\n",
      "Episode 7300, epsilon 0.1366, reward 303.43\n",
      "Episode 7350, epsilon 0.1337, reward 231.64\n",
      "Episode 7400, epsilon 0.1307, reward -22.25\n",
      "Episode 7450, epsilon 0.1278, reward -183.05\n",
      "Episode 7500, epsilon 0.1249, reward 178.30\n",
      "Episode 7550, epsilon 0.1220, reward -22.28\n",
      "Episode 7600, epsilon 0.1191, reward  32.89\n",
      "Episode 7650, epsilon 0.1163, reward -35.33\n",
      "Episode 7700, epsilon 0.1135, reward -57.38\n",
      "Episode 7750, epsilon 0.1106, reward 125.71\n",
      "Episode 7800, epsilon 0.1078, reward 106.41\n",
      "Episode 7850, epsilon 0.1051, reward -55.52\n",
      "Episode 7900, epsilon 0.1023, reward 132.26\n",
      "Episode 7950, epsilon 0.0996, reward 116.88\n",
      "Episode 8000, epsilon 0.0969, reward  36.09\n",
      "Episode 8050, epsilon 0.0942, reward  62.47\n",
      "Episode 8100, epsilon 0.0915, reward -29.28\n",
      "Episode 8150, epsilon 0.0888, reward 272.12\n",
      "Episode 8200, epsilon 0.0861, reward -13.00\n",
      "Episode 8250, epsilon 0.0835, reward 252.68\n",
      "Episode 8300, epsilon 0.0809, reward 244.14\n",
      "Episode 8350, epsilon 0.0783, reward  22.23\n",
      "Episode 8400, epsilon 0.0757, reward  11.16\n",
      "Episode 8450, epsilon 0.0731, reward 110.71\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 8500, epsilon 0.0705, reward   5.76\n",
      "Episode 8550, epsilon 0.0680, reward -95.80\n",
      "Episode 8600, epsilon 0.0655, reward -46.98\n",
      "Episode 8650, epsilon 0.0629, reward 265.94\n",
      "Episode 8700, epsilon 0.0604, reward  75.96\n",
      "Episode 8750, epsilon 0.0579, reward  12.63\n",
      "Episode 8800, epsilon 0.0555, reward  71.71\n",
      "Episode 8850, epsilon 0.0530, reward -182.52\n",
      "Episode 8900, epsilon 0.0506, reward 172.36\n",
      "Episode 8950, epsilon 0.0481, reward -94.58\n",
      "Episode 9000, epsilon 0.0457, reward -56.18\n",
      "Episode 9050, epsilon 0.0433, reward 253.68\n",
      "Episode 9100, epsilon 0.0409, reward 273.64\n",
      "Episode 9150, epsilon 0.0385, reward  24.19\n",
      "Episode 9200, epsilon 0.0362, reward 281.03\n",
      "Episode 9250, epsilon 0.0338, reward 239.33\n",
      "Episode 9300, epsilon 0.0315, reward  62.04\n",
      "Episode 9350, epsilon 0.0291, reward -196.54\n",
      "Episode 9400, epsilon 0.0268, reward -44.89\n",
      "Episode 9450, epsilon 0.0245, reward 176.48\n",
      "Episode 9500, epsilon 0.0222, reward 147.45\n",
      "Episode 9550, epsilon 0.0200, reward -136.08\n",
      "Episode 9600, epsilon 0.0177, reward 156.16\n",
      "Episode 9650, epsilon 0.0154, reward 149.37\n",
      "Episode 9700, epsilon 0.0132, reward 130.63\n",
      "Episode 9750, epsilon 0.0110, reward 224.53\n",
      "Episode 9800, epsilon 0.0100, reward -33.28\n",
      "Episode 9850, epsilon 0.0100, reward  36.92\n",
      "Episode 9900, epsilon 0.0100, reward  -1.80\n",
      "Episode 9950, epsilon 0.0100, reward  49.37\n",
      "Episode 9999, epsilon 0.0100, reward 103.21\n",
      "\n",
      " ********** Training number  2\n",
      "Episode 0, epsilon 1.0000, reward -412.20\n",
      "Episode 50, epsilon 1.0000, reward -73.45\n",
      "Episode 100, epsilon 1.0000, reward -31.20\n",
      "Episode 150, epsilon 1.0000, reward -97.16\n",
      "Episode 200, epsilon 1.0000, reward -350.95\n",
      "Episode 250, epsilon 1.0000, reward -113.45\n",
      "Episode 300, epsilon 1.0000, reward -114.62\n",
      "Episode 350, epsilon 1.0000, reward -341.65\n",
      "Episode 400, epsilon 1.0000, reward -127.53\n",
      "Episode 450, epsilon 1.0000, reward -109.77\n",
      "Episode 500, epsilon 1.0000, reward -86.25\n",
      "Episode 550, epsilon 1.0000, reward -349.12\n",
      "Episode 600, epsilon 1.0000, reward -136.95\n",
      "Episode 650, epsilon 1.0000, reward -285.39\n",
      "Episode 700, epsilon 1.0000, reward -91.00\n",
      "Episode 750, epsilon 1.0000, reward -86.74\n",
      "Episode 800, epsilon 1.0000, reward -108.82\n",
      "Episode 850, epsilon 1.0000, reward -132.91\n",
      "Episode 900, epsilon 1.0000, reward -98.98\n",
      "Episode 950, epsilon 1.0000, reward -147.52\n",
      "Episode 1000, epsilon 0.9996, reward -125.93\n",
      "Episode 1050, epsilon 0.9784, reward -85.40\n",
      "Episode 1100, epsilon 0.9582, reward -111.21\n",
      "Episode 1150, epsilon 0.9389, reward -243.15\n",
      "Episode 1200, epsilon 0.9205, reward -106.28\n",
      "Episode 1250, epsilon 0.9027, reward -105.99\n",
      "Episode 1300, epsilon 0.8857, reward -85.43\n",
      "Episode 1350, epsilon 0.8693, reward -43.74\n",
      "Episode 1400, epsilon 0.8536, reward -97.17\n",
      "Episode 1450, epsilon 0.8383, reward -88.57\n",
      "Episode 1500, epsilon 0.8236, reward -185.39\n",
      "Episode 1550, epsilon 0.8094, reward -84.50\n",
      "Episode 1600, epsilon 0.7956, reward -46.89\n",
      "Episode 1650, epsilon 0.7823, reward  39.36\n",
      "Episode 1700, epsilon 0.7693, reward -163.84\n",
      "Episode 1750, epsilon 0.7567, reward -375.67\n",
      "Episode 1800, epsilon 0.7445, reward -75.38\n",
      "Episode 1850, epsilon 0.7326, reward   2.71\n",
      "Episode 1900, epsilon 0.7210, reward -77.21\n",
      "Episode 1950, epsilon 0.7097, reward -88.88\n",
      "Episode 2000, epsilon 0.6988, reward -114.46\n",
      "Episode 2050, epsilon 0.6880, reward -56.06\n",
      "Episode 2100, epsilon 0.6776, reward -76.11\n",
      "Episode 2150, epsilon 0.6674, reward -260.85\n",
      "Episode 2200, epsilon 0.6574, reward -14.86\n",
      "Episode 2250, epsilon 0.6476, reward -73.33\n",
      "Episode 2300, epsilon 0.6381, reward -101.30\n",
      "Episode 2350, epsilon 0.6287, reward -77.34\n",
      "Episode 2400, epsilon 0.6196, reward -75.05\n",
      "Episode 2450, epsilon 0.6107, reward -103.30\n",
      "Episode 2500, epsilon 0.6019, reward -84.31\n",
      "Episode 2550, epsilon 0.5933, reward -33.07\n",
      "Episode 2600, epsilon 0.5849, reward -88.99\n",
      "Episode 2650, epsilon 0.5766, reward -65.31\n",
      "Episode 2700, epsilon 0.5685, reward -146.57\n",
      "Episode 2750, epsilon 0.5605, reward -153.19\n",
      "Episode 2800, epsilon 0.5527, reward -59.32\n",
      "Episode 2850, epsilon 0.5450, reward -50.37\n",
      "Episode 2900, epsilon 0.5375, reward -27.93\n",
      "Episode 2950, epsilon 0.5300, reward -38.67\n",
      "Episode 3000, epsilon 0.5227, reward -109.38\n",
      "Episode 3050, epsilon 0.5156, reward -55.59\n",
      "Episode 3100, epsilon 0.5085, reward -73.27\n",
      "Episode 3150, epsilon 0.5016, reward -28.43\n",
      "Episode 3200, epsilon 0.4947, reward -60.60\n",
      "Episode 3250, epsilon 0.4880, reward -110.25\n",
      "Episode 3300, epsilon 0.4814, reward -90.88\n",
      "Episode 3350, epsilon 0.4748, reward -189.41\n",
      "Episode 3400, epsilon 0.4684, reward -69.95\n",
      "Episode 3450, epsilon 0.4621, reward -70.73\n",
      "Episode 3500, epsilon 0.4558, reward -89.77\n",
      "Episode 3550, epsilon 0.4496, reward -12.71\n",
      "Episode 3600, epsilon 0.4436, reward -28.07\n",
      "Episode 3650, epsilon 0.4376, reward -67.33\n",
      "Episode 3700, epsilon 0.4317, reward -41.30\n",
      "Episode 3750, epsilon 0.4259, reward -44.86\n",
      "Episode 3800, epsilon 0.4201, reward -34.87\n",
      "Episode 3850, epsilon 0.4144, reward -24.93\n",
      "Episode 3900, epsilon 0.4088, reward -62.37\n",
      "Episode 3950, epsilon 0.4033, reward -38.94\n",
      "Episode 4000, epsilon 0.3978, reward -26.19\n",
      "Episode 4050, epsilon 0.3924, reward -46.19\n",
      "Episode 4100, epsilon 0.3871, reward -29.60\n",
      "Episode 4150, epsilon 0.3818, reward -20.40\n",
      "Episode 4200, epsilon 0.3766, reward   7.42\n",
      "Episode 4250, epsilon 0.3715, reward  15.89\n",
      "Episode 4300, epsilon 0.3664, reward  -8.82\n",
      "Episode 4350, epsilon 0.3614, reward -90.86\n",
      "Episode 4400, epsilon 0.3564, reward -61.64\n",
      "Episode 4450, epsilon 0.3515, reward -26.07\n",
      "Episode 4500, epsilon 0.3467, reward -48.05\n",
      "Episode 4550, epsilon 0.3419, reward -78.43\n",
      "Episode 4600, epsilon 0.3371, reward -20.16\n",
      "Episode 4650, epsilon 0.3325, reward  -4.10\n",
      "Episode 4700, epsilon 0.3278, reward  -8.26\n",
      "Episode 4750, epsilon 0.3232, reward  -3.54\n",
      "Episode 4800, epsilon 0.3187, reward -10.20\n",
      "Episode 4850, epsilon 0.3142, reward -11.42\n",
      "Episode 4900, epsilon 0.3097, reward   5.25\n",
      "Episode 4950, epsilon 0.3053, reward -69.41\n",
      "Episode 5000, epsilon 0.3009, reward -38.42\n",
      "Episode 5050, epsilon 0.2966, reward -37.31\n",
      "Episode 5100, epsilon 0.2923, reward -92.79\n",
      "Episode 5150, epsilon 0.2881, reward   1.10\n",
      "Episode 5200, epsilon 0.2839, reward   6.05\n",
      "Episode 5250, epsilon 0.2798, reward   4.64\n",
      "Episode 5300, epsilon 0.2756, reward -293.10\n",
      "Episode 5350, epsilon 0.2716, reward -48.71\n",
      "Episode 5400, epsilon 0.2675, reward   2.34\n",
      "Episode 5450, epsilon 0.2635, reward -51.41\n",
      "Episode 5500, epsilon 0.2596, reward  20.10\n",
      "Episode 5550, epsilon 0.2556, reward   1.31\n",
      "Episode 5600, epsilon 0.2517, reward  11.11\n",
      "Episode 5650, epsilon 0.2479, reward  -4.86\n",
      "Episode 5700, epsilon 0.2440, reward -221.81\n",
      "Episode 5750, epsilon 0.2403, reward -66.21\n",
      "Episode 5800, epsilon 0.2365, reward -77.92\n",
      "Episode 5850, epsilon 0.2328, reward  27.61\n",
      "Episode 5900, epsilon 0.2291, reward -77.26\n",
      "Episode 5950, epsilon 0.2254, reward -199.05\n",
      "Episode 6000, epsilon 0.2218, reward -62.03\n",
      "Episode 6050, epsilon 0.2182, reward  58.80\n",
      "Episode 6100, epsilon 0.2146, reward -83.05\n",
      "Episode 6150, epsilon 0.2111, reward -46.73\n",
      "Episode 6200, epsilon 0.2075, reward -158.48\n",
      "Episode 6250, epsilon 0.2041, reward -30.97\n",
      "Episode 6300, epsilon 0.2006, reward -32.95\n",
      "Episode 6350, epsilon 0.1972, reward  40.00\n",
      "Episode 6400, epsilon 0.1938, reward  16.98\n",
      "Episode 6450, epsilon 0.1904, reward -14.67\n",
      "Episode 6500, epsilon 0.1870, reward -51.36\n",
      "Episode 6550, epsilon 0.1837, reward -144.14\n",
      "Episode 6600, epsilon 0.1804, reward   7.31\n",
      "Episode 6650, epsilon 0.1771, reward -73.00\n",
      "Episode 6700, epsilon 0.1739, reward -89.07\n",
      "Episode 6750, epsilon 0.1706, reward 217.40\n",
      "Episode 6800, epsilon 0.1674, reward -293.76\n",
      "Episode 6850, epsilon 0.1642, reward -61.67\n",
      "Episode 6900, epsilon 0.1611, reward -26.03\n",
      "Episode 6950, epsilon 0.1580, reward 223.84\n",
      "Episode 7000, epsilon 0.1548, reward -366.94\n",
      "Episode 7050, epsilon 0.1517, reward -49.13\n",
      "Episode 7100, epsilon 0.1487, reward  15.53\n",
      "Episode 7150, epsilon 0.1456, reward  22.93\n",
      "Episode 7200, epsilon 0.1426, reward  74.82\n",
      "Episode 7250, epsilon 0.1396, reward  49.34\n",
      "Episode 7300, epsilon 0.1366, reward   9.86\n",
      "Episode 7350, epsilon 0.1337, reward -33.14\n",
      "Episode 7400, epsilon 0.1307, reward -115.17\n",
      "Episode 7450, epsilon 0.1278, reward  19.43\n",
      "Episode 7500, epsilon 0.1249, reward  11.29\n",
      "Episode 7550, epsilon 0.1220, reward -21.11\n",
      "Episode 7600, epsilon 0.1191, reward 234.20\n",
      "Episode 7650, epsilon 0.1163, reward -17.35\n",
      "Episode 7700, epsilon 0.1135, reward -68.57\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 7750, epsilon 0.1106, reward   2.46\n",
      "Episode 7800, epsilon 0.1078, reward 181.70\n",
      "Episode 7850, epsilon 0.1051, reward -234.81\n",
      "Episode 7900, epsilon 0.1023, reward  83.06\n",
      "Episode 7950, epsilon 0.0996, reward -77.67\n",
      "Episode 8000, epsilon 0.0969, reward -40.58\n",
      "Episode 8050, epsilon 0.0942, reward -16.29\n",
      "Episode 8100, epsilon 0.0915, reward  -4.09\n",
      "Episode 8150, epsilon 0.0888, reward  98.94\n",
      "Episode 8200, epsilon 0.0861, reward -45.22\n",
      "Episode 8250, epsilon 0.0835, reward -218.18\n",
      "Episode 8300, epsilon 0.0809, reward  90.19\n",
      "Episode 8350, epsilon 0.0783, reward  36.91\n",
      "Episode 8400, epsilon 0.0757, reward  59.85\n",
      "Episode 8450, epsilon 0.0731, reward -57.38\n",
      "Episode 8500, epsilon 0.0705, reward  39.83\n",
      "Episode 8550, epsilon 0.0680, reward  12.32\n",
      "Episode 8600, epsilon 0.0655, reward 194.43\n",
      "Episode 8650, epsilon 0.0629, reward -189.83\n",
      "Episode 8700, epsilon 0.0604, reward  25.46\n",
      "Episode 8750, epsilon 0.0579, reward 159.39\n",
      "Episode 8800, epsilon 0.0555, reward 243.84\n",
      "Episode 8850, epsilon 0.0530, reward  31.76\n",
      "Episode 8900, epsilon 0.0506, reward -29.72\n",
      "Episode 8950, epsilon 0.0481, reward   5.63\n",
      "Episode 9000, epsilon 0.0457, reward  37.94\n",
      "Episode 9050, epsilon 0.0433, reward  19.37\n",
      "Episode 9100, epsilon 0.0409, reward -127.81\n",
      "Episode 9150, epsilon 0.0385, reward -80.50\n",
      "Episode 9200, epsilon 0.0362, reward -36.08\n",
      "Episode 9250, epsilon 0.0338, reward -12.98\n",
      "Episode 9300, epsilon 0.0315, reward -159.73\n",
      "Episode 9350, epsilon 0.0291, reward -18.89\n",
      "Episode 9400, epsilon 0.0268, reward -55.28\n",
      "Episode 9450, epsilon 0.0245, reward 154.98\n",
      "Episode 9500, epsilon 0.0222, reward -296.92\n",
      "Episode 9550, epsilon 0.0200, reward -27.05\n",
      "Episode 9600, epsilon 0.0177, reward -145.02\n",
      "Episode 9650, epsilon 0.0154, reward  40.93\n",
      "Episode 9700, epsilon 0.0132, reward -39.22\n",
      "Episode 9750, epsilon 0.0110, reward -16.23\n",
      "Episode 9800, epsilon 0.0100, reward 274.54\n",
      "Episode 9850, epsilon 0.0100, reward   2.06\n",
      "Episode 9900, epsilon 0.0100, reward -61.42\n",
      "Episode 9950, epsilon 0.0100, reward -223.70\n",
      "Episode 9999, epsilon 0.0100, reward -67.37\n",
      "\n",
      " ********** Training number  3\n",
      "Episode 0, epsilon 1.0000, reward -111.78\n",
      "Episode 50, epsilon 1.0000, reward -335.00\n",
      "Episode 100, epsilon 1.0000, reward -155.85\n",
      "Episode 150, epsilon 1.0000, reward -211.90\n",
      "Episode 200, epsilon 1.0000, reward -76.13\n",
      "Episode 250, epsilon 1.0000, reward -277.26\n",
      "Episode 300, epsilon 1.0000, reward -93.02\n",
      "Episode 350, epsilon 1.0000, reward -25.68\n",
      "Episode 400, epsilon 1.0000, reward -137.58\n",
      "Episode 450, epsilon 1.0000, reward -263.12\n",
      "Episode 500, epsilon 1.0000, reward -89.45\n",
      "Episode 550, epsilon 1.0000, reward -106.77\n",
      "Episode 600, epsilon 1.0000, reward -408.37\n",
      "Episode 650, epsilon 1.0000, reward -41.46\n",
      "Episode 700, epsilon 1.0000, reward -149.41\n",
      "Episode 750, epsilon 1.0000, reward -163.47\n",
      "Episode 800, epsilon 1.0000, reward -72.34\n",
      "Episode 850, epsilon 1.0000, reward -93.93\n",
      "Episode 900, epsilon 1.0000, reward -225.49\n",
      "Episode 950, epsilon 1.0000, reward -149.22\n",
      "Episode 1000, epsilon 0.9996, reward -418.10\n",
      "Episode 1050, epsilon 0.9784, reward -97.89\n",
      "Episode 1100, epsilon 0.9582, reward -212.95\n",
      "Episode 1150, epsilon 0.9389, reward -303.51\n",
      "Episode 1200, epsilon 0.9205, reward -134.34\n",
      "Episode 1250, epsilon 0.9027, reward -50.97\n",
      "Episode 1300, epsilon 0.8857, reward -59.00\n",
      "Episode 1350, epsilon 0.8693, reward -96.81\n",
      "Episode 1400, epsilon 0.8536, reward -138.39\n",
      "Episode 1450, epsilon 0.8383, reward -51.80\n",
      "Episode 1500, epsilon 0.8236, reward -68.93\n",
      "Episode 1550, epsilon 0.8094, reward   6.37\n",
      "Episode 1600, epsilon 0.7956, reward -73.67\n",
      "Episode 1650, epsilon 0.7823, reward -69.51\n",
      "Episode 1700, epsilon 0.7693, reward -122.92\n",
      "Episode 1750, epsilon 0.7567, reward -110.07\n",
      "Episode 1800, epsilon 0.7445, reward -100.15\n",
      "Episode 1850, epsilon 0.7326, reward -95.34\n",
      "Episode 1900, epsilon 0.7210, reward -51.01\n",
      "Episode 1950, epsilon 0.7097, reward -39.24\n",
      "Episode 2000, epsilon 0.6988, reward -200.54\n",
      "Episode 2050, epsilon 0.6880, reward -57.42\n",
      "Episode 2100, epsilon 0.6776, reward -195.81\n",
      "Episode 2150, epsilon 0.6674, reward -29.96\n",
      "Episode 2200, epsilon 0.6574, reward -66.33\n",
      "Episode 2250, epsilon 0.6476, reward -55.27\n",
      "Episode 2300, epsilon 0.6381, reward -107.82\n",
      "Episode 2350, epsilon 0.6287, reward -169.11\n",
      "Episode 2400, epsilon 0.6196, reward -76.54\n",
      "Episode 2450, epsilon 0.6107, reward -239.30\n",
      "Episode 2500, epsilon 0.6019, reward -47.30\n",
      "Episode 2550, epsilon 0.5933, reward -292.28\n",
      "Episode 2600, epsilon 0.5849, reward -153.84\n",
      "Episode 2650, epsilon 0.5766, reward -81.29\n",
      "Episode 2700, epsilon 0.5685, reward -122.50\n",
      "Episode 2750, epsilon 0.5605, reward -127.67\n",
      "Episode 2800, epsilon 0.5527, reward -172.89\n",
      "Episode 2850, epsilon 0.5450, reward -68.80\n",
      "Episode 2900, epsilon 0.5375, reward -33.26\n",
      "Episode 2950, epsilon 0.5300, reward -120.56\n",
      "Episode 3000, epsilon 0.5227, reward -92.20\n",
      "Episode 3050, epsilon 0.5156, reward -24.18\n",
      "Episode 3100, epsilon 0.5085, reward -53.10\n",
      "Episode 3150, epsilon 0.5016, reward -136.70\n",
      "Episode 3200, epsilon 0.4947, reward -43.14\n",
      "Episode 3250, epsilon 0.4880, reward  23.91\n",
      "Episode 3300, epsilon 0.4814, reward -13.78\n",
      "Episode 3350, epsilon 0.4748, reward -43.99\n",
      "Episode 3400, epsilon 0.4684, reward -15.38\n",
      "Episode 3450, epsilon 0.4621, reward -49.26\n",
      "Episode 3500, epsilon 0.4558, reward  12.78\n",
      "Episode 3550, epsilon 0.4496, reward -32.75\n",
      "Episode 3600, epsilon 0.4436, reward -147.04\n",
      "Episode 3650, epsilon 0.4376, reward -119.72\n",
      "Episode 3700, epsilon 0.4317, reward -42.19\n",
      "Episode 3750, epsilon 0.4259, reward -44.38\n",
      "Episode 3800, epsilon 0.4201, reward  -8.30\n",
      "Episode 3850, epsilon 0.4144, reward   3.89\n",
      "Episode 3900, epsilon 0.4088, reward -43.01\n",
      "Episode 3950, epsilon 0.4033, reward -58.52\n",
      "Episode 4000, epsilon 0.3978, reward  -3.93\n",
      "Episode 4050, epsilon 0.3924, reward -66.14\n",
      "Episode 4100, epsilon 0.3871, reward -57.76\n",
      "Episode 4150, epsilon 0.3818, reward  -1.66\n",
      "Episode 4200, epsilon 0.3766, reward -19.78\n",
      "Episode 4250, epsilon 0.3715, reward -67.61\n",
      "Episode 4300, epsilon 0.3664, reward -20.90\n",
      "Episode 4350, epsilon 0.3614, reward -22.40\n",
      "Episode 4400, epsilon 0.3564, reward -22.18\n",
      "Episode 4450, epsilon 0.3515, reward -24.60\n",
      "Episode 4500, epsilon 0.3467, reward -12.55\n",
      "Episode 4550, epsilon 0.3419, reward -25.88\n",
      "Episode 4600, epsilon 0.3371, reward -47.48\n",
      "Episode 4650, epsilon 0.3325, reward  67.79\n",
      "Episode 4700, epsilon 0.3278, reward -212.83\n",
      "Episode 4750, epsilon 0.3232, reward -40.76\n",
      "Episode 4800, epsilon 0.3187, reward -35.28\n",
      "Episode 4850, epsilon 0.3142, reward -57.58\n",
      "Episode 4900, epsilon 0.3097, reward  31.87\n",
      "Episode 4950, epsilon 0.3053, reward -68.31\n",
      "Episode 5000, epsilon 0.3009, reward -51.32\n",
      "Episode 5050, epsilon 0.2966, reward  23.22\n",
      "Episode 5100, epsilon 0.2923, reward -21.98\n",
      "Episode 5150, epsilon 0.2881, reward -13.52\n",
      "Episode 5200, epsilon 0.2839, reward -155.07\n",
      "Episode 5250, epsilon 0.2798, reward -329.69\n",
      "Episode 5300, epsilon 0.2756, reward -238.32\n",
      "Episode 5350, epsilon 0.2716, reward  15.71\n",
      "Episode 5400, epsilon 0.2675, reward -19.74\n",
      "Episode 5450, epsilon 0.2635, reward -61.14\n",
      "Episode 5500, epsilon 0.2596, reward -184.14\n",
      "Episode 5550, epsilon 0.2556, reward  15.29\n",
      "Episode 5600, epsilon 0.2517, reward   3.21\n",
      "Episode 5650, epsilon 0.2479, reward -10.19\n",
      "Episode 5700, epsilon 0.2440, reward -52.63\n",
      "Episode 5750, epsilon 0.2403, reward -32.82\n",
      "Episode 5800, epsilon 0.2365, reward  27.55\n",
      "Episode 5850, epsilon 0.2328, reward  64.16\n",
      "Episode 5900, epsilon 0.2291, reward   7.62\n",
      "Episode 5950, epsilon 0.2254, reward -89.73\n",
      "Episode 6000, epsilon 0.2218, reward -33.08\n",
      "Episode 6050, epsilon 0.2182, reward  16.62\n",
      "Episode 6100, epsilon 0.2146, reward  16.94\n",
      "Episode 6150, epsilon 0.2111, reward -358.88\n",
      "Episode 6200, epsilon 0.2075, reward -17.23\n",
      "Episode 6250, epsilon 0.2041, reward -19.99\n",
      "Episode 6300, epsilon 0.2006, reward -145.58\n",
      "Episode 6350, epsilon 0.1972, reward -155.65\n",
      "Episode 6400, epsilon 0.1938, reward -43.22\n",
      "Episode 6450, epsilon 0.1904, reward 134.29\n",
      "Episode 6500, epsilon 0.1870, reward 156.99\n",
      "Episode 6550, epsilon 0.1837, reward  15.59\n",
      "Episode 6600, epsilon 0.1804, reward -88.30\n",
      "Episode 6650, epsilon 0.1771, reward  -5.56\n",
      "Episode 6700, epsilon 0.1739, reward -20.72\n",
      "Episode 6750, epsilon 0.1706, reward  -9.81\n",
      "Episode 6800, epsilon 0.1674, reward -25.76\n",
      "Episode 6850, epsilon 0.1642, reward  -4.29\n",
      "Episode 6900, epsilon 0.1611, reward -47.88\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 6950, epsilon 0.1580, reward -39.09\n",
      "Episode 7000, epsilon 0.1548, reward -29.93\n",
      "Episode 7050, epsilon 0.1517, reward -322.79\n",
      "Episode 7100, epsilon 0.1487, reward -27.44\n",
      "Episode 7150, epsilon 0.1456, reward -10.58\n",
      "Episode 7200, epsilon 0.1426, reward  42.82\n",
      "Episode 7250, epsilon 0.1396, reward  12.17\n",
      "Episode 7300, epsilon 0.1366, reward 177.09\n",
      "Episode 7350, epsilon 0.1337, reward  11.38\n",
      "Episode 7400, epsilon 0.1307, reward 201.21\n",
      "Episode 7450, epsilon 0.1278, reward 118.15\n",
      "Episode 7500, epsilon 0.1249, reward -13.54\n",
      "Episode 7550, epsilon 0.1220, reward -52.65\n",
      "Episode 7600, epsilon 0.1191, reward  -3.71\n",
      "Episode 7650, epsilon 0.1163, reward  -8.02\n",
      "Episode 7700, epsilon 0.1135, reward 175.35\n",
      "Episode 7750, epsilon 0.1106, reward -10.62\n",
      "Episode 7800, epsilon 0.1078, reward   0.05\n",
      "Episode 7850, epsilon 0.1051, reward 276.17\n",
      "Episode 7900, epsilon 0.1023, reward -30.17\n",
      "Episode 7950, epsilon 0.0996, reward  47.20\n",
      "Episode 8000, epsilon 0.0969, reward   2.96\n",
      "Episode 8050, epsilon 0.0942, reward 145.79\n",
      "Episode 8100, epsilon 0.0915, reward -171.38\n",
      "Episode 8150, epsilon 0.0888, reward -34.06\n",
      "Episode 8200, epsilon 0.0861, reward 275.39\n",
      "Episode 8250, epsilon 0.0835, reward -62.80\n",
      "Episode 8300, epsilon 0.0809, reward -42.23\n",
      "Episode 8350, epsilon 0.0783, reward  27.07\n",
      "Episode 8400, epsilon 0.0757, reward 112.49\n",
      "Episode 8450, epsilon 0.0731, reward 214.46\n",
      "Episode 8500, epsilon 0.0705, reward -53.46\n",
      "Episode 8550, epsilon 0.0680, reward 263.86\n",
      "Episode 8600, epsilon 0.0655, reward  36.98\n",
      "Episode 8650, epsilon 0.0629, reward -90.12\n",
      "Episode 8700, epsilon 0.0604, reward  -4.22\n",
      "Episode 8750, epsilon 0.0579, reward -46.89\n",
      "Episode 8800, epsilon 0.0555, reward -25.52\n",
      "Episode 8850, epsilon 0.0530, reward -76.64\n",
      "Episode 8900, epsilon 0.0506, reward -27.83\n",
      "Episode 8950, epsilon 0.0481, reward 190.65\n",
      "Episode 9000, epsilon 0.0457, reward -78.70\n",
      "Episode 9050, epsilon 0.0433, reward -67.94\n",
      "Episode 9100, epsilon 0.0409, reward -14.14\n",
      "Episode 9150, epsilon 0.0385, reward -78.40\n",
      "Episode 9200, epsilon 0.0362, reward  74.71\n",
      "Episode 9250, epsilon 0.0338, reward -105.32\n",
      "Episode 9300, epsilon 0.0315, reward  38.41\n",
      "Episode 9350, epsilon 0.0291, reward -91.24\n",
      "Episode 9400, epsilon 0.0268, reward -14.36\n",
      "Episode 9450, epsilon 0.0245, reward -81.25\n",
      "Episode 9500, epsilon 0.0222, reward 219.53\n",
      "Episode 9550, epsilon 0.0200, reward 185.15\n",
      "Episode 9600, epsilon 0.0177, reward 207.53\n",
      "Episode 9650, epsilon 0.0154, reward 222.85\n",
      "Episode 9700, epsilon 0.0132, reward 209.25\n",
      "Episode 9750, epsilon 0.0110, reward  24.76\n",
      "Episode 9800, epsilon 0.0100, reward  -7.41\n",
      "Episode 9850, epsilon 0.0100, reward  20.26\n",
      "Episode 9900, epsilon 0.0100, reward  10.96\n",
      "Episode 9950, epsilon 0.0100, reward 238.57\n",
      "Episode 9999, epsilon 0.0100, reward 196.72\n",
      "\n",
      " ********** Training number  4\n",
      "Episode 0, epsilon 1.0000, reward -305.40\n",
      "Episode 50, epsilon 1.0000, reward -208.33\n",
      "Episode 100, epsilon 1.0000, reward -106.89\n",
      "Episode 150, epsilon 1.0000, reward -346.55\n",
      "Episode 200, epsilon 1.0000, reward -527.05\n",
      "Episode 250, epsilon 1.0000, reward  12.45\n",
      "Episode 300, epsilon 1.0000, reward -108.94\n",
      "Episode 350, epsilon 1.0000, reward -125.38\n",
      "Episode 400, epsilon 1.0000, reward -312.64\n",
      "Episode 450, epsilon 1.0000, reward -458.00\n",
      "Episode 500, epsilon 1.0000, reward -235.28\n",
      "Episode 550, epsilon 1.0000, reward -109.36\n",
      "Episode 600, epsilon 1.0000, reward -333.52\n",
      "Episode 650, epsilon 1.0000, reward -344.49\n",
      "Episode 700, epsilon 1.0000, reward -234.84\n",
      "Episode 750, epsilon 1.0000, reward -114.18\n",
      "Episode 800, epsilon 1.0000, reward -209.79\n",
      "Episode 850, epsilon 1.0000, reward -129.24\n",
      "Episode 900, epsilon 1.0000, reward -181.88\n",
      "Episode 950, epsilon 1.0000, reward -337.20\n",
      "Episode 1000, epsilon 0.9996, reward -147.57\n",
      "Episode 1050, epsilon 0.9784, reward -89.95\n",
      "Episode 1100, epsilon 0.9582, reward -120.13\n",
      "Episode 1150, epsilon 0.9389, reward -109.19\n",
      "Episode 1200, epsilon 0.9205, reward -63.64\n",
      "Episode 1250, epsilon 0.9027, reward -73.58\n",
      "Episode 1300, epsilon 0.8857, reward -190.68\n",
      "Episode 1350, epsilon 0.8693, reward -145.83\n",
      "Episode 1400, epsilon 0.8536, reward -68.84\n",
      "Episode 1450, epsilon 0.8383, reward -98.56\n",
      "Episode 1500, epsilon 0.8236, reward -112.67\n",
      "Episode 1550, epsilon 0.8094, reward -141.99\n",
      "Episode 1600, epsilon 0.7956, reward -132.74\n",
      "Episode 1650, epsilon 0.7823, reward -103.79\n",
      "Episode 1700, epsilon 0.7693, reward -80.63\n",
      "Episode 1750, epsilon 0.7567, reward -208.07\n",
      "Episode 1800, epsilon 0.7445, reward -100.07\n",
      "Episode 1850, epsilon 0.7326, reward -110.32\n",
      "Episode 1900, epsilon 0.7210, reward -96.69\n",
      "Episode 1950, epsilon 0.7097, reward -207.25\n",
      "Episode 2000, epsilon 0.6988, reward -81.16\n",
      "Episode 2050, epsilon 0.6880, reward -121.37\n",
      "Episode 2100, epsilon 0.6776, reward -67.80\n",
      "Episode 2150, epsilon 0.6674, reward -147.42\n",
      "Episode 2200, epsilon 0.6574, reward -75.84\n",
      "Episode 2250, epsilon 0.6476, reward -47.68\n",
      "Episode 2300, epsilon 0.6381, reward -150.40\n",
      "Episode 2350, epsilon 0.6287, reward -108.71\n",
      "Episode 2400, epsilon 0.6196, reward -79.41\n",
      "Episode 2450, epsilon 0.6107, reward -53.21\n",
      "Episode 2500, epsilon 0.6019, reward -329.55\n",
      "Episode 2550, epsilon 0.5933, reward -45.96\n",
      "Episode 2600, epsilon 0.5849, reward -16.51\n",
      "Episode 2650, epsilon 0.5766, reward -77.76\n",
      "Episode 2700, epsilon 0.5685, reward -144.54\n",
      "Episode 2750, epsilon 0.5605, reward -180.90\n",
      "Episode 2800, epsilon 0.5527, reward -50.46\n",
      "Episode 2850, epsilon 0.5450, reward -33.03\n",
      "Episode 2900, epsilon 0.5375, reward -170.08\n",
      "Episode 2950, epsilon 0.5300, reward -32.52\n",
      "Episode 3000, epsilon 0.5227, reward -39.68\n",
      "Episode 3050, epsilon 0.5156, reward -21.42\n",
      "Episode 3100, epsilon 0.5085, reward -97.48\n",
      "Episode 3150, epsilon 0.5016, reward -91.19\n",
      "Episode 3200, epsilon 0.4947, reward -58.73\n",
      "Episode 3250, epsilon 0.4880, reward -65.62\n",
      "Episode 3300, epsilon 0.4814, reward -28.84\n",
      "Episode 3350, epsilon 0.4748, reward -64.66\n",
      "Episode 3400, epsilon 0.4684, reward -27.25\n",
      "Episode 3450, epsilon 0.4621, reward  49.17\n",
      "Episode 3500, epsilon 0.4558, reward -50.12\n",
      "Episode 3550, epsilon 0.4496, reward -15.58\n",
      "Episode 3600, epsilon 0.4436, reward -74.72\n",
      "Episode 3650, epsilon 0.4376, reward -32.87\n",
      "Episode 3700, epsilon 0.4317, reward -50.56\n",
      "Episode 3750, epsilon 0.4259, reward -18.91\n",
      "Episode 3800, epsilon 0.4201, reward -17.38\n",
      "Episode 3850, epsilon 0.4144, reward -81.45\n",
      "Episode 3900, epsilon 0.4088, reward -23.81\n",
      "Episode 3950, epsilon 0.4033, reward -35.10\n",
      "Episode 4000, epsilon 0.3978, reward -86.15\n",
      "Episode 4050, epsilon 0.3924, reward -22.42\n",
      "Episode 4100, epsilon 0.3871, reward -71.23\n",
      "Episode 4150, epsilon 0.3818, reward -25.05\n",
      "Episode 4200, epsilon 0.3766, reward -70.80\n",
      "Episode 4250, epsilon 0.3715, reward -54.88\n",
      "Episode 4300, epsilon 0.3664, reward -62.33\n",
      "Episode 4350, epsilon 0.3614, reward  -0.38\n",
      "Episode 4400, epsilon 0.3564, reward -96.51\n",
      "Episode 4450, epsilon 0.3515, reward -74.46\n",
      "Episode 4500, epsilon 0.3467, reward -137.06\n",
      "Episode 4550, epsilon 0.3419, reward -66.70\n",
      "Episode 4600, epsilon 0.3371, reward -47.41\n",
      "Episode 4650, epsilon 0.3325, reward -85.30\n",
      "Episode 4700, epsilon 0.3278, reward -40.73\n",
      "Episode 4750, epsilon 0.3232, reward -16.64\n",
      "Episode 4800, epsilon 0.3187, reward -28.35\n",
      "Episode 4850, epsilon 0.3142, reward  27.29\n",
      "Episode 4900, epsilon 0.3097, reward -190.10\n",
      "Episode 4950, epsilon 0.3053, reward -77.94\n",
      "Episode 5000, epsilon 0.3009, reward -72.86\n",
      "Episode 5050, epsilon 0.2966, reward -45.62\n",
      "Episode 5100, epsilon 0.2923, reward -88.87\n",
      "Episode 5150, epsilon 0.2881, reward -27.22\n",
      "Episode 5200, epsilon 0.2839, reward -25.66\n",
      "Episode 5250, epsilon 0.2798, reward -48.34\n",
      "Episode 5300, epsilon 0.2756, reward -50.29\n",
      "Episode 5350, epsilon 0.2716, reward -34.25\n",
      "Episode 5400, epsilon 0.2675, reward  -0.01\n",
      "Episode 5450, epsilon 0.2635, reward -35.19\n",
      "Episode 5500, epsilon 0.2596, reward  35.44\n",
      "Episode 5550, epsilon 0.2556, reward -25.67\n",
      "Episode 5600, epsilon 0.2517, reward -20.49\n",
      "Episode 5650, epsilon 0.2479, reward  -4.82\n",
      "Episode 5700, epsilon 0.2440, reward -21.01\n",
      "Episode 5750, epsilon 0.2403, reward -39.03\n",
      "Episode 5800, epsilon 0.2365, reward -77.73\n",
      "Episode 5850, epsilon 0.2328, reward -20.34\n",
      "Episode 5900, epsilon 0.2291, reward -17.75\n",
      "Episode 5950, epsilon 0.2254, reward   7.88\n",
      "Episode 6000, epsilon 0.2218, reward  24.38\n",
      "Episode 6050, epsilon 0.2182, reward  -2.61\n",
      "Episode 6100, epsilon 0.2146, reward  68.23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 6150, epsilon 0.2111, reward  12.43\n",
      "Episode 6200, epsilon 0.2075, reward  42.40\n",
      "Episode 6250, epsilon 0.2041, reward -45.39\n",
      "Episode 6300, epsilon 0.2006, reward -19.15\n",
      "Episode 6350, epsilon 0.1972, reward   1.16\n",
      "Episode 6400, epsilon 0.1938, reward -18.80\n",
      "Episode 6450, epsilon 0.1904, reward -34.25\n",
      "Episode 6500, epsilon 0.1870, reward   2.07\n",
      "Episode 6550, epsilon 0.1837, reward  48.42\n",
      "Episode 6600, epsilon 0.1804, reward  17.78\n",
      "Episode 6650, epsilon 0.1771, reward 227.52\n",
      "Episode 6700, epsilon 0.1739, reward  45.46\n",
      "Episode 6750, epsilon 0.1706, reward -103.72\n",
      "Episode 6800, epsilon 0.1674, reward -35.16\n",
      "Episode 6850, epsilon 0.1642, reward -22.27\n",
      "Episode 6900, epsilon 0.1611, reward -36.85\n",
      "Episode 6950, epsilon 0.1580, reward  31.75\n",
      "Episode 7000, epsilon 0.1548, reward 232.15\n",
      "Episode 7050, epsilon 0.1517, reward -46.89\n",
      "Episode 7100, epsilon 0.1487, reward -50.12\n",
      "Episode 7150, epsilon 0.1456, reward  49.27\n",
      "Episode 7200, epsilon 0.1426, reward   7.44\n",
      "Episode 7250, epsilon 0.1396, reward -21.35\n",
      "Episode 7300, epsilon 0.1366, reward   2.63\n",
      "Episode 7350, epsilon 0.1337, reward  37.23\n",
      "Episode 7400, epsilon 0.1307, reward -96.58\n",
      "Episode 7450, epsilon 0.1278, reward -71.19\n",
      "Episode 7500, epsilon 0.1249, reward -92.09\n",
      "Episode 7550, epsilon 0.1220, reward  -9.36\n",
      "Episode 7600, epsilon 0.1191, reward -22.14\n",
      "Episode 7650, epsilon 0.1163, reward  15.25\n",
      "Episode 7700, epsilon 0.1135, reward  -7.48\n",
      "Episode 7750, epsilon 0.1106, reward 249.39\n",
      "Episode 7800, epsilon 0.1078, reward -40.44\n",
      "Episode 7850, epsilon 0.1051, reward   5.25\n",
      "Episode 7900, epsilon 0.1023, reward  -8.16\n",
      "Episode 7950, epsilon 0.0996, reward -55.16\n",
      "Episode 8000, epsilon 0.0969, reward -21.43\n",
      "Episode 8050, epsilon 0.0942, reward  11.01\n",
      "Episode 8100, epsilon 0.0915, reward  35.10\n",
      "Episode 8150, epsilon 0.0888, reward -26.19\n",
      "Episode 8200, epsilon 0.0861, reward -27.15\n",
      "Episode 8250, epsilon 0.0835, reward  -0.78\n",
      "Episode 8300, epsilon 0.0809, reward -79.68\n",
      "Episode 8350, epsilon 0.0783, reward  20.30\n",
      "Episode 8400, epsilon 0.0757, reward  29.56\n",
      "Episode 8450, epsilon 0.0731, reward  29.09\n",
      "Episode 8500, epsilon 0.0705, reward  -0.16\n",
      "Episode 8550, epsilon 0.0680, reward  -8.15\n",
      "Episode 8600, epsilon 0.0655, reward   9.56\n",
      "Episode 8650, epsilon 0.0629, reward  11.53\n",
      "Episode 8700, epsilon 0.0604, reward -44.20\n",
      "Episode 8750, epsilon 0.0579, reward  16.38\n",
      "Episode 8800, epsilon 0.0555, reward -350.01\n",
      "Episode 8850, epsilon 0.0530, reward  37.22\n",
      "Episode 8900, epsilon 0.0506, reward -28.84\n",
      "Episode 8950, epsilon 0.0481, reward -27.66\n",
      "Episode 9000, epsilon 0.0457, reward -57.96\n",
      "Episode 9050, epsilon 0.0433, reward  16.79\n",
      "Episode 9100, epsilon 0.0409, reward  43.29\n",
      "Episode 9150, epsilon 0.0385, reward -66.10\n",
      "Episode 9200, epsilon 0.0362, reward 279.74\n",
      "Episode 9250, epsilon 0.0338, reward  15.58\n",
      "Episode 9300, epsilon 0.0315, reward -10.71\n",
      "Episode 9350, epsilon 0.0291, reward -36.92\n",
      "Episode 9400, epsilon 0.0268, reward  30.35\n",
      "Episode 9450, epsilon 0.0245, reward  45.14\n",
      "Episode 9500, epsilon 0.0222, reward -72.86\n",
      "Episode 9550, epsilon 0.0200, reward -10.71\n",
      "Episode 9600, epsilon 0.0177, reward -36.28\n",
      "Episode 9650, epsilon 0.0154, reward -25.00\n",
      "Episode 9700, epsilon 0.0132, reward  10.18\n",
      "Episode 9750, epsilon 0.0110, reward -36.09\n",
      "Episode 9800, epsilon 0.0100, reward -70.21\n",
      "Episode 9850, epsilon 0.0100, reward  18.39\n",
      "Episode 9900, epsilon 0.0100, reward  25.15\n",
      "Episode 9950, epsilon 0.0100, reward -52.93\n",
      "Episode 9999, epsilon 0.0100, reward  17.65\n"
     ]
    }
   ],
   "source": [
    "n_times = 5\n",
    "total_train_episodes = 10000\n",
    "gamma = 0.99                     \n",
    "max_epsilon = 1.0\n",
    "min_epsilon = 0.01   \n",
    "\n",
    "env = gym.make('LunarLander-v2')\n",
    "number_of_buckets, number_of_actions, state_value_bounds = set_buckets_and_actions()\n",
    "\n",
    "MC_tables = []\n",
    "MC_rewards = []\n",
    "\n",
    "for number in range(n_times):\n",
    "    print(\"\\n ********** Training number \", number)\n",
    "    q_table,rewards = Monte_Carlo()\n",
    "    MC_tables.append(q_table)\n",
    "    MC_rewards.append(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a85f7e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "MC_mean = np.mean(np.array(MC_rewards),axis=0)\n",
    "#print(MC_mean.shape)\n",
    "#np.save('MC_mean', MC_mean)\n",
    "#np.save('MC_tables', MC_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47b41368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAABlXklEQVR4nO2dd3hcV5m43zO9aNSrLfce24odO7ETh3TSSSGksECAkA2dsPTQ6y78srDAsgGywIYSHEJJAwKJ05ud2IntuMvdsnodSdNnzu+PW+aONGpWl877PHos3blz77kj+fvO14WUEoVCoVBMP2zjvQCFQqFQjA9KASgUCsU0RSkAhUKhmKYoBaBQKBTTFKUAFAqFYpriGO8FDJbi4mI5d+7c8V6GQqFQTCq2bdvWLKUsyfbapFEAc+fOZevWreO9DIVCoZhUCCGO9fWacgEpFArFNEUpAIVCoZimKAWgUCgU05RJEwPIRjwep6amhkgkMt5LUUxSPB4PlZWVOJ3O8V6KQjHmTGoFUFNTQyAQYO7cuQghxns5ikmGlJKWlhZqamqYN2/eeC9HoRhzJrULKBKJUFRUpIS/4pQQQlBUVKQsSMW0ZVIrAEAJf8WwUH8/iunMpFcACoVCMV5sPdrKvvrgeC/jlFEKYJgIIXjPe95j/pxIJCgpKeHqq68+peu1t7dzzz33DPl9XV1dfPCDH2TBggUsX76c8847jy1btgzpGhdccIEqtlMohsBXHtnND5+sHu9lnDJKAQwTv9/Prl27CIfDADz55JPMnDnzlK93qgrg9ttvp7CwkOrqanbv3s19991Hc3PzoN+fTCaHfE+FYroTjSeJJCbv/x2lAEaAK664gr/97W8AbNy4kXe+853ma62trVx33XVUVVWxfv16du7cCcDXv/51brvtNi644ALmz5/Pj3/8YwC+8IUvcOjQIVatWsVnP/tZAO6++27OPPNMqqqq+NrXvtbr/ocOHWLLli18+9vfxmbTfqXz58/nqquuAuC6665jzZo1LF++nHvvvdd8X05ODl/96ldZt24dr7zySsY1N27cyMqVK1mxYgWf//znR+qjUiimFPFUingyNd7LOGUmdRqolW88tps9tSPrizttRi5fe9vyAc+75ZZb+OY3v8nVV1/Nzp07ue2223jhhRcA+NrXvsbq1at5+OGHefrpp7n11lvZvn07APv27eOZZ56hs7OTJUuW8OEPf5jvfve77Nq1yzzniSeeoLq6mldffRUpJddccw3PP/885513nnn/3bt3s2rVKux2e9b1/epXv6KwsJBwOMyZZ57JDTfcQFFREd3d3axYsYJvfvObGefX1tby+c9/nm3btlFQUMCll17Kww8/zHXXXTf0D1GhmMLEE5J4YvKO1VUWwAhQVVXF0aNH2bhxI1deeWXGay+++KIZI7joootoaWmho6MDgKuuugq3201xcTGlpaU0NDT0uvYTTzzBE088werVqznjjDPYt28f1dVD8zn++Mc/5vTTT2f9+vWcOHHCfL/dbueGG27odf5rr73GBRdcQElJCQ6Hg3e96108//zzQ7qnQjEdSKRSxJQFMP4MZqc+mlxzzTV85jOf4dlnn6WlpcU8LmXv3YGReuh2u81jdrudRCLR61wpJXfddRcf/OAH+7z38uXL2bFjB6lUynQBGTz77LNs2rSJV155BZ/PxwUXXGDmvXs8nqxWQ7Y1KxSK3sQSk9sFpCyAEeK2227jq1/9KitXrsw4ft5553H//fcDmjAuLi4mNze3z+sEAgE6OzvNny+77DJ+9atf0dXVBcDJkydpbGzMeM+CBQtYu3YtX/va10zhXV1dzSOPPEJHRwcFBQX4fD727dvH5s2bB3yWdevW8dxzz9Hc3EwymWTjxo2cf/75g/sgFIppRDwpJ7UCmDIWwHhTWVnJnXfe2ev417/+dd7//vdTVVWFz+fj17/+db/XKSoqYsOGDaxYsYIrrriCu+++m71793L22WcDWuD2d7/7HaWlpRnv+8UvfsGnP/1pFi5ciM/no6ioiLvvvpuqqip+9rOfUVVVxZIlS1i/fv2Az1JRUcF//Md/cOGFFyKl5Morr+Taa68dwqehUEwPEqkU8eTktZjFZDH3165dK3vmqO/du5dly5aN04oUUwX1d6Q4FaSUzLvr78zM9/LSFy4a7+X0iRBim5RybbbXlAtIoVAoToFESts8T2YXkFIACoVixLl/yzG+/uju8V7GqGIIfqUAFAqFwsJLB5vZtLd3WvNUwvD9T+YYgFIACoVixIklUkQTk3dnPBiMnf9krgNQCkChUIw40USKSHzy9sgZDIlkOgYwWZJpeqIUgEKhGHGmkwUgJSRTSgFMS0a6HfTPfvYzfvOb34zU8mhqasLpdPLzn/98xK45mnzyk58020785Cc/YeHChQghMjqbSin5xCc+wcKFC6mqquL11183X/vHP/7BkiVLWLhwId/97nfN45/5zGd4+umnx+5BpjmxZIpYYvLujAeD1fUzWeMASgEMk5FuB/2hD32IW2+9daSWxx//+EfWr1/Pxo0bR+R62dpVjBStra1s3rzZbHS3YcMGNm3axJw5czLOe/zxx6murqa6upp7772XD3/4w4DW0vqjH/0ojz/+OHv27GHjxo3s2bMHgI9//OMZCkExusT03f9UtgISFqE/WeMASgGMAENtB51KpZg7dy7t7e3meQsXLqShoYGvf/3r/Od//iegDWj5/Oc/z1lnncXixYvNDqOhUIibbrqJqqoqbr75ZtatW9fnIJeNGzfy/e9/n5qaGk6ePElHRwdz584llUqZ15o1axbxeJxDhw5x+eWXs2bNGt7ylrewb98+AN73vvfxqU99igsvvJDPf/7zvPrqq5xzzjmsXr2ac845h/379w+4rieeeIKzzz6bM844gxtvvNFsbWHlT3/6E5dffrn58+rVq5k7d26v8x555BFuvfVWhBCsX7+e9vZ26urqePXVV1m4cCHz58/H5XJxyy238MgjjwAwZ84cWlpaqK+vH/gXqhg200EBxDMsgMn5nFOnFcQnPwl6C+URY9Uq+OEPBzztVNpBX3vttTz00EO8//3vZ8uWLcydO5eysrJe104kErz66qv8/e9/5xvf+AabNm3innvuoaCggJ07d7Jr1y5WrVqVdV0nTpygvr6es846i5tuuok//OEPfOpTn+L000/nueee48ILL+Sxxx7jsssuw+l0cscdd/Czn/2MRYsWsWXLFj7ykY+YbpMDBw6wadMm7HY7wWCQ559/HofDwaZNm/jiF7/In//85z7X1dzczLe//W02bdqE3+/ne9/7Hj/4wQ/46le/mrHel156iXe84x0Dft4nT55k1qxZ5s+VlZWcPHky63HrVLQzzjiDl156KWsHVMXIYuyIo/EkeJ3jvJrRQSkABTBwO+g///nPQGY76JtvvplvfvObvP/97+eBBx7g5ptvznrtt7/97QCsWbOGo0ePmtc0+g6tWLGCqqqqrO994IEHuOmmmwBNSX3gAx/gU5/6FDfffDN/+MMfuPDCC3nggQf4yEc+QldXFy+//DI33nij+f5oNGp+f+ONN5qdQzs6Onjve99LdXU1Qgji8Xi/69q8eTN79uxhw4YNAMRiMbO3kZW6ujpKSkqyPouVvjqs9td5FaC0tJTa2toBr68YPtPDAkj/vU3WmQBTRwEMYqc+mgy1HfTZZ5/NwYMHaWpq4uGHH+bLX/5y1usaLaOt7aIHG1jbuHEjDQ0NZjfS2tpaqqurueaaa7jrrrtobW1l27ZtXHTRRXR3d5Ofn28OoumJ3+83v//KV77ChRdeyEMPPcTRo0e54IIL+l2XlJK3vvWtA8YhvF6v2aq6PyorKzlx4oT5c01NDTNmzCAWi2U9bhCJRPB6vQNeXzF8oqYCmLqpoAnLrl/FAKY5Q20HLYTg+uuv51Of+hTLli2jqKho0Pc699xzefDBBwHYs2cPb775Zq9z9u/fT3d3NydPnuTo0aMcPXqUu+66iwceeICcnBzOOuss7rzzTq6++mrsdju5ubnMmzePP/7xj4AmtHfs2JH1/h0dHWag+7777htwXevXr+ell17i4MGDgBYrOHDgQK/rLlu2zDynP6655hp+85vfIKVk8+bN5OXlUVFRwZlnnkl1dTVHjhwhFovxwAMPcM0115jvO3DgACtWrBjw+orhY1gAkfjkFIyDITYFXEBKAYwQ/bWD3rp1K1VVVXzhC1/IaAd9880387vf/a5P909ffOQjH6GpqYmqqiq+973vUVVVRV5eXsY5Gzdu5Prrr884dsMNN5i78Gz3vv/++/nlL3/J6aefzvLly80Aak8+97nPcdddd7Fhw4aMYfJ9raukpIT77ruPd77znWYw3AgwW7nqqqt49tlnzZ9//OMfU1lZSU1NDVVVVdx+++0AXHnllcyfP5+FCxfyr//6r9xzzz0AOBwOfvKTn3DZZZexbNkybrrpJpYv1wYFxeNxDh48yNq1WZsiKkaY6eACsmYBTVYFoNpBT0KSySTxeByPx8OhQ4e4+OKLOXDgAC6Xa9Kv69xzz+Wvf/0r+fn5I7q2hx56iNdff51vfetbvV6brn9Ho4XRJhng97ev45yFxeO8otHh8Tfr+PD9Wg3Knz98NmvmFI7zirLTXzvoqRMDmEaEQiEuvPBC4vE4Ukp++tOfjrvwH6l1ff/73+f48eMjrgASiQSf/vSnR/SaiuxYXSNT2QKwPmdMBYEVY0UgEOgz7388GYl1rVu3boRWk4k1u0kxusQSVgUwlYPA/buApJS8eLCZDQuKsdlEr9cnAiMSAxBC/EoI0SiE2GU5ViiEeFIIUa3/W2B57S4hxEEhxH4hxGXDufdkcWEpJibq72fkyVQAU9cCGKgOYG9dJ+/55au8dKi512sThZEKAt8HXN7j2BeAp6SUi4Cn9J8RQpwG3AIs199zjxDCfio39Xg8tLS0qP/EilNCSklLSwsej2e8lzKlyHABTeEsoHiqfwugMxLX/x299inDZURcQFLK54UQc3scvha4QP/+18CzwOf14w9IKaPAESHEQeAs4JWh3tfIEGlqajrFlSumOx6Ph8rKyvFexpTCagFExtgF1B1N8NVHdvOlq5ZR6B/duFg8Ya0D6L0JNRThRG6LPZoxgDIpZR2AlLJOCFGqH58JbLacV6Mf64UQ4g7gDoDZs2f3et3pdDJv3ryRXLNCoRgmGS6gMbYAdp3s4M+v13Dp8jIuW14+qvdKpCwuoCyursmQCjsedQDZoiFZfThSynullGullGsH0yJAoVCMP9FxDAIHdXdLKDb6bpf4AEFgUwFMYAtgNBVAgxCiAkD/t1E/XgPMspxXCagGLQrFFCE6jkFgw+/eHR19oTtQENh0AU1TC+BR4L369+8FHrEcv0UI4RZCzAMWAa+O4joUCsUYMp5ZQEbAtTs6FhbAADEA0wLI/Ayau6Js+O7TbD7c0us9Y81IpYFuRAviLhFC1AghPgB8F3irEKIaeKv+M1LK3cCDwB7gH8BHpZQT10ZSKBRDwpoFNNYB0GBYtwBiY2EBDOACMlpi93CDbdrTwMn2MDtOtI/q+gbDSGUBvbOPly7u4/zvAN8ZiXsrFIqJxXgGgTv1nX9ojCwAr9NOOJ7sNwjcsyHepr0NADQEo73eM9aoZnAKhWJEGc9KYDMGMCYWQAqvy25+35NYlpbY4ViSF6q1wrDGzoFbn482SgEoFIoRJaZ3iHU5bGMeAwiGxy4LKJGUOO0Cl93WfwzA8hm8eLCZaCKFx2mjUVkACoViqmEIvlyPY+wVwChmAUkp6bK4lmLJFA6bDadd9J8FZImDPLu/kYDbwQWLS5UFoFAoph6GAgh4nGMeBB7NLKBn9jdy5rc30R6KAZoF4HLYcDlsAwSB068dbelmUVkOlQVeGoLRcW9joxSAQqEYUaKmAhg/C2A0XEAn28KE40lOtocBze/vtAuc9j4UQBYXUF1HhIo8L6W5bsLxZIZFMR4oBaBQKEYUY+erKYChWQCPv1nH0ebuU763aQGMQhDYEOTtIU3JxJNSdwHZss4DSGcBaWuRUlLfEaE8z0NZrtaAcLwzgZQCUCgUI4qR+hlwO4ecBvrpP+7g3hcOn/K9jTqA0UgDNRRAa7fmAoonUzj7cwH1sACCkQShWJKKPA8lATcw/plASgEoFIoRJaa7Rrwu+5C6gUopCceTnGgNDfo9//PMQX6hK4xYImUK21GxAPSdvBEDiCdTOG1iwCCw8b76Dk3YV+R5TQtgvDOBlAJQKCYBX3tkF3f/c994L2NQxBIpXHYbboetlwXQGYlzrCW7iyeelEjJkBTA47vq+NO2GvPaADluB93RxIgHWNMWgHYfLQ3UNugYQG2HFjuwuoCUBaBQKAZk67E2Xj/WPt7LGBSxRAqXQ1cAPYLAP3vuEDf+TBv98eiOWt7x05fN14x4QU1bmGRqcMI7Ek9xvDWElNLsBFqe5yGRkhktKUYC41nadAsglkzh0IPA/fcC6mkBeMhxO/C57CoGoFAoBiaWSI35cJVTxVQATnuvIHBzZ4yW7hhSSnaeaGfrsTbzHEPAJlKSOn23PBDhWJJQLElTV9S0AMr13XVoCLUABxu7uH/LsX7PMdZpKIBESrN0XHZb9lYQPdJA6zoi2ASm/78s10NDUFkACoViAKKJ1KQZrxhLZloAVldMKJ4kmZLEk5q/H6BL37lbrYUTrYNTAEaGzfGWkJkBZLhXuoeQCvrAq8f50kO7MtpY9MT4/NuMLKCE1CwARx8xgB5ZQPUdYUoCbpx2TeyWBNw0dioLQKFQDEA0kZxcFoDdhsdpR8rM7qBhXSiHY0nCeqDWyIW3Dk4x4gCxRIp99cE+72UI16MtITMDqCJPtwCGEAhu6tIEcXs41uc5pgvIyAJKpdIxgCwuq2wWQEWe13y9LNdDo7IAFArFQEwmCyCaSOFy2HE7bObPBoZQDseTpgXQmcUCOK4rgL+/WcflP3yBTXsa2F3bwaf+sD0jrz5sWgDd5nXKdQVgVAM/va+B327u373TrCuANj3AC/Dlh9/kKb1zp7Y+7V7WNFCXoQD66QaaSEkSyZSuADzm6xV5Huo6IuNaDawUgEIxCYjGU2PeWbMnrd0xvvrIrgHbO1hdQJDZErrbogBCPS2ALArAyJK566E3ed//vcZf3jjJwcYu8z7GxvtYa8isAq4wFYB2/f/85wHueeZgv2tu0l0xLd1pl8yDr9Xwl9dPmj+nC8HSrSAcejO4/lxAxnuNIjCDmfleookUzV19Wx2jjVIACsUER0qpuYDG2QJ4Ync9v3nlGHvr+nbJAMQSSdx2G26H1io5sx1yultnTwvAUCxOu+BEWyjjtbbumLlL79BdPdbP42hLiGAkgRBQGkjHABqCEfbUBU33UF8YQtiwAJJ6FtGBhk7zHEORdceSRBNJvRXEwM3gAFq6YnRFExkWwMx8zR1ktJYYD5QCUCgmOImUJCXHvrd+Tw406DvvAfr7xBIp3E4bbmffLqBI3BoDiGecN6/Yb8YAOiMJcj0O7nv/WfzoltVAOgvHqjA0F1CcHJeDHI9Dv1eC5/Y3AZrQTvQQ0m3dMd6s6SCRTJnXbO1x7SPN3Vn7+reH4sQz6gD6TgMFONaq1T4YAWqAykJdAbQpBaBQKPrAEIzxpBx0fvxoUN3YmbGevoiahWCaBWB1GRlCPxxL9c4C0n9eWJpDc1eMUCxBMBwn4HFy7qJi1s0rBNK9eIxrLSjJoS0Up6YtTK7XiV8f0tIdTfLM/kbz3oY1YfDNv+7hnf+7meauGIYb3gjwGmtLpCRH9N5E0UQKIbTzWrtj6WZwDlvWmoNYImWupU6vASjyu83XDQugpm3whW8jjVIACsUEx5odM9btla0Y7pCBFEC6DqBvCyAUS5gCvLNHDKCywAdobpNgJEGu1wlAnv6v6QLSd+RLywMAbD7cQsDjwOd2mOe9UN1MQP/ZiBGA9jk+sbuermiCXSc7zONGgNf6Oe+3PHdJjibA20KaAnAYdQB9uIACHm3NDboCyPc5zdcDHie5Hgcn28N0RuIcburq+0MdJZQCUCgmONEewcSxREpJU2eUjnDcrFodyBXVVxA4lUpn7VizgHrWAZTqhVLtoTjBSJyA7tLxOO14nDYzCGsokAuXlnLVygoSScncIj8+p7br3ny4ha5ogrcuLwPS08IAntnXaAakXzvWah5Pu5fSn3O1oQDiSTOI29ZtdQGJPrOAcr3a2hv0YLahxAxmFvg42Rbm7n/u5/p7XiaVkmza08Adv9mKlJI9tUH+8nrNqCn+ERkKr1AoRg+r0B9rC+D56mZuu+81vnLVsvR6BghGx3q4gAyFEekxG9fo2Z9OA9VeN4RsezhGZyRhukoACnyutAtI/yxKAx7+511nEE0kcdhs2GwCn8vOliOaYL94aRl/ef1khgXw2M5ac6D71qNt+rWd2S2A+rQFUJ7rYScdNOkC3WkTJLLEAKSUGRZAfYemPK0WAEBlgZfjLSEON3fTEY5TF4zw+K56ntjTQHsozhN76vnRU9VcubKi38/8VFEKQKGY4Fh33CNlATQGI+T7XLgc/TsBGoIRkinJ9584MOAavv7obk62hzN6AVnPtxZmdcfSWU3pQjDtZyNQ2haK0xmJk+sJmO/L8zpp111AxvnGYHZD4QD4XA6au6LMKfIxv8QPaC6h/33+MHf/cz/xVIp3rZvNH7fWsLOmHYDFZYFeCiDgcVCtp51GEylTORkVvE6Hzew7JKVE6EGCREprbGdYL42dEew2QY47U+TOzPfy7P5GU4EcbOzioB5rOdEW4nhriPJcDx6nndFAuYAUigmOdcdt3ZmeavAwEk9y8Q+e4zevHB3EvdN+epseAO3LBbT5cAsv6UPPXQ6bKbSMNYctCsBw40DvQjCjl09HKKYHgdNCM9/npKOHBeDNIhz9bu3YmjkFptslGI6z7VgbAY+D950zlw+et4A5RT7iSYnXaWdWoa9XELiqMo+jLd1E4lrqZ47bQY7bkVYAdpupRBOWAL11LCZojeDyvU5TQRhUFngzrIeDjV2mwjnRGuZ4S4jZhb6sn/dIoBSAQjHByRYDONjYybnfe4ZXj7T29bY+OdDQSWckQW37wG0IrL7wRaWBXusxSOnZMqGYNubQ5bCZO3Nj52/tzdPSnVYA6TRQ7TyjWVprd5yuaDoIDJDvdZntGgyF4nH2FmM+l6Y01swpMN8fjMRp6oqypDzA1962nFmFPuYVa9ZBccBFod9lSQPVnnFOkR8ptfXGkxK3w06h32V29tRGQmpC3RoITisAbR3NXVHyerh/IJ0JlOtxkOd18mJ1k/l5GRaAUgAKxRThZHuYB7eeGNJ7YlliAMYgEaMqdijsOqkVchmCtz+M+33g3Hm8e/1sIHsMoC4YyVAMbruN4hxXxlqtLqC2DAWQtgCcdoHHaSfH7eBke4iUxY0CmgVgxACMmEJWC8CVtgD8Ljs2oQWBm7uipoIBmKsrgJIcNwU+F5F4inAsaT53sZ7106oXirmdNmbkeziqzzQw6gBAaw5nYB2LCZCSWvyiJ0bG07r5RSwszeHFg83ma9UNXTR2RpUCUCimCg+8epzP/WnnkIaBW10uEUsWDWgdJofKrlot7bFnXnz2e6ewCfjyVct4z9lzcdpFVhfQkabMIS9aDEDbLRsZMFYXkGEBOGzCUgeQwqP78fO8TrMjqOFGAcjTFYCUMm0BuLK5gBwE3A4WlQYQQpDrdWoWQGfUFOoA84p0CyDHTaFfu09rKGZ+voYSM1pEuB02ZhX4zOpdh02YCiCWxQLI9Vitl94WwOwiHx6njYuWlrKgxG+6g2YVennlULN5zmihgsAKxRhiuA5au2K9AoJ9kc0FZOymazuG3k1yt573PhglFIkn8Tjtpu/a7bBndQEdae7SX7eZMQDQe97ra7RaAEawtTjHnZEFZNQOFPidZj+gTCHqIpbUisgMZehx9FYA16+eyYaFRdj1wEWux0ldR4RQLJnVAigOuM0demtXzIx9GIVbLYYF4NBiBUbhmMthM7/PcAElDQWQ/h1ncwHleZ288LmLKPK7zHYVxTluVs7M4+9v1gMoC0ChmCo06MHD1tDgG4D1bwEMTQHEkyn26mmNg7EAIomkmc0DhoDvbQEcaurG57JzxuwCAFz6rrg8121aAEbap8MmTAVQmuvOKAQzMnnyvS5zKExPFxBoNQKReAq7Le2Dt3Ld6pnccd4C8+dcr4NDeqFVidUCKLZaALoCCMXMGIBhARjrdTtsVBak01IdNhtOR38xgEzllY2SgBubTbCgJAeARaU5zCpIC32lABSKKYKxG7b6wAfC6nM3dt+GIhjs5CyD6oYuYrqvfXAWQCojBTHbnF/QeubMK/azRK/KdemCvCzXY+bAGy6bAr/LLLgqyXHrw9yTugLQRFK+z2l2+swMAqcVQDiexOOw9cqsyUae18nxFs2isFoApQE3d12xlLevnmkqgLZuiwtIP9dwWbmdNmZZBLLTnnYBZVMAViuvZw1ATxaU6gqgLMdUMjluh7mu0UC5gBSKMcTYDbcORQFYXUA9UiqNfvKDEYKQ9v+vmpU/qKlb0UQPBeDsywXUTVVlHovKNCFmdQG1dEeJJ1OmC6jI7zLbL5fmagK2O5okGk+a78tsmdDbjdIe1oS0N4v/Pxu5HqeZpmmNAQgh+OD5mqVgpKa2dseIxJM4bMJMIW01YwD2jN25027DCP3GsgSBXQ4tTTSWSA2oAGYVeDl/cQmXnlZOPKW9f1ahb9C/21NBWQAKxRgRiSfNDJahKYDehWDpnjpJcxj6YNhX14nHaWPFzDxzhu5Aax7IBRRNJKlpCzG/2G+mirotCkBKrd++sasuyknvaEv01s1dkYRmAejKxpoxk+EC0t0oHaG4GZ8YDNY4gtUC6HmOTWjtIML6tY0dvNUFVBpwm4rKaU/XO4Tj6d+DYQG4HDY8+rk920D0xGG38evbzuLcRcWmkpld6O33PcNFKQCFYoxossx/HVIMIEshmLUgbChxgKMt3cwt8pPrcdIdSw7YXTQST5pCGdJBXisnWrV0zXklftbMKeALVyzl/CUlAJTnacK2IRghFEtgt4kMYWz0/QlG4loQOIuwtJ5f4DcsgCEqAL0nj03Qp0vFZhMEPE6C4bjp+nI7bNhtIu0CcmitJir1/H2nXVCg7+yt08SsCiCbUhuIygIvdpswg9SjhVIACsUY0WCZ/zqkGICeimkT6QKlsEUBDCUOcKS5m/klfnNXPdDgdC0102oB2HvFAGr0fvazCnzYbYIPnb/AFNrGcJaGYITuaBKf057htjF2413RREYMwBCWLssOG9IWQHsoTjiWzFoDkA1jPUU5bjMzKBsBj4POSIJoPInHqcUXctyOdBaQfr9KPQ7gsNvMtbZZlLrpArLbMuIag8XjtPOr953J7atK4MCBgd9wiqgYgEIxRtQH09WjLUN0ARlC0HC/hGNJ7DZBMiXNXvMDkUimONEa4ooV5aYC6IokMnbY2e6db9m5up22XsPWjftX5Pd2Vxi9cxqCUcKxJD63HV82BRBJEI2nKPLrWUC6sLS6f0Cr+nU5bLSHtUydwSoAI3Zg9f9nI9ej1Qs47Tbz2jluR4YLCDR/PWgCvsCfRQHoFoDb0hIjIwsoHIaGBqithRMn4Phx7fvGRu2rvp7zT5yADr1VdSQC7v7XfiqMmwIQQlwO/AiwA7+QUn53vNaiUIwFRjvlhaWBIVsAhuAxLIBQPMnMfC8n2kKDVgA1bWESKcm8Yr/ZKmGgTCDNFZIZA2jr4b6q64jooxh7C6hCnwunXVAfjBCKJ/G5HKZgddltZlaPZgGk6wAMpZPbw28uhCDfq/UDCseTvRREXxhKri//v0HA4yAYSeB32U3B7XfbzcIvUwGYFoDA77LjtAva9PgOLS3kbnmJG3e+SPH/bOOjL+zG1tDAjFfuhoZ6qKuDYJaxmjk5UFYGJSWwYAGcfz7MmqV9jRLjogCEEHbgf4C3AjXAa0KIR6WUe8ZjPQrFWNAYjOBy2Jhf7GdvfVoA/GhTNStm5nLxsrKs74vGtfx4ISytlWOa8CsNuAddDWxMtppX7Dd74Q8UCNbqAKwxgN4uoPqOMCU5bjMd0orNJigNeGgIRgjHEniddlMBeF12M0++s5cLKLsFoL3mokXP1MmmdLJhxABKBrIAvE5OtIawC2EqPr8lldNwAVVV5lEUD1G+axvisWq+9czjrH20Ft53DBoaOB84H+BxuNztpdGbh71wAaxcCW99K1RUQHm59q8h5PPyBvUsI8l4WQBnAQellIcBhBAPANcCSgEopiwNwQhluVrBkTUL6OfPH8LncvDcZ4syhI2BsTMWZMYAvE475XneQVsAVgVwtCVz6HpfRHRfuEG2IHBdRySr+8egLNdNQzCClOBz2fHq1ofXac9wRUXilkIwwwLI4p4qz/NQ3xEhMsQ0UBjYAsj1OOmMJPA47RSJBOzaxZlHdjDjwHHKO5sp/MwjcOQQ5+zbx7baWviB9r5rXV7qK+fDlVfC8uU8aSvmm/sTPPzNt/PxR/azty7IG1+9dFBrHUvGSwHMBKwdsWqAdT1PEkLcAdwBMHv27LFZmUIxStQHI5QFPBT4XXSE4ySSKRIpSSiWJBRL8ssXj/CJixf1el8sqQ1YsdtERiVwjttBmdeZMdKwP462dBPwODIU0EAuoN51AL3TQOs6IizUq1izUZbr4UBDJwGPk4DHgVdXKD6XlmXjsms+/WxZQNksgBn5Xt482aE1jsvSBsIkFIJnn4Xdu5l/op5/f343Z21zw30eSCbB4dB23Xl54PVCKsW1+xo49+AxVjUcZE79UZApvmi5pNxeAIsXwyWXwPLl5tdt/zhJEhsPfuhsAI4+f5gTDXtx5ubgdtgy4igTifFSANnC8L3y0aSU9wL3Aqxdu3b8pmErFCNAYzDKshm5FPqcSKkNKDF2016nnXufP8wHzp3XywqIxlO4nTbstvTuOxxLUpzjZnFpgL+/WUcoljD9+n1xpLmb+cV+LbPFsvMGbYJVeyhuBjQNeqZaZusFVN8R4dyFxX3ed26xn017G5iR76Us122u0+gxVJTjoqUrptcBaArAbhPk+5xZc+crC7y0dkWZGe1gsb0eHtwHNTXQ3g6JhPa1axc884wWPAUKnE6u9AbwduSB2wV2O8Tjmi++o0M7z2Zjg7DR5s7h4KzF7Ft/MVfcfDE/3dPJQzVRGnMKefX7N2cdopOf05LRmdWaBfSONbPMZnITjfFSADWANbJRCdSO01oUU5COcJwTrSFWzBx7v2pfNAQjXLCklEKjxXB3zBSmFy8r5a8766jrCLOwNJDxPqNHTk8LwOeys6Q8gJRwoKGLVbPy+73/keZu1szRevUYBU6GBfDg1hN847E9bPnixaZfXkqpu2V6uIAsMYDOiNazv0LP9snG2jkF/PRZybGWEGfMLjC7dxrZQMU5bpq7osSMXkBdXbBrF/f7D1O2bzt88QFNSIfDEApx8/4jvGvfHvIjWVphOxzgdEJlJXzwg5pLZv16RCBA/iAqav/vhcN8+2978bvsXFVVwRXvOJ2GR3dzIHoUIcjadwgy21uApQ7AbuOqqtEZ5zgSjJcCeA1YJISYB5wEbgH+ZZzWopiC/PKFw9z7wmF2ff0yHFmCk2NNIpmiO5Yk3+ek0Og62R0joguKhXofmNbu3kFZwzXisNvMjpFGDvxSvffO/vpgvwogEk9ysj3MDWdUAuDXd+FGFfHzB5oJxbRzlpY79ftqa7NaAC69EthoP2EUoZX3qwAKscskle0NnLH9EKdtbuAbz+9gkSMOD8Pdx5qJJpJ8KJZk2W+DUHscgOXGBQxXjdcLXi/uvCIeXXouB4rnsPrCNVz3tvWawM/Ph2G2TTBiBd2xZEYWEGjKr6+2DAU+J216m2ohBLGk1m/J1k/NwURgXBSAlDIhhPgY8E+0NNBfSSl3j8daFFOTmrYwkXiK+mDEHLoxnqSFqc2sZm2z9J03OkH2TLE03pvjduCw2zIsAI/TzuxCH16nnX16h8++qG7oQkrMZm02fT5tVySBlJKtx7TJYvUdEZaW52asuacFkJLa+EOnXZjtqGfkeyEahR07YOdO2L0b9uyBmhryGhupbmnBJtNe3GJPDtG8AqACh13QGUkhgNZFp5H3odvh9NNh4UItLbKgAGzpNQTbw3zpu09r992wFFamu34OFyNbCLDUATj1Z+873lDgc5FMSYKRBHlepzYXeQJsPAZi3OoApJR/B/4+XvdXTG2aujSf68m28IRSAG6H3ewx39od760AstQHGGmgTr2pGOgWgMuOzSZYXJbDvrr+FcDeOi3tdFlFrnks4HHQFY1T0xY2axSsbSWMxnMep10T7keOMGf3Di48tJfk/W04O9oo3l7Nv287QNWmb8CbOyCmr9/ng2XLYOlSOO88nm2VPN7pZvXlG1h20Tqu/90url01gx/dspo/Pr6Xnz93GIBvX7eCeevn9PssZQG3WQQ30sPSre2b3aYCSFsAfWFUA7eHYmkF0M/5EwVVCayYkhhjCI0CnrFkx4l2lpQHMoSTkTmjZYSkO0yG41pF7xx96pNZTGTBSAN16hZAXM8e8unXX1qey5N7G/rtCrqnLojPZWeOpZVxjttBVzTB68fbAPDFwiS3boPDL8OhQ/j2HeR3L7zB6t+2Qv1JSKV4G/A2gD9p11hms1HmCeA8owruvBPWrYPVq2Hu3Ixde+f2k/zxge3Mr1qKp0iLQ5gxAH86NbM/IWvgsNsoz/Vwsj086ErgwWJNO+1ZB+DOMnvYwJwl0B1jTpFfKQCFYjyxWgBjSVt3jOvveYlvX7eSf1mXTl02Aqdup9YaIOBx0NiptUku8LnMlMj2PlxAbr2tcCSRMq0GIwd+SXmAP2w9QVNX1Oy905O9dUGWlAc0n3QoBMeOcd6h11j80hEW/k81L+3ZwcyOxoz3uItL8DsLaVu1Fv/t74eFC3m2w8Z/vdrA/37sIkrnzeRLz9Tw5IEWtn75kn4/l3XzinDYBKUBtym0DQVp7Q7qHqRAn5nv5WR7OOs4yOGQzQVkKoB+XEDWQTWAHgNQCkChGHNiiZSZ5z7WFkBLd4yUhJPtoYzjVhcQwJwiH0dbQnidNgr9ToQQFPhcWdtEG1lAWgZOkkjM4poBSyC4M1MBtLXB668jt23j5o1PcUa0Cb5Zq/WgAb6in1ZbPJNji6t4umwe7bPm4V1xGt8/mOCb/3IWn/3TTv731rVUnqZVKbe/cZIdNdvpnr8Iiv3UdB7uNwPIoDzPw1OfPp8Z+V7TzWXNAjIYjAUAMCNfu6dnhHfZgQwLQFtfwFQAg7MAAGUBKBTjhTXneqwVQFBvrWC4oAysLiCAuUV+dtZ0mJXBYKQSpl1A3/rrHmbke4nqPfndThvxWJz4rt1ctv9lVv32efhpPatqG3hw3wmW/EWCSGp++EgE6rWZsgI411+AXLQIrroK5s+HuXP5/v4If4nmcVJ4+exlS9h+op3jLSFm+ryEXY1m99KelcDG80gp2VMb5MKlpYP6bOboA9iNXbs3mwUwSKE5U2/GNthK4MFiLTzrbQH0vbb8Hh1BoyoIrFAMnR9uOkCe18n7N8w75WsYwtfnso+5C8hI0zRcUAZGCwdjVzmv2M/f36wDYMVMLTCrpRLqFkAyycsv7GRduJ5/2bOba7a0Unr0AB8/fADP92L83LhwZSXOklISNgfBslLyZhaBy6V9LVgAa9fynL+S9z56mD9/+GzK5hSaa2r8005Obj2Bwya4cU0lDcEIrx5pNWsDjBYTGb2AdGUQjaeoaQvT0h3j9Mqh1VoE3A4+euECLl1eDvS0AAbrAtJiGSMdA3DabfhcdkKxZO8YQD9ry/U4sNuE6QKKJ1ODVmbjiVIAigmDlJL7Xj7KaRW5g1YAzV1R2kOxjOIpY/DKypl5bD/RPqSRiQD76oN88oHt/O72daZw+t4/9mEXgs9ctiTre7Yda2PlzDw6DAXQObAFkJJwvDXEhfPy4Nlned9j9zF7+xb4eiuyuZnHU+mCq1B+Ea0Ll/Kb1Vdx/jsu4tN7knzuE9dw3hnzSMaT/MtX/sHnLl/CRy5YyBvH21gxM8/0Qe98qhqAJeW5GWsyqoEvW15Oaa6H8jwPHeG4+QxGRlCmBWC0pU6xs0ZrQXH6AAVoPRFC8NnLlpo/Wwe09BdotXLGnHzKct2jMjA94HEQiiUtWUADB4E1F57THPQTiiVGPENpNFAKQDFhONYSMod9D5b/evIAz+xr5OW7LjaPNerCd/XsArYcac0IjtZ1hHng1RMU5bi4YkVF1uZgD7x6gn31neytC/KWRSUcbe7m588dojTgyaoAdp3s4IafvswPb15Fp757buypAOKWGEAkwtL2Gt7z+l8578jrnP/jXRAOcbHdwfbKZXDddQTzirh7ezuHC2eyv2Qu//qO9fhcdv79kd2UX7aaXa1v4MrP1a9pw2ETdEUS1HWEuf6el/mvm0/n+tVa0dex1hDluZ6MAeWQFmzvWq8Fq8tzM335daYCyJwIBppC21nTjstuM+sGThWnXcuMag/FB71rXlqey5Yv9h94PlVyPU4agtF0HYBnYBcQaKmgRhC/LRRncVnf/ZEmCkoBKCYMO2ragfTA88FQ3xGhtiOiV8tq/2GN3feqWZpr4mSb1q5YCMF/P32Q32/RKk1/v+U4D390Q4aAS6Uk/9il+c6N3PifPXeIlNSaubV1x3r1y/mb7sqpD0bMEYutnWGSe/dhf30b7N/Pstd28sj2PSz7RRu0NLMc+BZwLL+cw5ddx9L33cRPU5X84NV6Dn7nSvYfa+N3P3/FvIfbYTMbnxlCxhBQRm+frmiC5k7tNevA97qOMBX5vQO1bzu9ApsQnD2/COhdzWsMsPH0aAcNmkLbfqKdZRWBEQl2FvldugIY/12zEQcw/i6MdNuB1lbgd5mTw9q6Y0MaATleKAWgGHGe3d/I8hl5A7be7ckbx9uBzHm3ViLxJN99fB8fPH8+FXlaENAwuRuDUXNIR1NXhEK/yww6fvGhXXRG4mz81/U8tr2W61fP5IoV5dzx223c/c/9fOXq09JrONFuCr6GYISGYIQ/v17D4rIcDjR0sbcuyDmWxmdSSra++CY373iBlUceIbelkTUHDnFaw2Hs39MzgWw28ioqOegtJnzpuQQWzUfOmsVV21Ls8ZXy43euZunpM/C9eISUrCcYifca8+h22E0XhDF71jpZy6jqNfr7W8dP1nVEzEwhKwtLA9x5Sfq48Zl6nDbyvS7zc7C6PozvQ/GkZvmsqcz6uxoqxTluDjV1Twi/uTGExlCwNps29GWgtRXnuDjQ0EUqJWkLxfqcPTyRUApAMaJ0RuLcdt9rvGVRCb++7awhvde0ACwKIJmSPLj1BDecUcnrx9q47+WjtIVi/OiW1UC6cra2PUxJwE0wHKcxGKUkx21miuyrD2ITgnf+72Y6owluPnMW6+cX8e71s/nli0e447z5lOnuj8ffrMNlt+GwCxqDEbYdayOelNx15TLe/3+vUX2olnNCtXDoEOzZQ+TPD/HHN7Zpa7U7CBaUcMidzyPLL+Ci91zJzEvOgyVLeGx7PXf95U0233UxgTwPAnB0vgg1HRSZWUBGgVisV49/t8Nm7kDbw9ozWy2XHLeDzmjCzEIyrBcpJfUdES5YPHCmjuECWlQaIJmSfVgAmhDcUxukO5akqjJ/wOsOBiPWMtgYwGhiFINZYx/LZ+axaACXTpHfTXNXC8FInJQc2hD48UIpAMWIUt3YRUrCcweaeO5AE+cvLhnU+2KJFLtrtXYFVhfQa0dbuesvb2bMZX10Ry0fuWAhS8oD5mzd+mCEpzcd4PdbjlOc46aywEuux8mXr1rG4rIAmw+3cM+zh5hd6GPdPC0T5sqVFfxu83EONnaZCuCpfY2cu6iYjuO1lD37BBV/2M/9L29m/V/C7D5Wg/97mTvzjsUr+PH57+WN1efjX3kaHo+Tv+3UXEKzrjyTmUs0wWu0VbDuIo1UUENQpIeLx6lrDxNwO3DoowbdTpspHI1ME28PC6A7miAYNmIQmvAORhKEYkkzb74/vC47xTkullUEMtJn3VmCwLtrtQDwsorelsWpUKyngk5EFxDAgx88e8D3Fee4aQ/FzfiPsgAU047qBq0nTYHPyb//bS/nLSrOyMCJJ1M0dUa15mEW3jzZTiyRYnahL6MfTa0uiPbUBenSZ7XahOBHTx3gR7esNida1bZH2HWyg85Igs5IgtV6Zsrtb5kPwJlzC3n5UAvvWFNprmd+sbajO9zczYbKHDq27+KKx/6PW5t3Urp3BzYpSTgc7Cudj33dal6ccwYnPPmEK2ez31fCdz59LVf9cgfLZ+bhlJKWcIKATLc3tmYCmYVgFmE6t1hzURl58KYC0C2AinwPXpeDtlA7bofdbJlwuElrg2xNgczxaAoy2MMFZLiS+uvWaeW+959FWa6Hrz+W7s3YsxkcaEVnkM7tHy4V+V5twMtEsAC8hgUwNGVk/B4P6XMBesaKJiJKAShGlAMNXbgdNj50/gL+4/F9tIXi5k6opi3Exze+we6TQV6+6yLT7K/rCPOJjdsp8Dm5aGkp9718lGRKYrcJ0w2xpzZINJFkSXmABSU5PLO/KaNzZn1HmEON3dgEpCSU5GbGH7wuOw//65mwbx/cfz9UV1NWXc0jz21jwc+bob2FPOBzQFfVav5544d4LH8xsdVnUB8X/PXjb+F1S9MygH0P7KWlO8adFy/i1y8f5XhrCCkl80v8mgKw1AJE4pmVwAA3rqnEZRfmXFvjc2oLaQqgPM9LvtfJjhPtuB02Fpfn4LQLdumWkreHC+h4Syhdh9AZJZmSpitpMNW6gDk/wWhZ3bMFsqHAGjujFOe4emUWnSrvXj+HdfMKJ4QFsKAkh+IcV0aMZTAYVsyBBk0BFCoXkGK6caChk4WlOWZzs9r2MIV+F1JK3vWLLRzTZ9HWtocpznFzoKGT23+9lWA4zu//dT2bD7cAWsDX73aY1sCeuiBSSi5eWkZFvofmrmhGte2hunacx4/ytVk2du45waVvHIHDT8PRo5q/vrpaE/4JfQSiEIjZs0n5i3l9/hLOe+taHu/y8M3uUp76wbvY8dRBnnzxMLO6UmYL5dP0TppVlXnMKvTxt511XLCkhDVzCnhsRy2tXTFsQrCiyE/A7chYXzSRxGkX2C394WcV+vjYRekRkNZ+MnUdEZbPyDUD6UYMYFlFLjtrOnA7bBm95gMeIwagPV9KQktX1NKvv++ZvdkwhrL33AVbq1tHavcPmgJbPbtgxK43HG44YybXnD5jyL18jA1NdaNuBft7TzObaCgFoBhRqhu6OHtBkZlRUtcRYcXMPA43d3OsJcTNa2dpjcs6oxxs7OLt97yM12Xnt7evY2VlHtstgWC/22HuYA13yqKyHIqj3aw7/ibJ//cKP/nnc6xsPMTM9gYcMtV7QW631vpgwQJ429ugqgpWrtR6zbvd/OL3r7P7ZAfPfvZCfv/LLeR3xfC5HJTluoknJUdaurlE74Ozfn4Ry2fk8p3rVlKW50ZKyb9dshjQdu+d0QQIrSq0JODOsACMfj79keN24LQLGoIRmruilOd5mKm7yoxUy6rKPHbWdPRqgWBkARkuINACwXUdEWwC08oYLEZrg54uGYddqzlIpGRGZ9GphBACl2Pog1yKDAVgWADKBaSYTnSE49QHIywqyzHzzg0f/pbD2sCRa1bNMBVAbXuYrmiChz+6wZyIFYiGWFOzh9QzDsj1MHPzVu44cojKhuMsbDnB2l/W4Wpu4jr9ngV5ZZyYfxqPes7jeH4Z/3b7pcyYWwF+P+TmagNFbH3v5OYX+/nHrnqiiSTbT7RzddUMADMoLCXM0rOJynI9/O0TbzHfe8+71pjfG/7eTn0gSHHA3SMGkBwwjVAIQb7PxatHtc9qRp6Xi5aW8s6zZpl9/LWsm+O9WiDkuJ2E40naumOmG6whGKFOz44a6m7W2L1m84O7HDYSseSIWgBTASMGcLhZc4OOdJuK0UApAMWIcVA3fReXBij2u3HZbdTqQcjNh1soDbhZU+6jPNiMfP0N3C3NvH3PPub/vhqOHYMXXuDaN97gulQK7teu+XX92kGXj8NFlcQvvYzgoqV8Znccx5lnsqkV3rVuNvdvOY7DJvj3ay+HIQi7ecV+kinJs/ubtODx7HwAyiwxhMpB7HSLLLu9XK+T0oDbzGoCY6jLwOu6fvVM7n1eizOU53koynHzH2+vMl8/XU+77GkBGGML6zoizC7UOo02dEaoD0aG7P6BtAWQbc1uh41QLGm6+RQaAbcDl91GLJmiIs89pPYj44VSAIoR40BDF0jJadEWbI+8zB17X2BpdRT5aIp3P7mFb7adxPPlRjZb3nMTwGOAxwPr13P0Q5/kG40BvnLjGuYU+njnfdu45G0b+M3hCO3hOLu+cRkyluTZr/2TnG4HkDB3x3OL/UPe6c7TM3H++2mtX85afWi6ta3yrEFMFLPmfOd6nFomUI8soMH0uv/C5Utp6Yrx59drzLVZWViag89l77W7NFIX6zoirJlTwLHWkOkCWlgy9JYEBaYLqPeaNVdWXCmAHgghKM5xUdsRmRQ1AKAUgGK4JBLaHNgXX6Tqj4/z6o7XKP1/mgvjM/opyfwCnN5SWtefS/76VfxgZzv+mRXUuQK0+nL58Scu0wZ622zUHWzm2V9s4cNr1+Mp9PHapgg3zJvF2bY2GoIRre2B20FAL3wKuB2mIDoVQWcI2V0ng9y0tpL5+jVKrRZAwcA76MIMC8BBrtdJVyxBKiWx2cSgXECgVZ3e/Y4qPnbRQrOy2YrdJlg7t5Ces8aNubUd4TgFPhfFOW4aOiLUd0Q411K5PFjMIHCWuIWRCaRcQL0pynFT2xGZFP5/UApAMRgiEWhuhpMnoaYGjhyBvXu1wd+7dkF3NwBlheXsWrqG0tuuhzPP5OuvtfJsS4oPXnoad/3lTTZ96nwozeHVe18hmZI0d8VYPiMXCtMtio1e8eF4knpLDvt3374SaVlSRb6HzoYuCnNcZorjgtKhC6R8n4sivwuHXfClq9ItIdwOOwU+J067bVD54BkKwOMk1+NASuiMajEBY6rXYLDZRNbdv8GPb1nV61iOpY99rlcLYm89prV2HkwRWE+MmEa2yly3w0bA4zCVhCKNWdOhFIBiJOmOJuiOJfoc+TcY9tUHKfS5KLV2fZQSmppg/344cAAOHtQE/JEjmrBva4Nwlp76ZWVw2mlw222wYQNs2MCVv97HWxaVcMFNpwPga95HzYnDPH+gibJcNwtKNKFWEvCws6adhmCEt+oZNgaGayMST5p96cvzPDh6uHbK87wcaOiiwOdidqGfS08r4/LlFaf0uXz/ptMpDXjI82YKtLJcj9kLfiDyLcIwz+s0XTKdkTh5XieReHLEctzzs7gXrPn4AY+TsoCHp/Y1Uhpwm4HtoRBwO3DYRNY1ux125hT5JoWPe6wxUkELJ4lyVApgkvD9Jw7w7P5Gnv7MBeax4y0hZuT3Fo598fFfvcK6poN8q6AF8frrcPiwJui7utInORwwZ4421Puyy7TdeUEBFBdDZSXMnAmzZ2fs2kHrUNnYuSOjBW5FvpdESvLUvkauOX2GKTBKctzUtIVJpmSvFsSGAgjHk2ZnxYrc3i6YGfquv9DvwuWwce+tawf1GWTjgiXZ++R84YqlgxbaTruNXI+DYCRBrtdp9pMxKpWjidSIFU1lwzrJKtfjYHF5gJ0nO/j9v67vVXU9GLSMJGfWytybz5w1IZq2TUSUBaAYFeqDYY60dBPXh01H4kku+a/nuPS0Mv77nat778aSSdiyBV54QXPV7NnDX7fvxJ2MI4WApUu1XPiLLtLy5Bcv1r5mz9aUwCCJxJPYbcKsflxclu4NYwjpWCLFWxal/dAlAbfZNrlnhaqR3RKOpajviOB12jMGdRsYrQ1GM9jWl2Loi6Ict6YAPA5ztqxRmRuNpyjyj57QtFoquV4nt22Yx50XLxrWUJL3nTPXTM+18u71c075mlMdo12HigEoRpTOSAKp53ZXFvgIxZLEEin+urOOM2YXcNu586C9HZ5+Gv72N5KPPYa9qUl7c2UlqWXL+PUZV/PqrBUkzjmHe++8dFh93CPxJBd//zlOtoeZVejlA/oEL2vHxApL+uEGSyCy2DIDtmePGo/FAqgLRijP82R1NVSYFsDEMbULfE6OoLlg0i4gwwJIDioL6FSxWhe5Hic2m8BjG979rFXKisFRHMjs6zTRUQpgkmBtelZZ4COaSJITDXFOw35in/8NqeQxbK+9BqkU5OZyZO15/Mi/jK/+5N8omV1Bc2eEf//OUyyryGVvXZAzv7OJL121jJvWzuLbf91DwOPkzksG/x++uSvKyfYwZ8zO5/Xj7fzixSP4XXazchUwvz+tIjdj7qt1TkBFjxx1awygKRjts4LVeN9EMrUL/W68Tjsuh81sKNYZ1S2AIQSBT4VMBaD+W48XRgHhUGdhjBfqL2WSYARE2/cegIdfoeDBP7JjyxbsMkXcZqe7ajWBL30JLr0U1q3jr88d4bFN1XzcnUMJ0KG3EP7wBQvIcdv54l928fibddy0dhbPVzfhdzuGpACMls3vPWcuDcH91LSFWTUrP2O3nut1MDPfy+UryjPea/znsNtEr/8oRr+ccCxJayjW51g9w69tmNwTgdmFPo7oGTe9LYCBW0EMB7tNmMPMc70TxyqabqyfV8S971nDWXMLBz55AqAUwERDSqir09IsDx/Wvo4e5b9e2kFpWwNl39Ny7MXylfzP+htZ/i/X8PEjbu64YiWf1PvSQFpAGz3023VfdL7XyXmLS1hQesRsHNYRjpvdKgdLt379HLeDd62fzf/7x/5ewloIwVOfPr9XcZYh9EsD7ozmaMZ7vE672dYgW8YLwIISPz+6ZRWXLCvL+vp48OlLF/Oh87X204YCSMcABlcHMBxy3NowcyMArRh7bDbBpcvLBz5xgqAUwHiSSGgdKnfs0L62b9e+DN89aAHZ2bPptufy7Lw15K45nSu+8mGq3UX84L9f5OcXrmFeqtrstWNgTNUy5scaQ0SMdMVcj5PGoBa4DYYTCJEY0tJDMe18n8vBTWtn8dNnD7F2Tu9dT7YgZJHfjU303aPe47QTiiW0sXp9KAAhBNeumjmkNY82frfDDMa6HdoIwQwLYJR73ed4HDR2RrMGzRWKbKi/lLEmGoWnnoK//AUeeUQrsAJwubS8+quvhlWrYMUKrYPlzJmkbHZu+eLfAbhkWSlXzJ9P9FgboBXlrJtXxP1bjmUMRg+ZFoAm+DtMC0ATqLkeJ8FInFgiZSqLUCyBz5X+k+gIx0mmZNaMBsPC8LnsFOe4ee1Llwx6h2u3CQr97j571HtdNhqDUW2s3gTy8Q+VgMdJMJJASjnqLiBIxwFGM91UMbVQfyljQTwOzz0HGzdqgr+9HQIBTdhfcYUm8JcuBWd2073b0uK3tl1rjxzTJ0y5HDbOmlfIr146ws6aDs7UfY+GUG8zLQDt3zzdAsjzOekIx80h4gAtXTF8hek/ic/+cQdNXVEe+siGXmsKWRQADH160revW9FniwWv026OJJxIWT5DRasLiKengY2BC8jvsg+6LkShUApgNGhs1KZOPf+85uI5dEhTAjk5cP31cPPNcMklWq/6QWAEgF12mzniL5ZMCxVjxu0rh1pMBRDRBbQxNL0jHEcIrcITNOEUiado7kpP1Wrqipr9Z1IpyZYjrYRiCWKJVK+UUcMC6NmVcrD0DAxb8TrtHGnW2kv0FQOYDAS8TjojiTFVACoArBgKSgGMFN3d8Pjj8Lvfwd/+pvn3Fy/W3DrXXQdnnqnt9r2Dr8r8wZMH2F8f5DOXLgFgfomfffWdhGNJy5BxOwV+F6dX5vH0vkY+cbGWyWO6gCwxgDyv05wiZQiKk+0h834tFmVwpKXbdBsdauoyO24aWGMAI43HaTcD1JNhrF5f5HocdEbiRBP672qU+8NfVVXB8hl5o3oPxdRCKYDhcOKE5s9/9FH4xz+0njnl5fBv/wbve58m/IfBG8fb2FMb1CZNAUvKA+yr76S2I2xaAMbO/OJlZfzXpgM0dUYpCbjTLiBLFlC+ZXdoZIqcaE33+Wm2TLB643i7+f3eumBvBRDPdAGNJFarYrJUVGYj4HFQ2x4mGh8bC2CiBcUVE59hKQAhxI1oMzuWAWdJKbdaXrsL+ACQBD4hpfynfnwNcB/gBf4O3CmllEw0kknNhXPkiJaaKSUEg1pHzJMnYds2rXEawIwZ8IEPwA03wLnnDqmVQn80d8VoDcXMHH6jzUJdeyQdA9D9vRctLeUHTx7gmf2N3LR2FhEzBpAOAudZdtNG47MTrVYLwKoA2gi4HcSSKfbWpQebGIRjSYQYHaFm7XU/mYPAuZ5MF9Bw2jIoFKPBcCXVLuDtwM+tB4UQpwG3AMuBGcAmIcRiKWUS+ClwB7AZTQFcDjw+zHWMDMEgbN6sZef86U+aL78nXq/WEG3pUvjoR+Hii7WMnVHojNjSFUVKONGmCelFel+W2vYwKV1nGqmFy2fkUpHn4am9Ddy0dpbpAjKCwB2hzJx6I1Wwps1qAaRdQG8cb2fV7HzaQ3H21nX2Wlt3NInPaR+VjpCGoHTaBf5RsDDGioDHoSsAw12ngrOKicWwFICUci+QTQhcCzwgpYwCR4QQB4GzhBBHgVwp5Sv6+34DXMdYKoBwWAvM7tqluXCamrSvN9/UvqTUhPxVV2nB2rVrtZmyQmhB3Pz8URH2PUmlpFnEdbRZUwBG9WtnNIFD9+UbFoAQgouWlvLQGydJpqTpArIWglkHeBguoBo9BlCe6zFdQKFYgn31QT524ULqgxGe2tuIlDLj9xyOJ/CNUrqhoQAKfK5J3XI44NHm9HZHlQJQTExGKwYwEzIm/9Xox+L69z2PZ0UIcQeatcDs2bNPbSWHDsGLL8JLL2lf+/Zp/XIMcnKgpETrjHn99XDOOdpXztCnS40kwUichN4x82iLlhFj9MWJxJOm4Ldm58wr9hOKJemKJMwsnc5IgngyRXsontGz3ggC17SFcdgEswq9pgLYX99JSsKKmXkU+F08uLWGpq5oxiyCUCw5Kv5/SLuAJrP/H9LVwMbnOtp1AArFUBlQAQghNgHZcva+JKV8pK+3ZTkm+zmeFSnlvcC9AGvXrj21OMGll2rtFPLzNcH+jnfAypWa22buXG0W7QTE6o4xFECB34UQmP59yBQqxq4+GIkTjidNF0Rbd4xgJDMIbMQA2kNxCv3aCMGDjVplsNE2oijHbSqKvXWdvRRAz7m0I4XXpSm1/EkyVKMvjN+HqQBGuRJYoRgqAyoAKeUlp3DdGmCW5edKoFY/Xpnl+Ojxv/8LpaVaRo5t4v0H7I4m+Ooju5lV6M3o5WMNyJ5oDeF12rXxhA47kXjS1KROe1qnGjvO1u4YyZRkZr6XffWdHG8NISUZQWC3w4bLbiOWTJHndVKU42LzYe2eXXoKZq7HYQr9vXVBzl9cYr4/rCyAATF+H02dhgUw8f7+FNOb0fqLfBS4RQjhFkLMAxYBr0op64BOIcR6oTl3bwX6siJGhosu0nb7E1D4d0UTvONnr/Dn12v4w2snMl5r6U5bAPGkNIWJx2kjHE8STWrFWVYfuTGEpFEXOEbM4LBeVGUdeSiEMAPBuR4HRX43baE48WTK7F+T43GQ53MyI8/TKxOoZ9uIkcQaA5jMGL+PtAJQLiDFxGJYUlEIcb0QogY4G/ibEOKfAFLK3cCDwB7gH8BH9QwggA8DvwAOAoeYKBlA48CrR1rYWxdk7ZwC6joiZrsGSFsAhq/fGPrtddqJxFPEEincPUr+DSXRENTaRRjDwM2q2h5VooaLItfrpFiPL7R1x8z2EIYAM2YIWAnFkqdcBTwQxnUnuwVgKNh0DGDibUIU05th/UVKKR+SUlZKKd1SyjIp5WWW174jpVwgpVwipXzccnyrlHKF/trHJmQNwBhhNGq7drUWB7emWxoxgHnFWuaO0cLBo7dKjmXpLmkoAMMCmJmvtXU4arZVyFQAAW+6M2ixLmybuqJ0RRMIgZmCuawil0NN3Rmxh3B89F1Ak7kNBKQVbJP+u1QxAMVEQ/1FDoMTraEMoThUjCrdcxYUAbCvPr3LbumOUuBzUpqr7cxzPGkFEI0niSZSpnVgkHY5ZFoA+xs0xdJTARguoVyvw9xtt3bH6IwkyHE7TPfSsopckilpBolBrwMY9RjA1AgCn9RrLZQLSDHRmNYKoLEzwuU/fD6jGnawJFOSy3/4PL988Ui/5/3Xkwd4/M26rK+1hWI4bIL5xX6K/K4MN0tLV4yiHDcl+ihFo8Wv15W2AHo2aDMtgKBmAeT7XHiddg43dVMScPcav2iMDsz1OM2K2/ZQnGAknjFUZFmFVoG8x7K+8GjGAFxTIwaQ63Wwdk6B6QLyKAtAMcGY1n+RR5q62VffmbXVwUB0xxJ0x5JsP9He73n3bznO33fVZ32tTa/OFUKwtELr82PQ0hWjyO+iSB+gnuPWBLLHaUvHAHrsKD1OOy67zXQB+Vx2PnbRQv7tksU88cnzzGElBrnedAzAsA7aQzG6IglTmQDMKfLjddrNz0lKSWgUXUCrKvO5uqqC1bMKRuX6Y4UQgu/fdLrpSutpsSkU4820bgZnFFoZbROGQrfeoG2/RWj3dV44ln3aVlt33HRzLCvP5bebj5FIpnDYbTR3R1lWnkuRbgEELEHgtm6tw2RPC8A4r1F3AXmddj564cI+12YNAhuDYtpCcTp7KAC7TbCkPMArh1o43NTFjHyvVjA9SgqgwO/iJ/9yxqhce6yZU+Tn+zedzlN7Gyd1VbNiajKttyRxvaNmdx8Cuj+M8v7jrSFTGfTEaMlgnNuTVkt/nqUVuUQTKY62aO6o1u4YRTlagRakXUBup51IIkks2dsFBJoCMNIOB2o+ZsYAPA5cDht+l522UIzOaLzXVKl3rKmkurGLi3/wHM8d0EZW+lRzs0Fx+YoK7r7x9PFehkLRi2mtABJJ3QLoQ0D3h1XoH2jIbgUYiiXUh4Jpt8y8XVoeMK9ltG4o8rvTLiBrGmhMzwLKqgCc6IbNgC4asw5AVwT5PhcdobjuAsoMwL57/Rye/9yFSElaAYxSDEChUIwN01sBpIZhAVje05cbyKio7e7DxdTaHadAdwEZ6Z5HmrvN7KCiHBfF/kwLwOO0EUmksgaBgQzXzUCtGkwXkP5vgd+pWQA9XEAGM/O9FPldVOsKb7RcQAqFYmyYVgrgQ7/dxpcfftP8OZ4cTgwg/Z59fSgAw0oIZXERSSlpD8XMTBe/20FZrpvDTd3UdWg+/OIcN/NK/JxWkcvplfmAJtTDsexpoNBDAQwgoDcsLOZd62azfIY27CXf67LEALKnYFYWeE2FN1pBYIVCMTZMGwWQSklePNjM7tp0xo9pAfThw+8Pw62T63H06QIyZvmGLLUCoViC/33+MB1hrdunNdVxfnEOR5q7zGybpeUBctwO/n7nW1hZqY368xgxgEQq64hBQ3APZlhLod/Fd65facYK8n1OGoMRYslUVgsAoLLAZ45rVBaAQjG5mTZO3JPtYbqiCdr1CVkwPAvAEO6rZxew62RHv+dYYwzP7GviO3/fawpY68SreSV+Hn+zjl21HeS4HczWB7Rb8Tjt2nCySKJfC8B7CsNaCnwu6vQ2En0qgMJ0LYFfxQAUiknNtLEADDdNm6XfjhEEPiULQBfqq2fn09Idy+jeaWBcN5ZMmSMcW7u187YcaQWgwFKdO7/YT1sozssHWzhtRq45wN2KsVsPhuN9xAC0652Ke6bA58RozNGfBWCgXEAKxeRm+igA3a3SEY6T1NNkjDTQ4VgAVbprxui4mXmOpXdOzJjQpVkgWw63AJkWwPwSv3ktwy/fEyOwG0tmzwLKtbSMGCrWdtFG4VlPKgvSFoByASkUk5vpowB0C0BKTQnA8OoAQrEEXqedRaVa+uYhS58cA6tlYdzDsEBq9UBvoUXozitOTyFbPiMv632t7QSyp4GmXUBDxWqN9GUBzLIoAJUGqlBMbqaRAghi110qhhA2K4FPoQ6gK5rE73YwI9+L22HjUFNvBdBlUQCGlWHt8w+Z/W4qC7zmrN+BLABgFFxA6bX0pQCMDqOneg+FQjFxmBYKIBJPcqS5mxUztV21kWefGKYF4HfbsdsE84r9HGrK5gJKZJxvvTdoLRasgtZptzG7yIfLYWNhafaZxFbXTn8WwKm5gCwzg/tIA/W67BTnuAeVZaRQKCY20+J/8MHGLlISzp6vtV1uCxkuoOH1AjKyYBaU5mS1ADJcQFEjBhAzhXS+19kr0LtqVj5r5xTg7KNxmGeMLICerSCsVBZ48Z1ClpFCoZhYTAsFcEzvr7NmjtZd0rQABqgD+M0rR/nY71/P+lp3NInfrQnZBSU5WWcDZLUAQjHOmlsIZAaADb779ip+9b4z+3wWawyg3zTQU8wCMsjpwwUEMKvQ16uzqEKhmHxMi//F7eHM6VpmDEC3AKKJlNmF08obx9t55VBL1mt2xxLmEJUFJX5SUlM0S/SePqC1gnDaBfGkpDuWREpJa3eMBaU57KjpyBC4Btl29Vasgj17Idipu4ByPU6EAI/D3qcFAvCJixZSo08xUygUk5dpYQEYWT8z87047aKXCwiy9+uJJVKE+5j4leECKtH89T3dQN2xhDnQJRxLaMPcEykK/S7+Zd1sLltePuRn8VhmAGSzAHKH4QKy2QR5Xme/u3+ARWUBLlxaOuTrKxSKicW0sAA6wnFcdhsep418n8t0ARlpoKC5aPJ6DE2P6gpAStnL3211ARn5+z1TQbuiSUpzPdR2ROiOJmnV71voc/Gh82ed0rNYLYBs1oLbYcPnsvfZy2cgCnwulGtfoZgeTAsFEAzHyfU6EUJQ6HNZ0kDTCiBbz/5YMoWUmiLo6VLptoxE9LkcWh+dzsxq4K5I3LQOQrEEbXoRWDbf/2CxWgDZsnCEENz3/rOYW9y7jcRgyPel20krFIqpzbRQAB3hOHl67/t8n9PsB2R1AWXr2R/X2zeEY8kMBSClpDuayMiUyfc6TVeTQXc0Sb7PidMu6I4ladUVz3CGnXtcliBwH/GCs+YVnvL1bz93PkmpNIBCMR2YRgpAE7qFfhfVuqsmkRzYAgAIx5NYp9NGEylSEnzutFLI87lo76UAEvjdDnwuB6FownQ9DWfYuctuQwitonmggPGpcFVVxYhfU6FQTEymRRC4PZRWAPk+F+36Tjye6t8CMBq49QwEG+mdVgsgr4cFIKWkK5Yg4Hbgd9kJxZJmFXDhMFxAQgizGlgVYikUiuEwLSRIRzhuzt4t8DlpC8WRUmqpn3ohVl9ZQJBu5GZgtI6wtkPO9zrpsHQaDcWSSKkNevG5HYRiSdq6Y9hE31W2g8VjKgDVikGhUJw600YBWF1AyZQkGEmQSErzeLapXYYLqK8CL7/VBeR1ZriAus1zNAugO5agVZ8Alq3N81AwLIDRcAEpFIrpw5SXIMmUpDOSyBh8DtpA9ngqrQD6swB6toowegdZq2HzfU6C4Tgp3a1kdRNpMQDNAhhOBpCBW68GzlYHoFAoFINlykuQzoi2KzcEvVF92xaKk0imTMWQzQKI9hEDMHb31nbIeV4tfbJTf80IKmsKQLcAumMZ7Z9PFTMG4Jzyvz6FQjGKTPksICMwaygAQ2iHYgniyRRepx2X3daHBaAdM1xAqZTk3x7cbgZxewaBATr0gHNnVLuvNQYQiiVZUhZguBgxAGUBKBSK4TDtFICxa44mUsSTEo9T4HPbs9cB6HUCYUsv/0e212K48K3tFgzXknE/qwXgd9lpCEYIxZK8Y03lsJ9JxQAUCsVIMOUlSC8FoAvNaDxFIpXCabfhdzkGrAPQrqVl+RjZozk9YgCQbjzXbQkU+1wOM46wbhhFWgZGR1CVBaRQKIbDtFEAhoA2hGY0kSSRlDhsAp+rtwWQTElzdrChAIwKYgNfjywg6zmdliCwkS3kdthYWZl91ONQMFxATrtq2qNQKE6daaMAeloAsUSKeFKzAHxuB13RBIebupB6GwQjAwggEstUAMsqcgm4HRk78HwjBqDfryuiKYCAx2nGHVbNyh+RXbvHacflsKmBLAqFYlhMeQVgCO1eLqBEikRK4rQL/C47L1Q3c9H3n+OxnXVApgIw3DdGnv8PbjqdP3/knIz75PZQAJ2ROA6bwOO0mbGCkXD/gBZ78Cj/v0KhGCbDkiJCiLuFEPuEEDuFEA8JIfItr90lhDgohNgvhLjMcnyNEOJN/bUfi1HexgbDcVwOW6/qWW0IjMRht7FuXhFVlXmUBNz8cesJ7fVkOiaQjgFown1GnpfFPbJ5PE47HqctbQFEE+R4HAghTAVw5ggpgFvPnsN3b6gakWspFIrpy3C3kU8CK6SUVcAB4C4AIcRpwC3AcuBy4B4hhOH7+ClwB7BI/7p8mGvoF2sVMFizgJK6C0hw5yWLePRj53LLmbN46WAzjcFIhgVgKoBQDCHIGORuJd+b7jPUFUmY512wpJSPXLCAdfOKRuSZFpYGuHKlatqmUCiGx7AUgJTyCSmlET3dDBg5jtcCD0gpo1LKI8BB4CwhRAWQK6V8RWrO9t8A1w1nDQPRUwEYufMx3QXksKU/gutWzyQl4dEdtRmtoo06gHb9Wn21csjzpltNByMJctzafUsCbj53+VKVtqlQKCYUIymRbgMe17+fCZywvFajH5upf9/zeFaEEHcIIbYKIbY2NTWd0qJ6KgCbTeC0C60OIJHCYcmkWVCSQ1VlHn97sy7TArAEgXtODbOS53NaXEDxPi0FhUKhmAgMqACEEJuEELuyfF1rOedLQAK43ziU5VKyn+NZkVLeK6VcK6VcW1JSMtBSs9JTAYAWB4jGU8T1OgArC0tzaAxGs7uAwnEz2ycb1qEwnRGtFbRCoVBMVAaUUFLKS/p7XQjxXuBq4GIpzVFSNYB16G0lUKsfr8xyfNQ4fVY+M/O9GcfcDltGHYAVoyYgpgeBbQLCcU0ZtIfj5PXTy8fqAuqKJpQFoFAoJjTDklBCiMuBzwPnSylDlpceBX4vhPgBMAMt2PuqlDIphOgUQqwHtgC3Av89nDUMxL9fv7LXMU0B6DGAHhaAz+UgHE+ajeByvU7CepFYRyjGnMK+Z+3m+zItgBylABQKxQRmuBLqJ4AbeFLP5twspfyQlHK3EOJBYA+aa+ijUkojr/LDwH2AFy1m8Hivq44yLofNrPx19aim9TrtROIpovquP8/rTFcCZ3EnWTHOjcSTehbQ8Aa/KBQKxWgyLAUgpVzYz2vfAb6T5fhWYMVw7jtc3A47XXrvn54WgFfP2Q9a2kjXtkdIpaQ+WaxvoV7odwNQ3xEhlkxl9ApSKBSKica0zEt0O21m//9sMQDIrCCOxJN0RhNISb8WQElAUwBHmrsByFUuIIVCMYGZngrAYTMndvXMAjJaLRsKIFd36xgFXvn9BIENBXCoqQtAxQAUCsWEZloqAJfDZo51dNh7WgCa0LY2kUumJM1dUfPnvuhpAQTcKgagUCgmLtNSAbgddrNbp9PWMwtItwD0vv6GwK9tjwD0GwMoztGsg8NNmgJQFoBCoZjITFMFkB4B2dMCMILAHT26iNZ36AqgHwvA7bCT53WaFoAKAisUionMtFUARqVv7zoAwwLooQCCmgLI68cCAM0NZJybq9JAFQrFBGZaKgBrUzZnH1lAPQfJGBZAfzEAgJIct/m9cgEpFIqJzLRUANapXL2ygPQgcHtIG+ji1904Ne1hPE7bgBO9jEAwKBeQQqGY2ExTBZB+7F4xAKdhAcRwOWzmzztr2jm9Mn/AaxsKwO2wqfbPCoViQjMtJZQxFAZ6WwCGCyielBkKQEptXsBAGApAtYFQKBQTnempACxunJ6VwG6HDWNIpdNuw+uy6d8LrlhRPuC1jRiA6gSqUCgmOtNSAbgyXECZH4EQAp++63fZ07OEz19c2m8VsEHaAlAKQKFQTGympQKwxgCc9t4zaoxAsNthozjHTVVlHrdtmDuoaxsKQAWAFQrFRGdaSqlMF1BvHWjEAVwOzQJ49GPnDvraygJQKBSTBWUBZLEArApgqBT4XNhtwhwIr1AoFBOVaakAMgrB7L0/AqMdhCvLawNhtwkuXFLCmjkFp75AhUKhGAOmpZ+ivzoAGJ4FAPCL9555agtTKBSKMWRaWgBuZ9+VwJAuBlOFXAqFYiozLSVchgVg6zsLKJtyUCgUiqnCtJRw/dUBAOk6AGUBKBSKKcy0lHAD1wFoCsCtLACFQjGFmZYSbih1AAqFQjFVmZYSbjTrABQKhWKyMC0lnNEN1GETCNF3EPhU6gAUCoVisjAtJZzbru3ws9UAgLIAFArF9GBaSjjDAnBm8f+DUgAKhWJ6MC0lnOHa6csC8Kg0UIVCMQ2YlhLOZhO47LasNQBgsQBUDEChUExhpq2EczlsOLNUAYNyASkUiunBtJVwbkffFoDXqbKAFArF1GfaSjhNAWS3AEoCbpx2QVmuZ4xXpVAoFGPHtGwHDVpH0L6ygEoCbl78/EWU6tO9FAqFYioybRWAy27D6chuAQBq969QKKY8w3IBCSG+JYTYKYTYLoR4Qggxw/LaXUKIg0KI/UKIyyzH1wgh3tRf+7HIVoo7Bridtqx9gBQKhWK6MFwJeLeUskpKuQr4K/BVACHEacAtwHLgcuAeIYTRge2nwB3AIv3r8mGu4ZRwO2xZ+wApFArFdGFYLiApZdDyox+Q+vfXAg9IKaPAESHEQeAsIcRRIFdK+QqAEOI3wHXA48NZx6lwx3kLSEk58IkKhUIxRRl2DEAI8R3gVqADuFA/PBPYbDmtRj8W17/veXzMeetpZeNxW4VCoZgwDOgCEkJsEkLsyvJ1LYCU8ktSylnA/cDHjLdluZTs53hf975DCLFVCLG1qalp4KdRKBQKxaAZ0AKQUl4yyGv9Hvgb8DW0nf0sy2uVQK1+vDLL8b7ufS9wL8DatWuVv0ahUChGkOFmAS2y/HgNsE///lHgFiGEWwgxDy3Y+6qUsg7oFEKs17N/bgUeGc4aFAqFQnFqDDcG8F0hxBIgBRwDPgQgpdwthHgQ2AMkgI9KKZP6ez4M3Ad40YK/Yx4AVigUCgUIOUkyYdauXSu3bt063stQKBSKSYUQYpuUcm2211QllEKhUExTlAJQKBSKaYpSAAqFQjFNmTQxACFEE1qg+VQoBppHcDmTAfXM04Pp9szT7Xlh+M88R0pZku2FSaMAhoMQYmtfQZCpinrm6cF0e+bp9rwwus+sXEAKhUIxTVEKQKFQKKYp00UB3DveCxgH1DNPD6bbM0+354VRfOZpEQNQKBQKRW+miwWgUCgUih4oBaBQKBTTlCmtAIQQl+sziQ8KIb4w3usZDkKIWUKIZ4QQe4UQu4UQd+rHC4UQTwohqvV/CyzvmdBzmQeDEMIuhHhDCPFX/ecp/bwAQoh8IcSfhBD79N/32VP5uYUQ/6b/Te8SQmwUQnim2vMKIX4lhGgUQuyyHBuxZ9Q7L/9BP75FCDF3UAuTUk7JL8AOHALmAy5gB3DaeK9rGM9TAZyhfx8ADgCnAf8P+IJ+/AvA9/TvT9Of2Q3M0z8Lu/7aq8DZaAN6HgeuGO/n6+e5P4U2a+Kv+s9T+nn19f4auF3/3gXkT9XnRpsIeATw6j8/CLxvqj0vcB5wBrDLcmzEnhH4CPAz/ftbgD8Mal3j/cGM4gd+NvBPy893AXeN97pG8PkeAd4K7Acq9GMVwP5szwv8U/9MKoB9luPvBH4+3s/TxzNWAk8BF5FWAFP2efX15eoCUfQ4PiWfW1cAJ4BCtPb0fwUunYrPC8ztoQBG7BmNc/TvHWiVw2KgNU1lF5Dxh2UwbvOHRxrdvFsNbAHKpDZoB/3fUv20vp5/JhNkLvMg+CHwObR5EwZT+XlBs1ibgP/TXV+/EEL4maLPLaU8CfwncByoAzqklE8wRZ+3ByP5jOZ7pJQJtBntRQMtYCorgCHNH54sCCFygD8Dn5RSBvs7NcuxIc9lHi+EEFcDjVLKbYN9S5Zjk+Z5LTjQXAU/lVKuBrrR3AN9MamfW/d7X4vm6pgB+IUQ7+7vLVmOTZrnHSSn8oyn9PxTWQH0NZd40iKEcKIJ//ullH/RDzcIISr01yuARv34iMxlHkc2ANcIIY4CDwAXCSF+x9R9XoMaoEZKuUX/+U9oCmGqPvclwBEpZZOUMg78BTiHqfu8VkbyGc33CCEcQB7QOtACprICeA1YJISYJ4RwoQVGHh3nNZ0yerT/l8BeKeUPLC89CrxX//69pGcsT+q5zFLKu6SUlVLKuWi/u6ellO9mij6vgZSyHjghtFGrABejjVadqs99HFgvhPDp67wY2MvUfV4rI/mM1mu9A+3/y8AW0HgHRkY56HIlWrbMIeBL472eYT7LuWgm3U5gu/51JZqf7ymgWv+30PKeL+nPvh9LRgSwFtilv/YTBhEsGudnv4B0EHg6PO8qYKv+u34YKJjKzw18A9inr/W3aNkvU+p5gY1oMY442m79AyP5jIAH+CNwEC1TaP5g1qVaQSgUCsU0ZSq7gBQKhULRD0oBKBQKxTRFKQCFQqGYpigFoFAoFNMUpQAUCoVimqIUgEKhUExTlAJQKBSKacr/B0OYGgtcGB1xAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline \n",
    "\n",
    "x = np.linspace(0, total_train_episodes, MC_mean.size)\n",
    "plt.plot(x, MC_mean, label='Monte Carlo')\n",
    "z = np.linspace(0, total_train_episodes, len(moving_average(MC_mean, 100)))\n",
    "plt.plot(z, moving_average(MC_mean, 100), 'r', label='Moving Average (100)')\n",
    "\n",
    "\n",
    "\n",
    "# Add a legend\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d3181564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score  -93.57869810615986\n",
      "Score  -6.129404267742032\n",
      "Score  -64.54266990077396\n",
      "Score  -21.8400075180825\n",
      "Score  -22.17541821686116\n",
      "Score  17.136371987167834\n",
      "Score  189.55693236805195\n",
      "Score  178.59355409272553\n",
      "Score  -48.78758572536567\n",
      "Score  99.81732435860695\n",
      "\n",
      "Average score 22.805039907156704\n"
     ]
    }
   ],
   "source": [
    "total_test_episodes = 10\n",
    "q_tables = np.load('MC_tables.npy')\n",
    "q_table = q_tables[0]\n",
    "rewards = []\n",
    "max_env_steps = env._max_episode_steps\n",
    "number_of_buckets, number_of_actions, state_value_bounds = set_buckets_and_actions()\n",
    "\n",
    "# ******* Loop for each episode:\n",
    "for episode in range(total_test_episodes):\n",
    "    #print(\"***Episode*** \", episode)\n",
    "    \n",
    "    # Control variables\n",
    "    total_rewards = 0\n",
    "    done =  False\n",
    "    \n",
    "    # ******* Initialize S\n",
    "    # Reset the environment getting the initial state\n",
    "    bucket_state = bucketize(env.reset())\n",
    "    \n",
    "    # *******Loop for each step of episode:\n",
    "    for step in range(max_env_steps):\n",
    "        env.render()\n",
    "        \n",
    "        #******* Choose A from S using policy derived from Q (greedy in this case)\n",
    "        action = np.argmax(q_table[bucket_state])\n",
    "        #print(action)\n",
    "        \n",
    "        # ******* Take the action A, observe R, S'\n",
    "        new_state, reward, done, info = env.step(action)\n",
    "        bucket_new_state = bucketize(new_state)\n",
    "        \n",
    "        # new_state is now the current state\n",
    "        bucket_state =  bucket_new_state\n",
    "        \n",
    "        total_rewards += reward\n",
    "        \n",
    "        if done:\n",
    "            rewards.append(total_rewards)\n",
    "            print(\"Score \", total_rewards)\n",
    "            break\n",
    "                \n",
    "env.close()\n",
    "print(\"\\nAverage score \" + str(sum(rewards)/total_test_episodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "120a0fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(a, n=3) :\n",
    "    ret = np.cumsum(a, dtype=float)\n",
    "    ret[n:] = ret[n:] - ret[:-n]\n",
    "    return ret[n - 1:] / n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c946e75e",
   "metadata": {},
   "source": [
    "## Q-Learning\n",
    "https://github.com/FitMachineLearning/FitML/blob/master/QLearning/LunarLander_v2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "02e77eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filepath  C:\\Users\\larsh\\Desktop\\ZHAW\\6. Semester\\KI2\\Lab03\\L9 - Reinforcement Learning - cartpole_example/LL-QL-v2-weights.h5\n",
      "File  LL-QL-v2-weights.h5  does not exis. Retraining... \n",
      "dataX shape (1, 12)\n",
      "dataY shape (1, 1)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-30c9c1797970>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 142\u001b[1;33m             \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    143\u001b[0m             \u001b[0mqs_a\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mqs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mactions_1_hot\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\gym\\core.py\u001b[0m in \u001b[0;36mrender\u001b[1;34m(self, mode, **kwargs)\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'human'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 240\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    241\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\gym\\envs\\box2d\\lunar_lander.py\u001b[0m in \u001b[0;36mrender\u001b[1;34m(self, mode)\u001b[0m\n\u001b[0;32m    374\u001b[0m                                      color=(0.8, 0.8, 0))\n\u001b[0;32m    375\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 376\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreturn_rgb_array\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'rgb_array'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    377\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    378\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\gym\\envs\\classic_control\\rendering.py\u001b[0m in \u001b[0;36mrender\u001b[1;34m(self, return_rgb_array)\u001b[0m\n\u001b[0;32m    105\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwindow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwindow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mswitch_to\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwindow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_events\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mgeom\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgeoms\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pyglet\\window\\win32\\__init__.py\u001b[0m in \u001b[0;36mdispatch_events\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0m_user32\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPeekMessageW\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbyref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPM_REMOVE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    699\u001b[0m             \u001b[0m_user32\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTranslateMessage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbyref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 700\u001b[1;33m             \u001b[0m_user32\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDispatchMessageW\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbyref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    701\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_allow_dispatch_event\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import gym\n",
    "import os\n",
    "import h5py\n",
    "\n",
    "\n",
    "\n",
    "num_env_variables = 8\n",
    "num_env_actions = 4\n",
    "num_initial_observation = 15\n",
    "learning_rate = 0.003\n",
    "weigths_filename = \"LL-QL-v2-weights.h5\"\n",
    "\n",
    "b_discount = 0.99\n",
    "max_memory_len = 60000\n",
    "starting_explore_prob = 0.05\n",
    "training_epochs = 3\n",
    "load_previous_weights = True\n",
    "observe_and_train = True\n",
    "save_weights = True\n",
    "num_games_to_play = 1000\n",
    "\n",
    "\n",
    "#One hot encoding array\n",
    "possible_actions = np.arange(0,num_env_actions)\n",
    "actions_1_hot = np.zeros((num_env_actions,num_env_actions))\n",
    "actions_1_hot[np.arange(num_env_actions),possible_actions] = 1\n",
    "\n",
    "#Create testing enviroment\n",
    "env = gym.make('LunarLander-v2')\n",
    "env.reset()\n",
    "\n",
    "#initialize training matrix with random states and actions\n",
    "dataX = np.random.random(( 5,num_env_variables+num_env_actions ))\n",
    "#Only one output for the total score\n",
    "dataY = np.random.random((5,1))\n",
    "\n",
    "\n",
    "\n",
    "#nitialize the Neural Network with random weights\n",
    "\n",
    "model = keras.Sequential()\n",
    "#model.add(Dense(num_env_variables+num_env_actions, activation='tanh', input_dim=dataX.shape[1]))\n",
    "model.add(keras.layers.Dense(512, activation='relu', input_dim=dataX.shape[1]))\n",
    "model.add(keras.layers.Dense(256, activation='relu' ))\n",
    "model.add(keras.layers.Dense(256, activation='relu'))\n",
    "model.add(keras.layers.Dense(dataY.shape[1]))\n",
    "\n",
    "opt = keras.optimizers.Adam(lr=learning_rate)\n",
    "\n",
    "model.compile(loss='mse', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "#load previous model weights if they exist\n",
    "if load_previous_weights:\n",
    "    dir_path = os.path.realpath(\".\")\n",
    "    fn = dir_path + \"/\"+weigths_filename\n",
    "    print(\"filepath \", fn)\n",
    "    if  os.path.isfile(fn):\n",
    "        print(\"loading weights\")\n",
    "        model.load_weights(weigths_filename)\n",
    "    else:\n",
    "        print(\"File \",weigths_filename,\" does not exis. Retraining... \")\n",
    "\n",
    "#Initialize training data array\n",
    "total_steps = 0\n",
    "dataX = np.zeros(shape=(1,num_env_variables+num_env_actions))\n",
    "dataY = np.zeros(shape=(1,1))\n",
    "\n",
    "#Initialize Memory Array data array\n",
    "memoryX = np.zeros(shape=(1,num_env_variables+num_env_actions))\n",
    "memoryY = np.zeros(shape=(1,1))\n",
    "\n",
    "\n",
    "print(\"dataX shape\", dataX.shape)\n",
    "print(\"dataY shape\", dataY.shape)\n",
    "\n",
    "\n",
    "#This function predicts the reward that will result from taking an \"action\" at a state \"qstate\"\n",
    "def predictTotalRewards(qstate, action):\n",
    "    qs_a = np.concatenate((qstate,actions_1_hot[action]), axis=0)\n",
    "    predX = np.zeros(shape=(1,num_env_variables+num_env_actions))\n",
    "    predX[0] = qs_a\n",
    "\n",
    "    #print(\"trying to predict reward at qs_a\", predX[0])\n",
    "    pred = model.predict(predX[0].reshape(1,predX.shape[1]))\n",
    "    remembered_total_reward = pred[0][0]\n",
    "    return remembered_total_reward\n",
    "\n",
    "\n",
    "\n",
    "if observe_and_train:\n",
    "\n",
    "    #Play the game a determine number of times\n",
    "    for game in range(num_games_to_play):\n",
    "        gameX = np.zeros(shape=(1,num_env_variables+num_env_actions))\n",
    "        gameY = np.zeros(shape=(1,1))\n",
    "        #Get the initial Q state\n",
    "        qs = env.reset()\n",
    "        for step in range (40000):\n",
    "\n",
    "            #Learn from observation and not playing\n",
    "            if game < num_initial_observation:\n",
    "                #take a radmon action\n",
    "                a = env.action_space.sample()\n",
    "            else:\n",
    "                #Now playing and also learning from experience during play\n",
    "\n",
    "                #Calculate probability to take deterministic action vs random action (epsilon)\n",
    "                prob = np.random.rand(1)\n",
    "                explore_prob = starting_explore_prob-(starting_explore_prob/num_games_to_play)*game\n",
    "\n",
    "                #Chose between prediction and chance\n",
    "                if prob < explore_prob:\n",
    "                    #take a random action\n",
    "                    a=env.action_space.sample()\n",
    "                    #print(\"taking random action\",a, \"at total_steps\" , total_steps)\n",
    "                    #print(\"prob \", prob, \"explore_prob\", explore_prob)\n",
    "\n",
    "                else:\n",
    "                    ##chose an action by estimating the function-estimator remembered consequences of all possible actions\n",
    "                    ## Bellman states that the best policy (i.e. action) is the one that maximizez expected rewards for future states\n",
    "                    ## to caculate rewards we compute the reward a this state t + the discounted (b_discount) reward at all possible state t+1\n",
    "                    ## all states t+1 are estimated by our function estimator (our Neural Network)\n",
    "\n",
    "\n",
    "                    utility_possible_actions = np.zeros(shape=(num_env_actions))\n",
    "\n",
    "                    utility_possible_actions[0] = predictTotalRewards(qs,0)\n",
    "                    utility_possible_actions[1] = predictTotalRewards(qs,1)\n",
    "                    utility_possible_actions[2] = predictTotalRewards(qs,2)\n",
    "                    utility_possible_actions[3] = predictTotalRewards(qs,3)\n",
    "\n",
    "\n",
    "                    #chose argmax action of estimated anticipated rewards\n",
    "                    #print(\"utility_possible_actions \",utility_possible_actions)\n",
    "                    #print(\"argmax of utitity\", np.argmax(utility_possible_actions))\n",
    "                    a = np.argmax(utility_possible_actions)\n",
    "\n",
    "\n",
    "\n",
    "            #env.render()\n",
    "            qs_a = np.concatenate((qs,actions_1_hot[a]), axis=0)\n",
    "\n",
    "            #print(\"action\",a,\" qs_a\",qs_a)\n",
    "            #Perform the optimal action and get the target state and reward\n",
    "            s,r,done,info = env.step(a)\n",
    "\n",
    "\n",
    "            #record information for training and memory\n",
    "            if step ==0:\n",
    "                gameX[0] = qs_a\n",
    "                gameY[0] = np.array([r])\n",
    "                memoryX[0] = qs_a\n",
    "                memoryY[0] = np.array([r])\n",
    "\n",
    "            gameX = np.vstack((gameX,qs_a))\n",
    "            gameY = np.vstack((gameY,np.array([r])))\n",
    "\n",
    "\n",
    "            if done :\n",
    "                #GAME ENDED\n",
    "                #Calculate Q values from end to start of game (From last step to first)\n",
    "                for i in range(0,gameY.shape[0]):\n",
    "                    #print(\"Updating total_reward at game epoch \",(gameY.shape[0]-1) - i)\n",
    "                    if i==0:\n",
    "                        #print(\"reward at the last step \",gameY[(gameY.shape[0]-1)-i][0])\n",
    "                        gameY[(gameY.shape[0]-1)-i][0] = gameY[(gameY.shape[0]-1)-i][0]\n",
    "                    else:\n",
    "                        #print(\"local error before Bellman\", gameY[(gameY.shape[0]-1)-i][0],\"Next error \", gameY[(gameY.shape[0]-1)-i+1][0])\n",
    "                        gameY[(gameY.shape[0]-1)-i][0] = gameY[(gameY.shape[0]-1)-i][0]+b_discount*gameY[(gameY.shape[0]-1)-i+1][0]\n",
    "                        #print(\"reward at step\",i,\"away from the end is\",gameY[(gameY.shape[0]-1)-i][0])\n",
    "                    if i==gameY.shape[0]-1 and game%5==0:\n",
    "                        print(\"Training Game #\",game, \" steps = \", step ,\"last reward\", r,\" finished with headscore \", gameY[(gameY.shape[0]-1)-i][0])\n",
    "\n",
    "                if memoryX.shape[0] ==1:\n",
    "                    memoryX = gameX\n",
    "                    memoryY = gameY\n",
    "                else:\n",
    "                    #Add experience to memory\n",
    "                    memoryX = np.concatenate((memoryX,gameX),axis=0)\n",
    "                    memoryY = np.concatenate((memoryY,gameY),axis=0)\n",
    "\n",
    "                #if memory is full remove first element\n",
    "                if np.alen(memoryX) >= max_memory_len:\n",
    "                    #print(\"memory full. mem len \", np.alen(memoryX))\n",
    "                    for l in range(np.alen(gameX)):\n",
    "                        memoryX = np.delete(memoryX, 0, axis=0)\n",
    "                        memoryY = np.delete(memoryY, 0, axis=0)\n",
    "\n",
    "            #Update the states\n",
    "            qs=s\n",
    "\n",
    "            #Retrain every X game after num_initial_observation\n",
    "            if done and game >= num_initial_observation:\n",
    "                if game%10 == 0:\n",
    "                    print(\"Training  game# \", game,\"momory size\", memoryX.shape[0])\n",
    "                    model.fit(memoryX,memoryY, batch_size=256,nb_epoch=training_epochs,verbose=0)\n",
    "\n",
    "            if done:\n",
    "                if r >= 0 and r <99:\n",
    "                    print(\"Game \",game,\" ended with positive reward \")\n",
    "                if r > 50:\n",
    "                    print(\"Game \", game,\" WON *** \" )\n",
    "                #Game ended - Break\n",
    "                break\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if save_weights:\n",
    "    #Save model\n",
    "    print(\"Saving weights\")\n",
    "    model.save_weights(weigths_filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
